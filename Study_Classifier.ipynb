{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_decomposition import PLSCanonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('study_266_processed.csv', index_col=0, dtype={'Disease': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_data = data.T[['npeaks','pcgroup','drt']].T.drop('Disease', axis=1)\n",
    "data_d = data.T.drop(labels=['npeaks','pcgroup', 'drt'], axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X,y) = (data_d.drop('Disease', axis=1), data_d['Disease'])\n",
    "dummies=pd.get_dummies(y)\n",
    "y = dummies.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_scaler = StandardScaler()\n",
    "feature_data_scaled = feature_scaler.fit_transform(feature_data.T[['npeaks','drt']])\n",
    "feature_data.T[['npeaks', 'drt']] = feature_data_scaled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_data, npeaks=0, drt=0, group=False, log_scale=False):\n",
    "        self.npeaks = npeaks\n",
    "        self.drt = drt\n",
    "        self.group = group\n",
    "        self.feature_data = feature_data\n",
    "        self.log_scale = log_scale\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        if self.log_scale:\n",
    "            data = data.fillna(1).replace(0,1).apply(np.log10)\n",
    "        else:\n",
    "            data = data.fillna(0)\n",
    "        data = data.astype(float)\n",
    "        data = pd.concat([data,feature_data], axis=0)\n",
    "        data = data.T\n",
    "        index_to_drop=[]\n",
    "        for index,row in data.iterrows():\n",
    "            npeaks_data = row['npeaks']\n",
    "            drt_data = row['drt']\n",
    "            if npeaks_data<self.npeaks or drt_data<self.drt:\n",
    "                index_to_drop.append(index)\n",
    "        data = data.drop(index_to_drop).drop(['npeaks','drt'], axis=1)\n",
    "        if self.group:\n",
    "            data = data.astype(float).groupby('pcgroup').mean().T.values\n",
    "        else:\n",
    "            data = data.astype(float).drop('pcgroup', axis=1).T.values\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector = FeatureSelector(feature_data=feature_data, npeaks = 0.5, drt = 0.5, group=True, log_scale=True)\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=2)\n",
    "clf = RandomForestClassifier()\n",
    "estimators = [('select_features',feature_selector),('scale',scaler), ('reduce_dim',pca), ('clf',clf)]\n",
    "pipe = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "npeaks = [0,0.5]\n",
    "drts = [0, 0.5]\n",
    "interizer = np.vectorize(int)\n",
    "Cs = interizer(np.logspace(1,4,4))\n",
    "param_grid = dict(select_features__npeaks = npeaks,\n",
    "                  select_features__drt = drts,\n",
    "                  select_features__group = [True, False], \n",
    "                  reduce_dim = [None, PCA(None), PCA(50)],\n",
    "                  clf__n_estimators = Cs,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7777777777777778, total=  23.4s\n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.75, total=  23.1s\n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.8571428571428571, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.6666666666666666, total=  23.2s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  23.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.2857142857142857, total=  22.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  22.8s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.625, total=  22.8s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.7142857142857143, total=  23.1s\n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.6666666666666666, total=  23.0s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  23.0s\n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  22.7s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.7777777777777778, total=  23.3s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  23.0s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  23.2s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.625, total=  24.2s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.875, total=  23.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  23.5s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  23.4s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.75, total=  23.8s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.8571428571428571, total=  23.0s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.7777777777777778, total=  22.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.625, total=  22.8s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=1.0, total=  23.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  3.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7777777777777778, total=  23.3s\n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.75, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  23.5s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=1.0, total=  23.0s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.625, total=  23.5s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.8571428571428571, total=  23.1s\n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.7777777777777778, total=  22.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.625, total=  23.0s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.42857142857142855, total=  23.8s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  23.4s\n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5, total=  23.2s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.8571428571428571, total=  23.3s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.4444444444444444, total=  23.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.5714285714285714, total=  23.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  6.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  23.2s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.75, total=  23.6s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  23.1s\n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  22.9s\n",
      "\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 [CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5, total=  23.0s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  23.5s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.8888888888888888, total=  23.4s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.75, total=  23.3s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  23.4s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  23.8s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.375, total=  23.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  8.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7142857142857143, total=  23.2s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  23.2s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.375, total=  23.3s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  22.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.3333333333333333, total=  22.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.875, total=  22.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=1.0, total=  22.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.625, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  23.3s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  23.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  9.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.375, total=  22.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  23.2s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  23.3s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.625, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.42857142857142855, total=  23.0s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.7777777777777778, total=  22.9s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.625, total=  23.2s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  22.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.5555555555555556, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.5, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  23.8s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.6666666666666666, total=  23.3s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.5, total=  23.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 11.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  24.2s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.7142857142857143, total=  24.8s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  25.3s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.625, total=  25.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.8571428571428571, total=  25.0s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  24.3s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5, total=  24.5s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.8571428571428571, total=  24.8s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.5555555555555556, total=  23.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.375, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  23.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 13.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.7777777777777778, total=  24.0s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.625, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=1.0, total=  23.9s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.6666666666666666, total=  24.2s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  24.1s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=1.0, total=  23.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  23.5s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.375, total=  23.9s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  23.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  23.5s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7142857142857143, total=  24.0s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  23.8s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.75, total=  23.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.7142857142857143, total=  23.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 15.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.6666666666666666, total=  24.1s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  23.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.375, total=  24.2s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.6666666666666666, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  23.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.7142857142857143, total=  24.1s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.625, total=  23.5s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  23.5s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  24.0s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.375, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  23.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 17.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  23.9s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.75, total=  23.9s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.5, total=  23.8s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7142857142857143, total=  23.8s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.875, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  23.5s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  23.5s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.7142857142857143, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5555555555555556, total=  23.5s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.625, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.6666666666666666, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  23.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 20.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  23.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  23.3s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  23.6s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  23.6s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  23.4s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  23.7s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  26.4s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.5, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.6666666666666666, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.5, total=  26.5s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.7142857142857143, total=  26.7s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.6666666666666666, total=  26.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 23.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5, total=  26.0s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.8571428571428571, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.8571428571428571, total=  25.8s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.6666666666666666, total=  26.0s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.5, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  25.9s\n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.7777777777777778, total=  25.8s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5, total=  25.9s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.8571428571428571, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.6666666666666666, total=  25.9s\n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5, total=  25.8s\n",
      "\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 [CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.8571428571428571, total=  26.0s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  26.3s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.625, total=  26.0s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  26.0s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  26.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 26.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7142857142857143, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  26.0s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.75, total=  26.3s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  26.4s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  26.0s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.875, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  26.5s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.6666666666666666, total=  26.7s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  26.1s\n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  25.9s\n",
      "\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 [CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  25.8s\n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  25.7s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  26.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 29.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  26.4s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.625, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  26.3s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  26.5s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7142857142857143, total=  26.3s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.75, total=  26.5s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  26.4s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  26.4s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  26.4s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  26.3s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5, total=  26.0s\n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  26.0s\n",
      "\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 [CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.5555555555555556, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  26.3s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  25.9s\n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  25.9s\n",
      "\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 [CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5, total=  26.0s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  26.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 32.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  26.4s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.625, total=  26.4s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  26.7s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  50.6s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.5, total=  50.0s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  50.0s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.5555555555555556, total=  50.3s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.5, total=  50.5s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  50.5s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5, total=  51.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.8571428571428571, total=  51.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.6666666666666666, total=  50.4s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5, total=  50.6s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.8571428571428571, total=  51.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.7777777777777778, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5, total=  49.9s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.8571428571428571, total=  50.3s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.5555555555555556, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.5, total=  50.6s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  50.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 38.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.7777777777777778, total=  51.0s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5, total=  51.5s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.8571428571428571, total=  50.9s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.7777777777777778, total=  50.3s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5, total=  50.6s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.8571428571428571, total=  50.9s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.625, total=  50.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  50.0s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7142857142857143, total=  49.6s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  49.8s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.75, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  50.3s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  49.7s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  50.4s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  50.6s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  50.6s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5, total=  50.4s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  51.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.5555555555555556, total=  50.7s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  50.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 44.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  50.0s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5, total=  50.4s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  50.0s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  50.5s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  50.4s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  50.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.625, total=  50.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  50.5s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  50.6s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7142857142857143, total=  50.0s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  50.5s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.75, total=  50.8s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  50.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  50.0s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  50.4s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  50.5s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  49.9s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5, total=  49.8s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.5555555555555556, total=  50.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 50.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  50.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  50.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5, total=  50.7s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  49.8s\n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  49.9s\n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  49.9s\n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  48.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 288 out of 288 | elapsed: 52.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('select_features', FeatureSelector(drt=0.5,\n",
       "        feature_data=                  0         1          2         3          4         5  \\\n",
       "new_index\n",
       "npeaks     0.230431 -0.424874  -0.670614 -0.342961    0.72191 -0.179135\n",
       "pcgroup          77      6780       6604      6297       6320 ...     ...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'select_features__npeaks': [0, 0.5], 'select_features__drt': [0, 0.5], 'select_features__group': [True, False], 'reduce_dim': [None, PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False), PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)], 'clf__n_estimators': array([   10,   100,  1000, 10000])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = GridSearchCV(pipe,param_grid=param_grid, verbose=10, n_jobs=-1)\n",
    "estimator.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_clf__n_estimators</th>\n",
       "      <th>param_reduce_dim</th>\n",
       "      <th>param_select_features__drt</th>\n",
       "      <th>param_select_features__group</th>\n",
       "      <th>param_select_features__npeaks</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.015584</td>\n",
       "      <td>11.162480</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': None, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087276</td>\n",
       "      <td>0.049783</td>\n",
       "      <td>0.043606</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.789093</td>\n",
       "      <td>11.234387</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': None, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.134057</td>\n",
       "      <td>0.028626</td>\n",
       "      <td>0.165172</td>\n",
       "      <td>0.027730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.625713</td>\n",
       "      <td>11.267243</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': None, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109181</td>\n",
       "      <td>0.021354</td>\n",
       "      <td>0.035215</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.556832</td>\n",
       "      <td>11.324277</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': None, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078320</td>\n",
       "      <td>0.047779</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.009953</td>\n",
       "      <td>11.575240</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': None, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064642</td>\n",
       "      <td>0.527772</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.029463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.037585</td>\n",
       "      <td>11.300622</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': None, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.175473</td>\n",
       "      <td>0.089510</td>\n",
       "      <td>0.043606</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.938110</td>\n",
       "      <td>11.445169</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': None, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.219868</td>\n",
       "      <td>0.109824</td>\n",
       "      <td>0.077152</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.539071</td>\n",
       "      <td>11.423855</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': None, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133477</td>\n",
       "      <td>0.085070</td>\n",
       "      <td>0.148293</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.829038</td>\n",
       "      <td>11.329101</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.081157</td>\n",
       "      <td>0.038272</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.756657</td>\n",
       "      <td>11.431839</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141122</td>\n",
       "      <td>0.105265</td>\n",
       "      <td>0.148293</td>\n",
       "      <td>0.029463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.750638</td>\n",
       "      <td>11.476978</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094603</td>\n",
       "      <td>0.134760</td>\n",
       "      <td>0.125660</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.630605</td>\n",
       "      <td>11.566732</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.217590</td>\n",
       "      <td>0.178141</td>\n",
       "      <td>0.141445</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.980314</td>\n",
       "      <td>11.335568</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>0.062492</td>\n",
       "      <td>0.140859</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.909832</td>\n",
       "      <td>11.482664</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200616</td>\n",
       "      <td>0.129146</td>\n",
       "      <td>0.078216</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.743212</td>\n",
       "      <td>11.557830</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.132825</td>\n",
       "      <td>0.148255</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11.599101</td>\n",
       "      <td>11.541738</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.106887</td>\n",
       "      <td>0.127753</td>\n",
       "      <td>0.030156</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12.034706</td>\n",
       "      <td>11.341305</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017882</td>\n",
       "      <td>0.042499</td>\n",
       "      <td>0.128586</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11.860545</td>\n",
       "      <td>11.508476</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.128828</td>\n",
       "      <td>0.190157</td>\n",
       "      <td>0.178638</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11.708711</td>\n",
       "      <td>11.427607</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>0.056522</td>\n",
       "      <td>0.124004</td>\n",
       "      <td>0.027730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11.557100</td>\n",
       "      <td>11.357389</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008845</td>\n",
       "      <td>0.017359</td>\n",
       "      <td>0.294628</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11.879098</td>\n",
       "      <td>11.288771</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025690</td>\n",
       "      <td>0.036985</td>\n",
       "      <td>0.035215</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11.768646</td>\n",
       "      <td>11.338297</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082208</td>\n",
       "      <td>0.080595</td>\n",
       "      <td>0.208730</td>\n",
       "      <td>0.031427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.661699</td>\n",
       "      <td>11.449664</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>0.117252</td>\n",
       "      <td>0.078216</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11.548043</td>\n",
       "      <td>11.378550</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100168</td>\n",
       "      <td>0.102938</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12.157496</td>\n",
       "      <td>11.364437</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 100, 'reduce_dim': None,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070851</td>\n",
       "      <td>0.096083</td>\n",
       "      <td>0.087211</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12.020375</td>\n",
       "      <td>11.511051</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 100, 'reduce_dim': None,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032037</td>\n",
       "      <td>0.132262</td>\n",
       "      <td>0.140859</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12.140991</td>\n",
       "      <td>12.061190</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 100, 'reduce_dim': None,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.159925</td>\n",
       "      <td>0.356417</td>\n",
       "      <td>0.090468</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12.488261</td>\n",
       "      <td>12.840627</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 100, 'reduce_dim': None,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333226</td>\n",
       "      <td>0.565644</td>\n",
       "      <td>0.125660</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12.815194</td>\n",
       "      <td>11.718088</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 100, 'reduce_dim': None,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287496</td>\n",
       "      <td>0.098096</td>\n",
       "      <td>0.140859</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12.249979</td>\n",
       "      <td>11.395466</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 100, 'reduce_dim': None,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083095</td>\n",
       "      <td>0.111392</td>\n",
       "      <td>0.191373</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>14.437385</td>\n",
       "      <td>11.926356</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 1000, 'reduce_dim': PCA(...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041316</td>\n",
       "      <td>0.064580</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>14.450727</td>\n",
       "      <td>11.886438</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 1000, 'reduce_dim': PCA(...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062652</td>\n",
       "      <td>0.027709</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>14.431783</td>\n",
       "      <td>11.688955</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 1000, 'reduce_dim': PCA(...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136258</td>\n",
       "      <td>0.013070</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>14.332872</td>\n",
       "      <td>11.784331</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 1000, 'reduce_dim': PCA(...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109556</td>\n",
       "      <td>0.030904</td>\n",
       "      <td>0.125660</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>14.270215</td>\n",
       "      <td>11.869963</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 1000, 'reduce_dim': PCA(...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067613</td>\n",
       "      <td>0.239084</td>\n",
       "      <td>0.030156</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>14.435935</td>\n",
       "      <td>12.083596</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 1000, 'reduce_dim': PCA(...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327511</td>\n",
       "      <td>0.222304</td>\n",
       "      <td>0.030156</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>37.292763</td>\n",
       "      <td>12.911550</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': Non...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166666</td>\n",
       "      <td>0.102557</td>\n",
       "      <td>0.090468</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>37.382960</td>\n",
       "      <td>12.948625</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': Non...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.104873</td>\n",
       "      <td>0.077451</td>\n",
       "      <td>0.150781</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>37.924633</td>\n",
       "      <td>13.005772</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': Non...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.325262</td>\n",
       "      <td>0.072553</td>\n",
       "      <td>0.150781</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>37.703556</td>\n",
       "      <td>13.027902</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': Non...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266801</td>\n",
       "      <td>0.053260</td>\n",
       "      <td>0.140859</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>37.194507</td>\n",
       "      <td>12.941773</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': Non...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.103778</td>\n",
       "      <td>0.048374</td>\n",
       "      <td>0.150781</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>37.480362</td>\n",
       "      <td>13.018299</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': Non...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.150344</td>\n",
       "      <td>0.033673</td>\n",
       "      <td>0.150781</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>38.124145</td>\n",
       "      <td>12.998091</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': Non...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333424</td>\n",
       "      <td>0.069146</td>\n",
       "      <td>0.150781</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>37.669380</td>\n",
       "      <td>12.960642</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': Non...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.289195</td>\n",
       "      <td>0.048761</td>\n",
       "      <td>0.150781</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>37.120566</td>\n",
       "      <td>13.047693</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024208</td>\n",
       "      <td>0.023275</td>\n",
       "      <td>0.035215</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>37.014882</td>\n",
       "      <td>12.924578</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.257633</td>\n",
       "      <td>0.046976</td>\n",
       "      <td>0.064293</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>37.152267</td>\n",
       "      <td>12.968365</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.244137</td>\n",
       "      <td>0.045288</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>37.279613</td>\n",
       "      <td>12.953753</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.373861</td>\n",
       "      <td>0.086288</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>37.540961</td>\n",
       "      <td>13.158258</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.096718</td>\n",
       "      <td>0.216211</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>37.171929</td>\n",
       "      <td>13.091165</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.147883</td>\n",
       "      <td>0.259564</td>\n",
       "      <td>0.125660</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>37.301266</td>\n",
       "      <td>12.967365</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215386</td>\n",
       "      <td>0.103754</td>\n",
       "      <td>0.030156</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>37.241355</td>\n",
       "      <td>13.041510</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.331850</td>\n",
       "      <td>0.114206</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>37.264453</td>\n",
       "      <td>12.952479</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.132643</td>\n",
       "      <td>0.036627</td>\n",
       "      <td>0.035215</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>37.335506</td>\n",
       "      <td>12.907768</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.192863</td>\n",
       "      <td>0.068855</td>\n",
       "      <td>0.064293</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>37.305571</td>\n",
       "      <td>13.164652</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110026</td>\n",
       "      <td>0.202105</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>37.318638</td>\n",
       "      <td>12.988787</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194842</td>\n",
       "      <td>0.041658</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>37.090186</td>\n",
       "      <td>12.887812</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.132386</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>37.317060</td>\n",
       "      <td>12.893817</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046425</td>\n",
       "      <td>0.138505</td>\n",
       "      <td>0.125660</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>37.300926</td>\n",
       "      <td>12.918597</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.255276</td>\n",
       "      <td>0.112514</td>\n",
       "      <td>0.030156</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>37.176423</td>\n",
       "      <td>12.269980</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.227534</td>\n",
       "      <td>0.840018</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       12.015584        11.162480         0.791667          1.000000   \n",
       "1       11.789093        11.234387         0.541667          0.980392   \n",
       "2       11.625713        11.267243         0.666667          1.000000   \n",
       "3       11.556832        11.324277         0.666667          1.000000   \n",
       "4       12.009953        11.575240         0.666667          0.979167   \n",
       "5       12.037585        11.300622         0.833333          1.000000   \n",
       "6       11.938110        11.445169         0.750000          1.000000   \n",
       "7       11.539071        11.423855         0.791667          1.000000   \n",
       "8       11.829038        11.329101         0.708333          1.000000   \n",
       "9       11.756657        11.431839         0.791667          0.979167   \n",
       "10      11.750638        11.476978         0.666667          1.000000   \n",
       "11      11.630605        11.566732         0.625000          1.000000   \n",
       "12      11.980314        11.335568         0.666667          1.000000   \n",
       "13      11.909832        11.482664         0.541667          1.000000   \n",
       "14      11.743212        11.557830         0.625000          1.000000   \n",
       "15      11.599101        11.541738         0.541667          1.000000   \n",
       "16      12.034706        11.341305         0.750000          1.000000   \n",
       "17      11.860545        11.508476         0.625000          1.000000   \n",
       "18      11.708711        11.427607         0.541667          0.980392   \n",
       "19      11.557100        11.357389         0.708333          1.000000   \n",
       "20      11.879098        11.288771         0.666667          1.000000   \n",
       "21      11.768646        11.338297         0.666667          0.977778   \n",
       "22      11.661699        11.449664         0.541667          1.000000   \n",
       "23      11.548043        11.378550         0.666667          1.000000   \n",
       "24      12.157496        11.364437         0.583333          1.000000   \n",
       "25      12.020375        11.511051         0.666667          1.000000   \n",
       "26      12.140991        12.061190         0.625000          1.000000   \n",
       "27      12.488261        12.840627         0.666667          1.000000   \n",
       "28      12.815194        11.718088         0.666667          1.000000   \n",
       "29      12.249979        11.395466         0.583333          1.000000   \n",
       "..            ...              ...              ...               ...   \n",
       "66      14.437385        11.926356         0.666667          1.000000   \n",
       "67      14.450727        11.886438         0.625000          1.000000   \n",
       "68      14.431783        11.688955         0.583333          1.000000   \n",
       "69      14.332872        11.784331         0.666667          1.000000   \n",
       "70      14.270215        11.869963         0.541667          1.000000   \n",
       "71      14.435935        12.083596         0.583333          1.000000   \n",
       "72      37.292763        12.911550         0.625000          1.000000   \n",
       "73      37.382960        12.948625         0.625000          1.000000   \n",
       "74      37.924633        13.005772         0.625000          1.000000   \n",
       "75      37.703556        13.027902         0.666667          1.000000   \n",
       "76      37.194507        12.941773         0.708333          1.000000   \n",
       "77      37.480362        13.018299         0.625000          1.000000   \n",
       "78      38.124145        12.998091         0.708333          1.000000   \n",
       "79      37.669380        12.960642         0.708333          1.000000   \n",
       "80      37.120566        13.047693         0.666667          1.000000   \n",
       "81      37.014882        12.924578         0.708333          1.000000   \n",
       "82      37.152267        12.968365         0.666667          1.000000   \n",
       "83      37.279613        12.953753         0.625000          1.000000   \n",
       "84      37.540961        13.158258         0.583333          1.000000   \n",
       "85      37.171929        13.091165         0.666667          1.000000   \n",
       "86      37.301266        12.967365         0.541667          1.000000   \n",
       "87      37.241355        13.041510         0.625000          1.000000   \n",
       "88      37.264453        12.952479         0.666667          1.000000   \n",
       "89      37.335506        12.907768         0.708333          1.000000   \n",
       "90      37.305571        13.164652         0.666667          1.000000   \n",
       "91      37.318638        12.988787         0.625000          1.000000   \n",
       "92      37.090186        12.887812         0.583333          1.000000   \n",
       "93      37.317060        12.893817         0.666667          1.000000   \n",
       "94      37.300926        12.918597         0.541667          1.000000   \n",
       "95      37.176423        12.269980         0.625000          1.000000   \n",
       "\n",
       "   param_clf__n_estimators                                   param_reduce_dim  \\\n",
       "0                       10                                               None   \n",
       "1                       10                                               None   \n",
       "2                       10                                               None   \n",
       "3                       10                                               None   \n",
       "4                       10                                               None   \n",
       "5                       10                                               None   \n",
       "6                       10                                               None   \n",
       "7                       10                                               None   \n",
       "8                       10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "9                       10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "10                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "11                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "12                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "13                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "14                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "15                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "16                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "17                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "18                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "19                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "20                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "21                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "22                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "23                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "24                     100                                               None   \n",
       "25                     100                                               None   \n",
       "26                     100                                               None   \n",
       "27                     100                                               None   \n",
       "28                     100                                               None   \n",
       "29                     100                                               None   \n",
       "..                     ...                                                ...   \n",
       "66                    1000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "67                    1000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "68                    1000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "69                    1000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "70                    1000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "71                    1000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "72                   10000                                               None   \n",
       "73                   10000                                               None   \n",
       "74                   10000                                               None   \n",
       "75                   10000                                               None   \n",
       "76                   10000                                               None   \n",
       "77                   10000                                               None   \n",
       "78                   10000                                               None   \n",
       "79                   10000                                               None   \n",
       "80                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "81                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "82                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "83                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "84                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "85                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "86                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "87                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "88                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "89                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "90                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "91                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "92                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "93                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "94                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "95                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "\n",
       "   param_select_features__drt param_select_features__group  \\\n",
       "0                           0                         True   \n",
       "1                           0                         True   \n",
       "2                           0                        False   \n",
       "3                           0                        False   \n",
       "4                         0.5                         True   \n",
       "5                         0.5                         True   \n",
       "6                         0.5                        False   \n",
       "7                         0.5                        False   \n",
       "8                           0                         True   \n",
       "9                           0                         True   \n",
       "10                          0                        False   \n",
       "11                          0                        False   \n",
       "12                        0.5                         True   \n",
       "13                        0.5                         True   \n",
       "14                        0.5                        False   \n",
       "15                        0.5                        False   \n",
       "16                          0                         True   \n",
       "17                          0                         True   \n",
       "18                          0                        False   \n",
       "19                          0                        False   \n",
       "20                        0.5                         True   \n",
       "21                        0.5                         True   \n",
       "22                        0.5                        False   \n",
       "23                        0.5                        False   \n",
       "24                          0                         True   \n",
       "25                          0                         True   \n",
       "26                          0                        False   \n",
       "27                          0                        False   \n",
       "28                        0.5                         True   \n",
       "29                        0.5                         True   \n",
       "..                        ...                          ...   \n",
       "66                          0                        False   \n",
       "67                          0                        False   \n",
       "68                        0.5                         True   \n",
       "69                        0.5                         True   \n",
       "70                        0.5                        False   \n",
       "71                        0.5                        False   \n",
       "72                          0                         True   \n",
       "73                          0                         True   \n",
       "74                          0                        False   \n",
       "75                          0                        False   \n",
       "76                        0.5                         True   \n",
       "77                        0.5                         True   \n",
       "78                        0.5                        False   \n",
       "79                        0.5                        False   \n",
       "80                          0                         True   \n",
       "81                          0                         True   \n",
       "82                          0                        False   \n",
       "83                          0                        False   \n",
       "84                        0.5                         True   \n",
       "85                        0.5                         True   \n",
       "86                        0.5                        False   \n",
       "87                        0.5                        False   \n",
       "88                          0                         True   \n",
       "89                          0                         True   \n",
       "90                          0                        False   \n",
       "91                          0                        False   \n",
       "92                        0.5                         True   \n",
       "93                        0.5                         True   \n",
       "94                        0.5                        False   \n",
       "95                        0.5                        False   \n",
       "\n",
       "   param_select_features__npeaks  \\\n",
       "0                              0   \n",
       "1                            0.5   \n",
       "2                              0   \n",
       "3                            0.5   \n",
       "4                              0   \n",
       "5                            0.5   \n",
       "6                              0   \n",
       "7                            0.5   \n",
       "8                              0   \n",
       "9                            0.5   \n",
       "10                             0   \n",
       "11                           0.5   \n",
       "12                             0   \n",
       "13                           0.5   \n",
       "14                             0   \n",
       "15                           0.5   \n",
       "16                             0   \n",
       "17                           0.5   \n",
       "18                             0   \n",
       "19                           0.5   \n",
       "20                             0   \n",
       "21                           0.5   \n",
       "22                             0   \n",
       "23                           0.5   \n",
       "24                             0   \n",
       "25                           0.5   \n",
       "26                             0   \n",
       "27                           0.5   \n",
       "28                             0   \n",
       "29                           0.5   \n",
       "..                           ...   \n",
       "66                             0   \n",
       "67                           0.5   \n",
       "68                             0   \n",
       "69                           0.5   \n",
       "70                             0   \n",
       "71                           0.5   \n",
       "72                             0   \n",
       "73                           0.5   \n",
       "74                             0   \n",
       "75                           0.5   \n",
       "76                             0   \n",
       "77                           0.5   \n",
       "78                             0   \n",
       "79                           0.5   \n",
       "80                             0   \n",
       "81                           0.5   \n",
       "82                             0   \n",
       "83                           0.5   \n",
       "84                             0   \n",
       "85                           0.5   \n",
       "86                             0   \n",
       "87                           0.5   \n",
       "88                             0   \n",
       "89                           0.5   \n",
       "90                             0   \n",
       "91                           0.5   \n",
       "92                             0   \n",
       "93                           0.5   \n",
       "94                             0   \n",
       "95                           0.5   \n",
       "\n",
       "                                               params       ...         \\\n",
       "0   {'clf__n_estimators': 10, 'reduce_dim': None, ...       ...          \n",
       "1   {'clf__n_estimators': 10, 'reduce_dim': None, ...       ...          \n",
       "2   {'clf__n_estimators': 10, 'reduce_dim': None, ...       ...          \n",
       "3   {'clf__n_estimators': 10, 'reduce_dim': None, ...       ...          \n",
       "4   {'clf__n_estimators': 10, 'reduce_dim': None, ...       ...          \n",
       "5   {'clf__n_estimators': 10, 'reduce_dim': None, ...       ...          \n",
       "6   {'clf__n_estimators': 10, 'reduce_dim': None, ...       ...          \n",
       "7   {'clf__n_estimators': 10, 'reduce_dim': None, ...       ...          \n",
       "8   {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "9   {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "10  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "11  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "12  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "13  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "14  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "15  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "16  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "17  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "18  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "19  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "20  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "21  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "22  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "23  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "24  {'clf__n_estimators': 100, 'reduce_dim': None,...       ...          \n",
       "25  {'clf__n_estimators': 100, 'reduce_dim': None,...       ...          \n",
       "26  {'clf__n_estimators': 100, 'reduce_dim': None,...       ...          \n",
       "27  {'clf__n_estimators': 100, 'reduce_dim': None,...       ...          \n",
       "28  {'clf__n_estimators': 100, 'reduce_dim': None,...       ...          \n",
       "29  {'clf__n_estimators': 100, 'reduce_dim': None,...       ...          \n",
       "..                                                ...       ...          \n",
       "66  {'clf__n_estimators': 1000, 'reduce_dim': PCA(...       ...          \n",
       "67  {'clf__n_estimators': 1000, 'reduce_dim': PCA(...       ...          \n",
       "68  {'clf__n_estimators': 1000, 'reduce_dim': PCA(...       ...          \n",
       "69  {'clf__n_estimators': 1000, 'reduce_dim': PCA(...       ...          \n",
       "70  {'clf__n_estimators': 1000, 'reduce_dim': PCA(...       ...          \n",
       "71  {'clf__n_estimators': 1000, 'reduce_dim': PCA(...       ...          \n",
       "72  {'clf__n_estimators': 10000, 'reduce_dim': Non...       ...          \n",
       "73  {'clf__n_estimators': 10000, 'reduce_dim': Non...       ...          \n",
       "74  {'clf__n_estimators': 10000, 'reduce_dim': Non...       ...          \n",
       "75  {'clf__n_estimators': 10000, 'reduce_dim': Non...       ...          \n",
       "76  {'clf__n_estimators': 10000, 'reduce_dim': Non...       ...          \n",
       "77  {'clf__n_estimators': 10000, 'reduce_dim': Non...       ...          \n",
       "78  {'clf__n_estimators': 10000, 'reduce_dim': Non...       ...          \n",
       "79  {'clf__n_estimators': 10000, 'reduce_dim': Non...       ...          \n",
       "80  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "81  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "82  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "83  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "84  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "85  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "86  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "87  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "88  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "89  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "90  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "91  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "92  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "93  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "94  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "95  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0            0.777778            1.000000              0.750   \n",
       "1            0.666667            1.000000              0.625   \n",
       "2            0.666667            1.000000              0.625   \n",
       "3            0.666667            1.000000              0.750   \n",
       "4            0.777778            1.000000              0.625   \n",
       "5            0.777778            1.000000              0.875   \n",
       "6            0.666667            1.000000              0.750   \n",
       "7            0.777778            1.000000              0.625   \n",
       "8            0.777778            1.000000              0.750   \n",
       "9            0.777778            1.000000              0.625   \n",
       "10           0.555556            1.000000              0.625   \n",
       "11           0.777778            1.000000              0.625   \n",
       "12           0.666667            1.000000              0.500   \n",
       "13           0.444444            1.000000              0.625   \n",
       "14           0.555556            1.000000              0.750   \n",
       "15           0.555556            1.000000              0.500   \n",
       "16           0.888889            1.000000              0.750   \n",
       "17           0.777778            1.000000              0.375   \n",
       "18           0.666667            1.000000              0.375   \n",
       "19           0.333333            1.000000              0.875   \n",
       "20           0.666667            1.000000              0.625   \n",
       "21           0.777778            0.933333              0.375   \n",
       "22           0.555556            1.000000              0.625   \n",
       "23           0.777778            1.000000              0.625   \n",
       "24           0.555556            1.000000              0.500   \n",
       "25           0.666667            1.000000              0.500   \n",
       "26           0.666667            1.000000              0.500   \n",
       "27           0.555556            1.000000              0.625   \n",
       "28           0.666667            1.000000              0.500   \n",
       "29           0.555556            1.000000              0.375   \n",
       "..                ...                 ...                ...   \n",
       "66           0.666667            1.000000              0.750   \n",
       "67           0.555556            1.000000              0.750   \n",
       "68           0.666667            1.000000              0.500   \n",
       "69           0.555556            1.000000              0.625   \n",
       "70           0.555556            1.000000              0.500   \n",
       "71           0.555556            1.000000              0.625   \n",
       "72           0.666667            1.000000              0.500   \n",
       "73           0.555556            1.000000              0.500   \n",
       "74           0.555556            1.000000              0.500   \n",
       "75           0.666667            1.000000              0.500   \n",
       "76           0.777778            1.000000              0.500   \n",
       "77           0.555556            1.000000              0.500   \n",
       "78           0.777778            1.000000              0.500   \n",
       "79           0.777778            1.000000              0.500   \n",
       "80           0.666667            1.000000              0.625   \n",
       "81           0.777778            1.000000              0.625   \n",
       "82           0.666667            1.000000              0.750   \n",
       "83           0.555556            1.000000              0.750   \n",
       "84           0.666667            1.000000              0.500   \n",
       "85           0.555556            1.000000              0.625   \n",
       "86           0.555556            1.000000              0.500   \n",
       "87           0.555556            1.000000              0.750   \n",
       "88           0.666667            1.000000              0.625   \n",
       "89           0.777778            1.000000              0.625   \n",
       "90           0.666667            1.000000              0.750   \n",
       "91           0.555556            1.000000              0.750   \n",
       "92           0.666667            1.000000              0.500   \n",
       "93           0.555556            1.000000              0.625   \n",
       "94           0.555556            1.000000              0.500   \n",
       "95           0.555556            1.000000              0.750   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0               1.0000           0.857143            1.000000      0.087276   \n",
       "1               1.0000           0.285714            0.941176      0.134057   \n",
       "2               1.0000           0.714286            1.000000      0.109181   \n",
       "3               1.0000           0.571429            1.000000      0.078320   \n",
       "4               0.9375           0.571429            1.000000      0.064642   \n",
       "5               1.0000           0.857143            1.000000      0.175473   \n",
       "6               1.0000           0.857143            1.000000      0.219868   \n",
       "7               1.0000           1.000000            1.000000      0.133477   \n",
       "8               1.0000           0.571429            1.000000      0.081157   \n",
       "9               0.9375           1.000000            1.000000      0.141122   \n",
       "10              1.0000           0.857143            1.000000      0.094603   \n",
       "11              1.0000           0.428571            1.000000      0.217590   \n",
       "12              1.0000           0.857143            1.000000      0.013532   \n",
       "13              1.0000           0.571429            1.000000      0.200616   \n",
       "14              1.0000           0.571429            1.000000      0.132825   \n",
       "15              1.0000           0.571429            1.000000      0.106887   \n",
       "16              1.0000           0.571429            1.000000      0.017882   \n",
       "17              1.0000           0.714286            1.000000      0.128828   \n",
       "18              1.0000           0.571429            0.941176      0.104094   \n",
       "19              1.0000           1.000000            1.000000      0.008845   \n",
       "20              1.0000           0.714286            1.000000      0.025690   \n",
       "21              1.0000           0.857143            1.000000      0.082208   \n",
       "22              1.0000           0.428571            1.000000      0.031284   \n",
       "23              1.0000           0.571429            1.000000      0.100168   \n",
       "24              1.0000           0.714286            1.000000      0.070851   \n",
       "25              1.0000           0.857143            1.000000      0.032037   \n",
       "26              1.0000           0.714286            1.000000      0.159925   \n",
       "27              1.0000           0.857143            1.000000      0.333226   \n",
       "28              1.0000           0.857143            1.000000      0.287496   \n",
       "29              1.0000           0.857143            1.000000      0.083095   \n",
       "..                 ...                ...                 ...           ...   \n",
       "66              1.0000           0.571429            1.000000      0.041316   \n",
       "67              1.0000           0.571429            1.000000      0.062652   \n",
       "68              1.0000           0.571429            1.000000      0.136258   \n",
       "69              1.0000           0.857143            1.000000      0.109556   \n",
       "70              1.0000           0.571429            1.000000      0.067613   \n",
       "71              1.0000           0.571429            1.000000      0.327511   \n",
       "72              1.0000           0.714286            1.000000      0.166666   \n",
       "73              1.0000           0.857143            1.000000      0.104873   \n",
       "74              1.0000           0.857143            1.000000      0.325262   \n",
       "75              1.0000           0.857143            1.000000      0.266801   \n",
       "76              1.0000           0.857143            1.000000      0.103778   \n",
       "77              1.0000           0.857143            1.000000      0.150344   \n",
       "78              1.0000           0.857143            1.000000      0.333424   \n",
       "79              1.0000           0.857143            1.000000      0.289195   \n",
       "80              1.0000           0.714286            1.000000      0.024208   \n",
       "81              1.0000           0.714286            1.000000      0.257633   \n",
       "82              1.0000           0.571429            1.000000      0.244137   \n",
       "83              1.0000           0.571429            1.000000      0.373861   \n",
       "84              1.0000           0.571429            1.000000      0.096718   \n",
       "85              1.0000           0.857143            1.000000      0.147883   \n",
       "86              1.0000           0.571429            1.000000      0.215386   \n",
       "87              1.0000           0.571429            1.000000      0.331850   \n",
       "88              1.0000           0.714286            1.000000      0.132643   \n",
       "89              1.0000           0.714286            1.000000      0.192863   \n",
       "90              1.0000           0.571429            1.000000      0.110026   \n",
       "91              1.0000           0.571429            1.000000      0.194842   \n",
       "92              1.0000           0.571429            1.000000      0.132386   \n",
       "93              1.0000           0.857143            1.000000      0.046425   \n",
       "94              1.0000           0.571429            1.000000      0.255276   \n",
       "95              1.0000           0.571429            1.000000      0.227534   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "0         0.049783        0.043606         0.000000  \n",
       "1         0.028626        0.165172         0.027730  \n",
       "2         0.021354        0.035215         0.000000  \n",
       "3         0.047779        0.070430         0.000000  \n",
       "4         0.527772        0.088622         0.029463  \n",
       "5         0.089510        0.043606         0.000000  \n",
       "6         0.109824        0.077152         0.000000  \n",
       "7         0.085070        0.148293         0.000000  \n",
       "8         0.038272        0.088622         0.000000  \n",
       "9         0.105265        0.148293         0.029463  \n",
       "10        0.134760        0.125660         0.000000  \n",
       "11        0.178141        0.141445         0.000000  \n",
       "12        0.062492        0.140859         0.000000  \n",
       "13        0.129146        0.078216         0.000000  \n",
       "14        0.148255        0.088622         0.000000  \n",
       "15        0.127753        0.030156         0.000000  \n",
       "16        0.042499        0.128586         0.000000  \n",
       "17        0.190157        0.178638         0.000000  \n",
       "18        0.056522        0.124004         0.027730  \n",
       "19        0.017359        0.294628         0.000000  \n",
       "20        0.036985        0.035215         0.000000  \n",
       "21        0.080595        0.208730         0.031427  \n",
       "22        0.117252        0.078216         0.000000  \n",
       "23        0.102938        0.088622         0.000000  \n",
       "24        0.096083        0.087211         0.000000  \n",
       "25        0.132262        0.140859         0.000000  \n",
       "26        0.356417        0.090468         0.000000  \n",
       "27        0.565644        0.125660         0.000000  \n",
       "28        0.098096        0.140859         0.000000  \n",
       "29        0.111392        0.191373         0.000000  \n",
       "..             ...             ...              ...  \n",
       "66        0.064580        0.070430         0.000000  \n",
       "67        0.027709        0.088622         0.000000  \n",
       "68        0.013070        0.070430         0.000000  \n",
       "69        0.030904        0.125660         0.000000  \n",
       "70        0.239084        0.030156         0.000000  \n",
       "71        0.222304        0.030156         0.000000  \n",
       "72        0.102557        0.090468         0.000000  \n",
       "73        0.077451        0.150781         0.000000  \n",
       "74        0.072553        0.150781         0.000000  \n",
       "75        0.053260        0.140859         0.000000  \n",
       "76        0.048374        0.150781         0.000000  \n",
       "77        0.033673        0.150781         0.000000  \n",
       "78        0.069146        0.150781         0.000000  \n",
       "79        0.048761        0.150781         0.000000  \n",
       "80        0.023275        0.035215         0.000000  \n",
       "81        0.046976        0.064293         0.000000  \n",
       "82        0.045288        0.070430         0.000000  \n",
       "83        0.086288        0.088622         0.000000  \n",
       "84        0.216211        0.070430         0.000000  \n",
       "85        0.259564        0.125660         0.000000  \n",
       "86        0.103754        0.030156         0.000000  \n",
       "87        0.114206        0.088622         0.000000  \n",
       "88        0.036627        0.035215         0.000000  \n",
       "89        0.068855        0.064293         0.000000  \n",
       "90        0.202105        0.070430         0.000000  \n",
       "91        0.041658        0.088622         0.000000  \n",
       "92        0.032945        0.070430         0.000000  \n",
       "93        0.138505        0.125660         0.000000  \n",
       "94        0.112514        0.030156         0.000000  \n",
       "95        0.840018        0.088622         0.000000  \n",
       "\n",
       "[96 rows x 21 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(estimator.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4XNWd//H3V73LsiWrWm7Ylg0uGGEbQ8DUgBNKgCRA\nQoAkj5dd2E12N9mQ/PIk+2y2QNpmE0gIoSahhAQMJJgaerNx7zJylyxZclG1us7vj7kiwqiMZkaa\nkefzep55NPfec+/96lr+zplzzz3HnHOIiEj0iAl3ACIiMrKU+EVEoowSv4hIlFHiFxGJMkr8IiJR\nRolfRCTKKPGLiEQZJX4RkSijxC8iEmXiwh1AX7Kzs92kSZPCHYaIyKixZs2aQ865HH/KRmTinzRp\nEqtXrw53GCIio4aZ7fW3rJp6RESijBK/iEiUUeIXEYkySvwiIlFGiV9EJMoo8YuIRBklfhGRKDNo\n4jezCWb2qpltNbMtZvY1b/1YM3vJzD7wfmb1s//FZlZmZuVmdluofwERERkafx7g6gT+1Tm31szS\ngTVm9hJwI/BX59ztXkK/DfhW7x3NLBa4C7gQqADeN7NnnHNbQ/lLiITSIyv3DXmf6xYWD0MkIsNj\n0Bq/c67KObfWe98IbAMKgcuBh7xiDwFX9LH7AqDcObfLOdcOPObtJyIiYTKkNn4zmwScCqwEcp1z\nVd6maiC3j10Kgf29liu8dX0de5mZrTaz1bW1tUMJS0REhsDvxG9macATwNedcw29tznnHOCCCcQ5\nd49zrtQ5V5qT49c4QyIiEgC/Er+ZxeNL+g875570Vh80s3xvez5Q08eulcCEXstF3joREQkTf3r1\nGHAfsM0599Nem54BbvDe3wA83cfu7wPTzGyymSUA13j7iYhImPhT4z8TuB44z8zWe6+lwO3AhWb2\nAXCBt4yZFZjZCgDnXCdwK/ACvpvCjzvntgzD7yEiIn4atDunc+4twPrZfH4f5Q8AS3strwBWBBqg\niIiElp7cFRGJMkr8IiJRRolfRCTKKPGLiEQZJX4RkSijxC8iEmWU+EVEoowSv4hIlFHiFxGJMkr8\nIiJRRolfRCTKKPGLiEQZJX4RkSijxC8iEmWU+EVEoowSv4hIlFHiFxGJMoPOwGVm9wOfBmqcc6d4\n6/4AzPCKjAHqnHPz+th3D9AIdAGdzrnSEMUtIiIBGjTxAw8CdwK/7VnhnPt8z3sz+wlQP8D+5zrn\nDgUaoIiIhJY/c+6+YWaT+tpmZgZ8DjgvtGGJiMhwCbaN/xPAQefcB/1sd8DLZrbGzJYNdCAzW2Zm\nq81sdW1tbZBhiYhIf4JN/NcCjw6w/Syv7f8S4BYzO7u/gs65e5xzpc650pycnCDDEhGR/gSc+M0s\nDrgS+EN/ZZxzld7PGmA5sCDQ84mISGgEU+O/ANjunKvoa6OZpZpZes974CJgcxDnExGREBg08ZvZ\no8C7wAwzqzCzr3ibruG4Zh4zKzCzFd5iLvCWmW0AVgHPOueeD13oIiISCH969Vzbz/ob+1h3AFjq\nvd8FzA0yPhERCTE9uSsiEmWU+EVEoowSv4hIlFHiFxGJMkr8IiJRRolfRCTKKPGLiEQZJX4RkSij\nxC8iEmWU+EVEoowSv4hIlFHiFxGJMkr8IiJRRolfRCTKKPGLiEQZJX4RkSjjzwxc95tZjZlt7rXu\n382s0szWe6+l/ex7sZmVmVm5md0WysBFRCQw/tT4HwQu7mP9/zrn5nmvFcdvNLNY4C7gEmAWcK2Z\nzQomWBERCd6gid859wZwJIBjLwDKnXO7nHPtwGPA5QEcR0REQiiYNv5/NLONXlNQVh/bC4H9vZYr\nvHUiIhJGgSb+XwFTgHlAFfCTYAMxs2VmttrMVtfW1gZ7OBER6UdAid85d9A51+Wc6wZ+g69Z53iV\nwIRey0Xeuv6OeY9zrtQ5V5qTkxNIWCIi4oeAEr+Z5fda/AywuY9i7wPTzGyymSUA1wDPBHI+EREJ\nnbjBCpjZo8ASINvMKoDvA0vMbB7ggD3A33llC4B7nXNLnXOdZnYr8AIQC9zvnNsyLL+FiIj4bdDE\n75y7to/V9/VT9gCwtNfyCuBjXT1FRCR89OSuiEiUUeIXEYkySvwiIlFGiV9EJMoo8YuIRBklfhGR\nKKPELyISZZT4RUSijBK/iEiUUeIXEYkySvwiIlFGiV9EJMoo8YuIRBklfhGRKKPELyISZZT4RUSi\njBK/iEiUGTTxm9n9ZlZjZpt7rfuRmW03s41mttzMxvSz7x4z22Rm681sdSgDFxGRwPhT438QuPi4\ndS8Bpzjn5gA7gG8PsP+5zrl5zrnSwEIUEZFQGjTxO+feAI4ct+5F51ynt/geUDQMsYmIyDAIRRv/\nl4Hn+tnmgJfNbI2ZLRvoIGa2zMxWm9nq2traEIQlIiJ9CSrxm9n/AzqBh/spcpZzbh5wCXCLmZ3d\n37Gcc/c450qdc6U5OTnBhCUiIgMIOPGb2Y3Ap4EvOOdcX2Wcc5XezxpgObAg0POJiEhoBJT4zexi\n4N+Ay5xzx/opk2pm6T3vgYuAzX2VFRGRkeNPd85HgXeBGWZWYWZfAe4E0oGXvK6ad3tlC8xshbdr\nLvCWmW0AVgHPOueeH5bfQkRE/BY3WAHn3LV9rL6vn7IHgKXe+13A3KCiExGRkNOTuyIiUUaJX0Qk\nyijxi4hEGSV+EZEoo8QvIhJllPhFRKKMEr+ISJRR4hcRiTJK/CIiUUaJX0Qkyijxi4hEGSV+EZEo\nM+ggbSICb35Qy6GmdmJjoCAzmdJJY8MdkkjAlPhFBlFV38Jzm6tJio+h28HKziNMHZ9GVkpCuEMT\nCYiaekQGsXLXEeJijG9cNIOvnz8NgNV7joQ5KpHAKfGLDKC1o4v1++uYUzSGlIQ4xqQkMD03ndV7\njtLV3eeMoyIRT4lfZADr99fR3tXNwsl/a9NfOHksjW2dbKtqCGNkIoHzZ+rF+82sxsw291o31sxe\nMrMPvJ9Z/ex7sZmVmVm5md0WysBFhptzjpW7D1MwJomirOQP10/PSyczOZ5Vau6RUcqfGv+DwMXH\nrbsN+KtzbhrwV2/5I8wsFrgLuASYBVxrZrOCilZkBO07coyDDW0snDwOM/twfYwZp0/KorymicNN\nbWGMUCQw/sy5+4aZTTpu9eXAEu/9Q8BrwLeOK7MAKPfm3sXMHvP22xpwtBL1Hlm5b8j7XLewOKBz\n7TjYhAGzCzM/tu3UCVm8vK2GsoONLE5LDOj4IuESaBt/rnOuyntfDeT2UaYQ2N9rucJb1yczW2Zm\nq81sdW1tbYBhiYTOviPN5GcmkRQf+7FtWakJZCTFse/IsTBEJhKcoG/uOuccEHT3BufcPc65Uudc\naU5OTrCHEwlKV7dj/5EWisel9lumeFyqEr+MSoEm/oNmlg/g/azpo0wlMKHXcpG3TiTiHWxopb2r\nm4ljU/otM3FsCnXHOmho6RjByESCF2jifwa4wXt/A/B0H2XeB6aZ2WQzSwCu8fYTiXh7vZp88bj+\nE3+x96GgWr+MNv5053wUeBeYYWYVZvYV4HbgQjP7ALjAW8bMCsxsBYBzrhO4FXgB2AY87pzbMjy/\nhkho7T3cTEZSHGOS4/stkz8mibgYU+KXUcefXj3X9rPp/D7KHgCW9lpeAawIODqRMNl35BjF41I/\n0o3zeHExMRSOSVbil1FHT+6KHKe+pYO6Yx0Dtu/3KB6XQmVdC60dXSMQmUhoKPGLHKenBl/sT+If\nm0JXt2PLgfrhDkskZJT4RY6z73Az8bFGwZjkQcv2fDis3Vs33GGJhIwSv8hx9h05RuGYZGJj+m/f\n75GeFM/Y1ATW7D06ApGJhIYSv0gv3d2Ogw1t5PtR2+9RkJnEtmqN1Cmjh2bgEull35FjtHd1k5+R\n5Pc+uZlJbNleQ3NbJ6mJ/v+XGslxh0R6U41fpJftXs09L9P/xJ+fkYRzsONg43CFJRJSSvwivWyt\nasSA3KHU+L2yZdVK/DI6KPGL9LK9qoHstETiY/3/r5GVmkBKQizblfhllFDiF+llW3XDkJp5wDcx\ny/Tc9A+biUQinRK/iKextYP9R1qGnPgBZuanU1bdiG+UcpHIpsQv4um5OTuUHj09ZuSmc/RYBzWN\nmopRIp8Sv4hna5Uv8QdS4y/JzwBQO7+MCkr8Ip7tVQ1kJMWROcBQzP0pyUv/8BgikU6JX8SzvbqR\nkvyMAYdi7s+YlARyMxLVpVNGBSV+EXxDNWyvamCmV3MPRElehpp6ZFQIOPGb2QwzW9/r1WBmXz+u\nzBIzq+9V5nvBhywSehVHW2hu72Km11YfiJK8dMprmujo6g5hZCKhF/BYPc65MmAegJnF4ptIfXkf\nRd90zn060POIjIStXtt8SX4GWw8E1k5fkp9Oe1c3ew41My038G8OIsMtVE095wM7nXN7Q3Q8kRG1\nvboBM5iemxbwMWbk+r4tbFNzj0S4UCX+a4BH+9m22Mw2mtlzZnZyfwcws2VmttrMVtfW1oYoLBH/\nbK9qZPK4VFISAh+wdur4VOJijDI9wSsRLujEb2YJwGXAH/vYvBYods7NAX4BPNXfcZxz9zjnSp1z\npTk5OcGGJTIk26obKMkPrnkmMS6WKTmp6tkjES8UNf5LgLXOuYPHb3DONTjnmrz3K4B4M8sOwTlF\nQqa5rZO9h48xMy/wG7s9ZuRlsK1KiV8iWygS/7X008xjZnnmdYo2swXe+Q6H4JwiIdPTBbMkiB49\nPUry0qmsa6GhtSPoY4kMl6ASv5mlAhcCT/Zad7OZ3ewtXg1sNrMNwM+Ba5xGsZII0zOqZkkQffh7\n9Bxjh5p7JIIFNfWic64ZGHfcurt7vb8TuDOYc4gMt+1VjaQnxlGU5f88u/3pPWZP6aSxQR9PZDjo\nyV2JetuqfDd2Axmq4XgFmUmkJ8VpbH6JaEr8EtWcc74xekJwYxfAzCjJS1fPHoloSvwS1SqOttDU\n1hnUUA3Hm5GXznZNyiIRTIlfotq2D4dqCN0QCyV5GTS2dnKgvjVkxxQJpaBu7srIemTlviHvc93C\n4mGI5MSxraoRM98MWqHS07OnrLqBwjHB3zAWCTXV+CWqbaqsZ/K4VFITQ1cHmu4lfj3IJZFKiV+i\nlnOO9fvrmDdhTEiPm5EUz8RxKWw5UB/S44qEihK/RK2q+lYONbUxN8SJH2B2YSYbK5T4JTIp8UvU\n2rC/DmBYEv+cokwqjrZwpLk95McWCZYSv0St9RV1xMcaM0PYo6fHKYWZgO8egkikUa8e+Zho6T20\nYX8ds/IzSIyLDfmxP0z8FXWcM13DjEtkUY1folJXt2NTRX3Ib+z2yEiKZ0p2qtr5JSIp8UtU2lnb\nRHN717C07/eYXZSpph6JSEr8EpXWD+ON3R6zCzOpqm+lplFP8EpkUeKXqLRhfx3pSXFMHpc6bOeY\nU+T7UNmsWr9EGN3clVFjZ20TL2ypZv3+OlITYrnqtCLyMwMbEmH9/jrmFo0hJib4oZj7c3JBBmaw\nsaKe80pyh+08IkOlGr+MCqt2H+Gi/32DNz+oJTcjkcbWTn752k7e+qB2yKNg1h1rZ3t1I6cWD18z\nD0BqYhwn5aSxSTd4JcIEVeM3sz1AI9AFdDrnSo/bbsD/AUuBY8CNzrm1wZxTok9zWyff+OMGCsYk\n8YWFE8lIiqeprZPl6ypZsbmapPjYIc129VpZLV3djvNKxg9j1D6zizJ5vayW7m43rN8uRIYiFDX+\nc51z845P+p5LgGneaxnwqxCcT6LM/zy3jf1Hj/Hjq+eSkRQPQFpiHF9YWMzk7FSe3VTF0SE8IfvS\n1oPkpCcyt2h4a/wAi6dmc7i5na1VmpFLIsdwN/VcDvzW+bwHjDGz/GE+p5xA3i4/xO/f28dXzpzM\nwikfmd6ZGDOunl8EwJ/WVtDtR5NPW2cXr++o5YKZ40ekBn729GwAXt9RO+znEvFXsInfAS+b2Roz\nW9bH9kJgf6/lCm/dx5jZMjNbbWara2v1n0R8fvbyDgrHJPONT87oc3tWagKfmp3P7kPNvLfr8KDH\ne2/XEZraOrlw1sjcbB2fnsTJBRm8Xqa/aYkcwSb+s5xz8/A16dxiZmcHeiDn3D3OuVLnXGlOjh5x\nF183yPf3HOWmMyeRFN//sAqnTcxi2vg0Xtp6kIbWjgGP+fLWgyTHx7J4anaow+3Xkhk5rNl3lPqW\ngWPrS7dzbD1Qz7aqBrq6NZWjhEZQid85V+n9rAGWAwuOK1IJTOi1XOStExnUg+/sISUhls+WThiw\nnJlx6dwCOrsdz2+u7recc46Xtx3k7OnZA36QhNo508fT1e14p/zQkPYrr2nil6+W8/uV+/jde3v5\n0QvbuevVcrr1ASBBCjjxm1mqmaX3vAcuAjYfV+wZ4Evmswiod85VBRytRI1DTW08s/4AV80vIjM5\nftDy2WmJnD0tm/X769h1qKnPMpsq66mqb+WCmSPbp35+8RjSk+KG1M7//p4j3P/2blo6uvhcaRHX\nL5pIbkYSP3qhjIfe3TNssUp0CKY7Zy6w3NdjkzjgEefc82Z2M4Bz7m5gBb6unOX4unPeFFy4Ei0e\nXbmP9q5ublg8ye99zpk+nvX763h63QH+YclUEnvV6p1z3P7cdtIS40Y88cfFxnDWSdm8VuZ75sD7\nP9Ov8pomnl5fyfTcNL64cCJxsb76WUleOq9sr+F/ntvO4qnZzMgL/XDSEh0CrvE753Y55+Z6r5Od\nc//lrb/bS/p4vXlucc5Ndc7Nds6tDlXgcuLq7Orm9yv3cvb0HE4an+b3fglxMXzm1CION7fxh9X7\nP9LL5/HV+3ln52G+vbSErNSE4Qh7QEtm5FDd0Mr26oHn4a1tbOORVXvJTkvkmtOLP0z64GvSuuPq\nOWQkxfG1x9bR1tk13GHLCUpP7krEeav8EAcb2rhuwcBt+305aXwan55TwPbqRlZsqqLbOQ42tPKf\nz25j4eSxXHt6eOYNOK8kl8S4GO55Y1e/Zdo6uvj9e3uJNeNLZ/R9Qzs7LZEfXT2X7dWN/GaAY4kM\nRIlfIs4TaysZkxLPuQE+WbtoyjgWTx3HOzsP892nNnPWHa/Q3tnNHVfNCdvTsznpidx45iSeWl/J\ntj4e5nLO8eS6Sg41tXHNgmLGDvCt5NyS8SyZkcOD7+yhtUO1fhk6JX6JKPUtHby4pZrL5hYENTPW\n0tn5XHlqIeeVjOeGMyZx3w2nMyl7+Ebi9Mc/nHMS6Ylx/OiFso9te3fXYTZV1nPRrFym5gzevPXV\ns6ZwqKmdZzYcGI5Q5QSn0Tklojy7sYq2zm6u8p7IDVSM2Yfj90TKtJCZKfHcvGQqP3y+jJXew2bd\nzvH6jlpe3nqQkrx0PuHnNI1nnjSOkrx07ntzN589rWjQG8YivanGLxHlibUVTBufxpyizHCHMixu\nWjyZ3IxEvnDvSh58ZzcPvbOHl7YeZHZRJtecXkyMnwnczPjKWZMpO9jIW0N8PkBEiV8ixu5DzazZ\ne5SrTuAabHJCLI//3Rl85azJ1DS2sau2mUvn5PP50gkkxA3tv+Nl8wrITkvk3jd3D1O0cqJSU49E\njCfXVhBj8JlT+xzO6YQxcVwq3146k+KxKXR1u4902RyKxLhYrltYzC9e+YCq+paAJ6WR6KMav0SE\n7m7Hk2srOWtaDrkZSeEOZ0SYWcBJv8dV8wtxDpav00go4j8l/lGsvqWDjq7ucIcREu/tPkxlXQtX\nzT+xa/uhNnFcKqUTs3hybeWQZyKT6KWmnlHGOcfuQ828vqOWD2qaSIqP4ZSCTBZNGUfBmNH7Vf9P\naypIT4zjkyfnhTuUUeeq04r49pOb2FRZ/+EE7yIDUY1/lHl5Ww33vrWbqvpWzi8Zz8y8DDZW1HP3\n6zv7HZws0jW3dfL85mo+NSd/REfNPFEsnZ1PQlwMT65Vc4/4R4l/FNlUWc+rZTXML87im5+cwfkz\nc/ls6QS+8ckZZKUm8Lt391JZ1zLscTjnONzURkt7aJ4afW5zNcfau7jqtOD67kerzOR4LpyVyzMb\nDtDeeWI0/cnwUlPPKLG9uoEn1lRQPDaFK+YVfOSmYFpiHF8+czK/fmMnD7y9m1uWnDQsA5HVt3Tw\n8taDfFDTSENrJ3ExxskFGSw6bkrEoXp01T4mjkuhdGJWiCKNPlfNL+TZjVW8VlbDRWouk0Goxj8K\ndHR1c8vDa0mMj+G6hcV99gTJTI7ny2dOprPbsXxd6G/0Hahr4VevlbOpsp7icalcNreA0klZlB1s\n5Ndv7OLeNwMbMGzV7iOs2XuUmxZPOmH77o+ET0zLITstQc094hfV+EeBx1btY2dtM9cvmkhGUv+T\nkmSnJXLJKXk8vf4Aq/ce5XRvyIJgldc08fuVe0mOj+Xmc6aSl/m37pYXn5zPn9bs5z+f3UZ1fSvf\nWTpzSAOh/fK1csalJvD5MI2aeaKIj43h8nmF/PbdPdQda2dMysgPPS2jhxJ/hGtq6+RnL3/Awslj\nKfFj4o3TJ41lU0U9KzZVMT03+Ik6DjW28fDKvWSlxHPj4skfmw0rIS6GaxYUU17TxL1v7aats5v/\nuPxkv2rvmyvrea2slm9+cgbJCbqpG6wr5xdy31u7+fPGKq5fNDHc4fjlkZX7hrxPpIy9NJoFM/Xi\nBDN71cy2mtkWM/taH2WWmFm9ma33Xt8LLtzo8+vXd3K4uZ3vLJ3pVzKNMeMzpxbS7RxPrw+uyaet\ns4vfr9xLbIxvfPj+pkCMMeP7l85i2dlT+N17e7nr1XK/jv+r13eSlhjHF0dJkop0s/IzKMlL58m1\nFeEORSJcMG38ncC/OudmAYuAW8xsVh/l3nTOzfNe/xHE+aLOwYZWfvPmLi6dW8DcCf73zx6XlsgF\nM3PZXt3IC1sOBnRu53z3Cmob27jm9GKyBmk6MDNuu7iEz5xayI9f3MFjqwauyb2/5wjPbarii4sm\n+jWnrgzOzLhyfiHr9tWxs3Z0du2VkRHM1ItVzrm13vtGYBugxy5D6Ddv7KK9s5tvXDR9yPsunppN\nXkYS//7MFpraOoe8/6o9R9hYUc+Fs3L9nv4wJsa446o5nD09h28v39Tv1/iaxlZueXgtxWNT+Idz\npw45NunfFfMKiTFYrpu8MoCQ9Ooxs0nAqcDKPjYvNrONZvacmZ0civNFg6PN7Tyyah+XzS1g4rih\nTyASG2NccWohBxtb+emLO4a078GGVp7dWMW08Wmc7ef48D0S4mK45/rTWDI9h+8s38S9b+76SHNT\nR1c3tz6yjobWDu6+/rQBb1bL0I3PSOIT03JYvq6S7m4N4SB9Czrxm1ka8ATwdefc8XPKrQWKnXNz\ngF8ATw1wnGVmttrMVtfW1gYb1qj34Dt7ONbexd8vOSngYxSPTeG6BcU8+M5u3vMm/hhMa0cXj72/\nj8T4WK4+rcjv8eF7S4qP5dfXl3LJKXn857PbWPrzt3j8/f385o1dfPrnb7Fq9xFuv3IOJXkZQz62\nDO7K+YVU1rWwcveRcIciESqoxG9m8fiS/sPOuSeP3+6ca3DONXnvVwDxZpbd17Gcc/c450qdc6U5\nOUOrZZ5omts6efCdPVwwM5cZfvTkGci3l85k0rhUvvbYOg43tQ1Y1jnHt5/cxMGGNj57WhHpQdTG\nE+Ji+MW1p3L7lbPp7nb82xMb+a8V20hOiOWnn5vLFSf40MvhdNGsPNIS43STV/oVcHdO83UxuQ/Y\n5pz7aT9l8oCDzjlnZgvwfdD4V/WMYo+u2kd9S0dI2r/TEuO487r5XPHLt/mXxzfwwI2n99vP/scv\nlrF8XSUXzsoNSVfQuFhfV8/Pnz6BdfvryEyO92s+WQlOckIsS2fn8ezGKv7j8lPUVVY+Jpga/5nA\n9cB5vbprLjWzm83sZq/M1cBmM9sA/By4xmns2AG1dXbxmzd3ccaUccwvDs0QBrMKMvjep2fx+o5a\nbntyI60dHx1jxznHg2/v5q5Xd3LtggksGWK7/mDMjPnFWUr6I+iq+UU0t3fxwpbqcIciESjgGr9z\n7i1gwAZg59ydwJ2BniMaPbm2koMNbfz4s3NDetwvLCympqGVn79SzvbqRn549RwmZKVQ29jG95/Z\nwus7ajm/ZDw/uPwUHl+tJoLR7vRJYynKSuaJtRVqVpOP0ZO7EaSzq5u7X9/JnKJMzjqpz1shATMz\n/uWiGZxSmMm/Pr6Bi3/25ofb0hLj+P6ls7h+0cSgZ4SSyBATY1x5aiF3vlrOvsPHKB6XEu6QJIIo\n8UeQFZur2Xv4GHd/cf6wDVh20cl5PPf1DN4pP8yRY+20d3bz+dMnRM10h9HkC4smcvfru7j7jZ38\n92dmhzsciSBK/BGiu9vxy1fLmZqTykWzhndY3aKsFD53umqAJ7rcjCSuLi3iT6sr+Nr50/ThLh/S\n9/oI8eymKrZXN3LLuScNaXRLkYHcfPZUOru7Ax42OxyOtXey42Ajr5XV8OzGA6zZe5Sq+hbNKRxC\nqvFHgI6ubn78YhkleelcPk834iR0iselcNncAh5euY9/GKYJekKltaOLN3bU8vbOQ3R0+ZJ8XIzR\n6T2BXDw2hUtO0SQzoaDEHwEeW7WPvYePcf+NpcSqti8h9vdLTuKp9Qf4xSvlfO/SvsZRDL/t1Q38\naU0Fx9q7mFOUyYJJYykYk0xCXAyHm9rZWdvEq2U1/PqNXRxsaOW/PjOb1ESlr0DpyoVZc1sn//fX\nchZMGsu5M8aHOxw5Ac3IS+eLi4p54J3dfGpOHqdNDM0EPaHgnOPNDw7xwpZq8jOTuGnxZAqzkj9S\nJic9kZz0ROYXZ/H6jlqe2XCA7dWN/OZLpUwYq3tVgVAbf5j94pVyDjW18a1LSjT1oAyb2y6ZSUFm\nMt/848cf4AuX1o4u/rSmgue3VHNKYSbLzp76saTfW0JcDBfOyuWBmxZwoK6FS+98izV7j45gxCcO\n1fjDaO2+o9zzxk4+XzqB0zTRuAyjtMQ4fnj1HL5w70p++HzZoE0+wz0zVk1DK8t+t4b1++u4YGYu\n587I8bvic870HJ659SxufGAVX7x3Jb/64nyW6NvykKjGHyYt7V184/EN5Gcm891Pzwx3OBIFzjwp\nmxvOmMiEOiRzAAAMaUlEQVT9b+/mpy+Wha2XzKaKei67823Kqhu5bkEx55WMH/K33UnZqfzx5sVM\nyUnlqw+t5un1mn9gKJT4w+T257ax61AzP7x6TlCjYIoMxfcuPZlrTp/Az18p5wd/2UZnV/eInv/P\nGw7w2V+/Q2yM8cTfL+aUwsyAj5WTnsijyxZx2sQsvv6H9Tz0zp7QBXqCU+IPg1+9tpOH3t3LTWdO\n4swQD80gMpDYGON/rpzNTWdO4v63d3PR/77B8nUVw/4BcKy9k39/Zgv/+Og6Zhdm8vStZzKrIPj5\nGDKS4nnoywu4YGYu339mCz99sUwT0PhBbfwj7Hfv7uGO57dz2dwCvvupyOxaJyc2M+N7n57Fwsnj\n+NnLO/jnP2zgu8s3c3JhJrPyMxibmkB5TRPJCbGkxMf6fibEkZoQS2L80IZ47um1892nNrPvyDFu\nOGMi3/nUTBLjQjdUdFJ8LL/6wny+s3wTP3+lnG3Vjfzkc3M1u9sAlPhHyLH2Tn70QhkPvO2bYOUn\nn5urPvsSNmbGxafkcdGsXP66vYa3PqhlfUU9f1pTMeAczWmJcYz3uleOz0hifHoi49MTSevVp767\n27H3yDHe3XmY3767h+3VjUwcl8JjyxaxaMq4Yfl94mJjuOMq36xu/71iG5ff+TY/+dzckA1tfqJR\n4g+BgXpAdHZ3s72qkRe2VHO4uZ1FU8bxiWnZxGsUTIkAMTHGhbNyuXBW7ofr2ju7eeDt3bS0d9HS\n0cWx9i5a2rtoauuktqmNmoZW1u+vo63zb81DSfEx3PVqOTExxtHmdprbfV1GS/LSueOq2Vw+r5Ck\nIX5bGCoz48tnTeaUwkz+6dF1XPnLd7j6tCL+7ZMzeHlbzZCPN5ReSqONEn8ItXd2c6y9k/qWDqob\nWqk82sKWAw20dHQxNjWBr541mSmajEQiXEJcDOlJ8QN2OnDO0djaSU1jGzWNrRxqaqMoK4XubkdG\ncjyz8jM4uTCDWfkZI/58yoLJY3n5X8/hzlfKue+tXTy1rpJpuemcOmEME8elqDMFSvx+6+zqZmdt\nM3sPN1NZ10LF0RYqj7ZwoL6FfYeP0dze+eH4Ij0S42KYnpvO/OIsThqfpqYdOWGYGRnJ8WQkx3PS\neF9lJpJqyGmJcdx2SQnXnD6BR1ft4+GV+9hW1QBARlIcmcnxJCfEkuB98+79P7enl+ubH9SSmRzP\nmJQEirKSmZqTxtScVHLSE0f9w5ZBJX4zuxj4PyAWuNc5d/tx283bvhQ4BtzonFsbzDlHQkt7F9ur\nG9hyoOdVz/bqRtqP+2pblJVCwZhkYs1ITfTd/EpNjCMtKY7cjCTGJMeP+j8QkdFsUnYq3146k6Ks\nFPYeaeZAXStVdS00tnXS3NbF0a6Oj0wj2PPf1TDau7qpb+mg7lj7Ryp16YlxTBmfxsy8dE4uyGBW\nQSYz89NJSRg99ehgJluPBe4CLgQqgPfN7Bnn3NZexS4BpnmvhcCvvJ9h55yjoaWT/UePUXG0hV2H\nmth6oIFtVQ3sPtRMT4+wjKQ4TinM5IYzJjKrIIMp2WkUZSUzNjXhw6QeyFOOIjJyYmOMKdlpTMn2\nv6m15xtMd7ejuqGVnbVN7KptZmdtE+U1TTy/pZrH3t8P+D4wJmencnJBJicXZDAlO5WirBQKs5LJ\nTI68pqVgPqIWAOXOuV0AZvYYcDnQO/FfDvzWm2D9PTMbY2b5zrmqIM7br0dW7qOts4vOLkdHd7fv\nZ1c3TW2dNLR00tDaQWNrB0ebO6isa/lY74WirGRm5Wdw6dwCZub72ieLspJVaxeJYjExRsGYZArG\nJPOJaTkfrnfOUVXf+mGrwJYDDazde5Q/bzjwkf3Tk+IoHJNMVkoC6UlxZCTHk54UR3piHHGxMcTF\nGvExvp9piXF8tnTCsP9OFuhj22Z2NXCxc+6r3vL1wELn3K29yvwFuN2bmB0z+yvwLefc6j6OtwxY\n5i3OAMoCCiw8soFD4Q5iFNB18o+u0+B0jT5uonMuZ/BiEXRz1zl3D3BPuOMIhJmtds6VhjuOSKfr\n5B9dp8HpGgUnmM7klUDv7yRF3rqhlhERkREUTOJ/H5hmZpPNLAG4BnjmuDLPAF8yn0VA/XC174uI\niH8CbupxznWa2a3AC/i6c97vnNtiZjd72+8GVuDrylmOrzvnTcGHHJFGZRNVGOg6+UfXaXC6RkEI\n+OauiIiMThowRkQkyijxi4hEGSX+ITCzi82szMzKzey2PrYvMbN6M1vvvb4XjjjDabBr5JVZ4l2f\nLWb2+kjHGAn8+Fv6Zq+/o81m1mVmY8MRazj5cZ0yzezPZrbB+3s6Ue8jhpZzTi8/XvhuYO8EpgAJ\nwAZg1nFllgB/CXesEX6NxuB7urvYWx4f7rgj8TodV/5S4JVwxx2J1wn4DnCH9z4HOAIkhDv2SH+p\nxu+/D4eocM61Az1DVMjf+HONrgOedM7tA3DODX2g9NFvqH9L1wKPjkhkkcWf6+SAdG9AyDR8ib//\nmWQEUFPPUBQC+3stV3jrjrfYzDaa2XNmdvLIhBYx/LlG04EsM3vNzNaY2ZdGLLrI4e/fEmaWAlwM\nPDECcUUaf67TncBM4ACwCfiac25kZ5AfhSJmyIYTxFp8TRhNZrYUeArfyKTyN3HAacD5QDLwrpm9\n55zbEd6wItalwNvOuSPhDiRCfRJYD5wHTAVeMrM3nXMN4Q0rsqnG779Bh59wzjU455q89yuAeDPL\nHrkQw86fIToqgBecc83OuUPAG8DcEYovUgxlKJNriM5mHvDvOt2Er+nQOefKgd1AyQjFN2op8ftv\n0CEqzCzPa2vEzBbgu76HRzzS8PFnGI+ngbPMLM5rxlgIbBvhOMPNn+uEmWUC5+C7ZtHIn+u0D9+3\nR8wsF9/IvrtGNMpRSE09fnL+DVFxNfD3ZtYJtADXOK+7QTTw5xo557aZ2fPARqAb38xtm8MX9cjz\n828J4DPAi8655jCFGlZ+XqcfAA+a2SbA8A37ruGaB6EhG0REooyaekREoowSv4hIlFHiFxGJMkr8\nIiJRRolfRCTKKPGL9GJmX/eeLwhk3yvMbFaoYxIJNSV+kY/6OhBQ4geuAEY08ZtZ7EieT04MSvwS\nMcxskpltN7MHzWyHmT1sZheY2dtm9oGZLTCzVDO738xWmdk6M7u8175vmtla77XYW7/EGxDuT96x\nH+55urqP8/8TUAC8amaveusuMrN3vWP+0czSvPW3m9lWb0C+H3vnuwz4kTeG/tT+ztFrv8e8dWlm\n9oCZbfLWX+Wtv9Zbt9nM7uh1jCYz+4mZbQDOMLPTzOx1b9C7F8wsP0T/JHKiCve40Hrp1fMCJuEb\nUnc2vkrJGuB+fE9kXo5v0Lv/Br7olR8D7ABS8dXSk7z104DV3vslQD2+cV5igHeBswaIYQ+Q7b3P\nxjeWUKq3/C3ge8A4oIy/PQA5xvv5IHD1IL/jASDxuP3uAH7Wq0wWvg+gffjGmI8DXgGu8LY74HPe\n+3jgHSDHW/48vidcw/7vqVfkvjRkg0Sa3c65TQBmtgX4q3POeY/kT8KXwC8zs2945ZOAYnwJ9U4z\nmwd04Rv+uccq51yFd8z13nHe8iOWRfiabt72viQk4PvgqAdagfvM7C/AX4bw+20EHjazp/B9kAFc\ngG8cGgCcc0fN7GzgNedcrRf3w8DZ3j5d/G2Y5hnAKfhGpQTf0AZVQ4hHopASv0Satl7vu3std+P7\ne+0CrnLOlfXeycz+HTiIb6TPGHyJua9jduH/370BLznnrv3YBt8gfOfjG5/pVnzDAvvjU/gS+KXA\n/zOz2X7u11urc66rV4xbnHNnBHAciVJq45fR5gXgH3uNgnqqtz4TqHK+STiux1fzDUQjkO69fw84\n08xO8s6VambTvXb+TOcbevuf+duw0r33/RgziwEmOOdexddslIlv1qiXgFt6lcsCVgHnmFm2dwP3\nWqCv+YnLgBwzO8PbN96ibwIgGSIlfhltfoCvXXuj1xT0A2/9L4EbvBueJUCgI1reAzxvZq96zSw3\nAo+a2UZ8zTwl+JL7X7x1bwH/4u37GPBN76ZzXzd3Y4Hfe81W64CfO+fqgP/ENyvZZi/+c51zVcBt\nwKv45ppd45z72PDMzjcl4dXAHd6+64HFAf7uEiU0OqeISJRRjV9EJMro5q5EJTNbDkw+bvW3nHMv\nhOj4dwFnHrf6/5xzD4Ti+CLBUFOPiEiUUVOPiEiUUeIXEYkySvwiIlFGiV9EJMoo8YuIRJn/D8RF\na/bBGxGdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b902a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(results['mean_test_score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__n_estimators': 10,\n",
       " 'reduce_dim': None,\n",
       " 'select_features__drt': 0.5,\n",
       " 'select_features__group': True,\n",
       " 'select_features__npeaks': 0.5}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83333333333333337"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>10936</th>\n",
       "      <th>10937</th>\n",
       "      <th>10938</th>\n",
       "      <th>10939</th>\n",
       "      <th>10940</th>\n",
       "      <th>10941</th>\n",
       "      <th>10942</th>\n",
       "      <th>10943</th>\n",
       "      <th>10944</th>\n",
       "      <th>10945</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20120829_07</th>\n",
       "      <td>4482.31</td>\n",
       "      <td>407.027</td>\n",
       "      <td>3671.02</td>\n",
       "      <td>6326.44</td>\n",
       "      <td>6176.96</td>\n",
       "      <td>533.566</td>\n",
       "      <td>18457.1</td>\n",
       "      <td>4475.88</td>\n",
       "      <td>1412.48</td>\n",
       "      <td>727.531</td>\n",
       "      <td>...</td>\n",
       "      <td>79918</td>\n",
       "      <td>5125.63</td>\n",
       "      <td>11959.2</td>\n",
       "      <td>25885</td>\n",
       "      <td>7409.45</td>\n",
       "      <td>6441.98</td>\n",
       "      <td>2778.57</td>\n",
       "      <td>2722.8</td>\n",
       "      <td>1438.29</td>\n",
       "      <td>425.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_08</th>\n",
       "      <td>2507.02</td>\n",
       "      <td>51.2232</td>\n",
       "      <td>3250.53</td>\n",
       "      <td>6517.23</td>\n",
       "      <td>4384.86</td>\n",
       "      <td>517.621</td>\n",
       "      <td>10634.7</td>\n",
       "      <td>6011.26</td>\n",
       "      <td>850.188</td>\n",
       "      <td>1016.01</td>\n",
       "      <td>...</td>\n",
       "      <td>123186</td>\n",
       "      <td>1565.6</td>\n",
       "      <td>11029.4</td>\n",
       "      <td>41771.9</td>\n",
       "      <td>7158.11</td>\n",
       "      <td>8263.18</td>\n",
       "      <td>2517.06</td>\n",
       "      <td>2331.97</td>\n",
       "      <td>2453.68</td>\n",
       "      <td>958.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_09</th>\n",
       "      <td>3298.28</td>\n",
       "      <td>4.20738</td>\n",
       "      <td>7994.55</td>\n",
       "      <td>9881.68</td>\n",
       "      <td>5931.93</td>\n",
       "      <td>483.42</td>\n",
       "      <td>14689.4</td>\n",
       "      <td>4546.74</td>\n",
       "      <td>874.314</td>\n",
       "      <td>942.373</td>\n",
       "      <td>...</td>\n",
       "      <td>75956.7</td>\n",
       "      <td>2721.17</td>\n",
       "      <td>10441.5</td>\n",
       "      <td>25155.9</td>\n",
       "      <td>6911.77</td>\n",
       "      <td>6635.63</td>\n",
       "      <td>2369.77</td>\n",
       "      <td>1620.75</td>\n",
       "      <td>2590.32</td>\n",
       "      <td>1443.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_100</th>\n",
       "      <td>1754.61</td>\n",
       "      <td>262.214</td>\n",
       "      <td>1704.33</td>\n",
       "      <td>7109.08</td>\n",
       "      <td>3797.1</td>\n",
       "      <td>439.296</td>\n",
       "      <td>8886.16</td>\n",
       "      <td>5029.88</td>\n",
       "      <td>456.016</td>\n",
       "      <td>1324.18</td>\n",
       "      <td>...</td>\n",
       "      <td>20406.6</td>\n",
       "      <td>489.11</td>\n",
       "      <td>274.326</td>\n",
       "      <td>6152.39</td>\n",
       "      <td>126.473</td>\n",
       "      <td>1370.22</td>\n",
       "      <td>55.4646</td>\n",
       "      <td>95.7112</td>\n",
       "      <td>146.4</td>\n",
       "      <td>48.0095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_101</th>\n",
       "      <td>1495.63</td>\n",
       "      <td>111.67</td>\n",
       "      <td>1964.83</td>\n",
       "      <td>6670.93</td>\n",
       "      <td>5255.66</td>\n",
       "      <td>285.331</td>\n",
       "      <td>8409.28</td>\n",
       "      <td>4028.25</td>\n",
       "      <td>342.784</td>\n",
       "      <td>1015.89</td>\n",
       "      <td>...</td>\n",
       "      <td>16385.9</td>\n",
       "      <td>69.7487</td>\n",
       "      <td>380.941</td>\n",
       "      <td>4010.65</td>\n",
       "      <td>117.559</td>\n",
       "      <td>901.018</td>\n",
       "      <td>69.905</td>\n",
       "      <td>58.6354</td>\n",
       "      <td>246.885</td>\n",
       "      <td>102.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_102</th>\n",
       "      <td>3020.06</td>\n",
       "      <td>157.998</td>\n",
       "      <td>1634.87</td>\n",
       "      <td>7136.84</td>\n",
       "      <td>5181.62</td>\n",
       "      <td>408.465</td>\n",
       "      <td>12003.4</td>\n",
       "      <td>5873.79</td>\n",
       "      <td>367.427</td>\n",
       "      <td>979.468</td>\n",
       "      <td>...</td>\n",
       "      <td>21281.1</td>\n",
       "      <td>132.173</td>\n",
       "      <td>387.814</td>\n",
       "      <td>5939.97</td>\n",
       "      <td>172.314</td>\n",
       "      <td>1177.66</td>\n",
       "      <td>41.3523</td>\n",
       "      <td>133.906</td>\n",
       "      <td>78.639</td>\n",
       "      <td>54.9892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_103</th>\n",
       "      <td>2481.63</td>\n",
       "      <td>63.1608</td>\n",
       "      <td>1228.99</td>\n",
       "      <td>7284.39</td>\n",
       "      <td>5255.64</td>\n",
       "      <td>383.222</td>\n",
       "      <td>11254.2</td>\n",
       "      <td>5130.25</td>\n",
       "      <td>407.389</td>\n",
       "      <td>1640.23</td>\n",
       "      <td>...</td>\n",
       "      <td>4637.41</td>\n",
       "      <td>42.7096</td>\n",
       "      <td>269.473</td>\n",
       "      <td>880.128</td>\n",
       "      <td>178.026</td>\n",
       "      <td>185.109</td>\n",
       "      <td>34.4602</td>\n",
       "      <td>73.4292</td>\n",
       "      <td>121.923</td>\n",
       "      <td>17.7994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_104</th>\n",
       "      <td>2558.77</td>\n",
       "      <td>105.553</td>\n",
       "      <td>1993.79</td>\n",
       "      <td>7162.73</td>\n",
       "      <td>6179.08</td>\n",
       "      <td>339.455</td>\n",
       "      <td>10711.1</td>\n",
       "      <td>5374.43</td>\n",
       "      <td>663.869</td>\n",
       "      <td>894.002</td>\n",
       "      <td>...</td>\n",
       "      <td>7253.53</td>\n",
       "      <td>112.544</td>\n",
       "      <td>287.321</td>\n",
       "      <td>2015.75</td>\n",
       "      <td>153.179</td>\n",
       "      <td>414.203</td>\n",
       "      <td>95.5041</td>\n",
       "      <td>47.2978</td>\n",
       "      <td>73.6355</td>\n",
       "      <td>75.7553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_105</th>\n",
       "      <td>2993.82</td>\n",
       "      <td>183.156</td>\n",
       "      <td>1004.28</td>\n",
       "      <td>7331.51</td>\n",
       "      <td>5880.73</td>\n",
       "      <td>423.792</td>\n",
       "      <td>12874.4</td>\n",
       "      <td>4714.81</td>\n",
       "      <td>845.356</td>\n",
       "      <td>797.323</td>\n",
       "      <td>...</td>\n",
       "      <td>197.192</td>\n",
       "      <td>47.4063</td>\n",
       "      <td>430.275</td>\n",
       "      <td>59.1959</td>\n",
       "      <td>105.233</td>\n",
       "      <td>13.4843</td>\n",
       "      <td>36.1623</td>\n",
       "      <td>76.7565</td>\n",
       "      <td>105.527</td>\n",
       "      <td>18.0521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_106</th>\n",
       "      <td>1404.82</td>\n",
       "      <td>228.641</td>\n",
       "      <td>1810.98</td>\n",
       "      <td>5909.65</td>\n",
       "      <td>6487.57</td>\n",
       "      <td>348.968</td>\n",
       "      <td>7678.22</td>\n",
       "      <td>4388.55</td>\n",
       "      <td>540.393</td>\n",
       "      <td>648.147</td>\n",
       "      <td>...</td>\n",
       "      <td>13952.8</td>\n",
       "      <td>307.061</td>\n",
       "      <td>150.343</td>\n",
       "      <td>4667.14</td>\n",
       "      <td>29.3562</td>\n",
       "      <td>834.821</td>\n",
       "      <td>24.3023</td>\n",
       "      <td>7.10606</td>\n",
       "      <td>93.4605</td>\n",
       "      <td>53.6453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_107</th>\n",
       "      <td>4008.43</td>\n",
       "      <td>106.47</td>\n",
       "      <td>1715.38</td>\n",
       "      <td>7326.67</td>\n",
       "      <td>7120.98</td>\n",
       "      <td>275.147</td>\n",
       "      <td>15688.4</td>\n",
       "      <td>3823.1</td>\n",
       "      <td>800.317</td>\n",
       "      <td>1030.42</td>\n",
       "      <td>...</td>\n",
       "      <td>3606.98</td>\n",
       "      <td>96.7879</td>\n",
       "      <td>260.307</td>\n",
       "      <td>586.708</td>\n",
       "      <td>150.627</td>\n",
       "      <td>128.129</td>\n",
       "      <td>88.3621</td>\n",
       "      <td>13.9516</td>\n",
       "      <td>33.7758</td>\n",
       "      <td>25.7216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_109</th>\n",
       "      <td>2733.94</td>\n",
       "      <td>39.4078</td>\n",
       "      <td>3718.75</td>\n",
       "      <td>6361.42</td>\n",
       "      <td>7057.72</td>\n",
       "      <td>288.068</td>\n",
       "      <td>12659.8</td>\n",
       "      <td>5234.99</td>\n",
       "      <td>515.029</td>\n",
       "      <td>815.48</td>\n",
       "      <td>...</td>\n",
       "      <td>56805.8</td>\n",
       "      <td>1289.25</td>\n",
       "      <td>9703.85</td>\n",
       "      <td>17704.5</td>\n",
       "      <td>6558.96</td>\n",
       "      <td>3651.28</td>\n",
       "      <td>1816.3</td>\n",
       "      <td>1798.78</td>\n",
       "      <td>2964.82</td>\n",
       "      <td>1752.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_10</th>\n",
       "      <td>2105.18</td>\n",
       "      <td>52.9066</td>\n",
       "      <td>2583.44</td>\n",
       "      <td>5775.38</td>\n",
       "      <td>7555.59</td>\n",
       "      <td>525.883</td>\n",
       "      <td>9785.9</td>\n",
       "      <td>4769.35</td>\n",
       "      <td>687.835</td>\n",
       "      <td>1010.49</td>\n",
       "      <td>...</td>\n",
       "      <td>133203</td>\n",
       "      <td>2598.01</td>\n",
       "      <td>10328.1</td>\n",
       "      <td>44603.4</td>\n",
       "      <td>7007.75</td>\n",
       "      <td>12706.2</td>\n",
       "      <td>2149.25</td>\n",
       "      <td>2625.79</td>\n",
       "      <td>1227.68</td>\n",
       "      <td>323.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_110</th>\n",
       "      <td>2385.86</td>\n",
       "      <td>128.018</td>\n",
       "      <td>2420.62</td>\n",
       "      <td>6856.07</td>\n",
       "      <td>7775.63</td>\n",
       "      <td>327.347</td>\n",
       "      <td>10373.1</td>\n",
       "      <td>8863.18</td>\n",
       "      <td>1038.35</td>\n",
       "      <td>728.182</td>\n",
       "      <td>...</td>\n",
       "      <td>115396</td>\n",
       "      <td>392.43</td>\n",
       "      <td>8701.29</td>\n",
       "      <td>34324.7</td>\n",
       "      <td>5778.81</td>\n",
       "      <td>8762.74</td>\n",
       "      <td>2050.35</td>\n",
       "      <td>1576.79</td>\n",
       "      <td>1918.35</td>\n",
       "      <td>855.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_111</th>\n",
       "      <td>1837.58</td>\n",
       "      <td>103.58</td>\n",
       "      <td>1050.07</td>\n",
       "      <td>6882.22</td>\n",
       "      <td>7434.01</td>\n",
       "      <td>304.898</td>\n",
       "      <td>8530.51</td>\n",
       "      <td>5793.77</td>\n",
       "      <td>458.336</td>\n",
       "      <td>898.996</td>\n",
       "      <td>...</td>\n",
       "      <td>49795.6</td>\n",
       "      <td>436.361</td>\n",
       "      <td>9189.91</td>\n",
       "      <td>14670.7</td>\n",
       "      <td>6347.59</td>\n",
       "      <td>2695.73</td>\n",
       "      <td>2114.55</td>\n",
       "      <td>1492.88</td>\n",
       "      <td>1862.48</td>\n",
       "      <td>1060.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_112</th>\n",
       "      <td>2114.06</td>\n",
       "      <td>124.581</td>\n",
       "      <td>3790.93</td>\n",
       "      <td>7360.61</td>\n",
       "      <td>7794.22</td>\n",
       "      <td>160.761</td>\n",
       "      <td>8408.48</td>\n",
       "      <td>3951.42</td>\n",
       "      <td>855.31</td>\n",
       "      <td>856.613</td>\n",
       "      <td>...</td>\n",
       "      <td>45326.6</td>\n",
       "      <td>336.166</td>\n",
       "      <td>9425.21</td>\n",
       "      <td>15156</td>\n",
       "      <td>5867.11</td>\n",
       "      <td>3372.02</td>\n",
       "      <td>1871.85</td>\n",
       "      <td>937.171</td>\n",
       "      <td>2792.38</td>\n",
       "      <td>1185.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_113</th>\n",
       "      <td>2848.74</td>\n",
       "      <td>109.893</td>\n",
       "      <td>1855.93</td>\n",
       "      <td>6971.62</td>\n",
       "      <td>7087.33</td>\n",
       "      <td>306.075</td>\n",
       "      <td>11028.2</td>\n",
       "      <td>4014.06</td>\n",
       "      <td>703.277</td>\n",
       "      <td>1054.39</td>\n",
       "      <td>...</td>\n",
       "      <td>127018</td>\n",
       "      <td>302.325</td>\n",
       "      <td>8426.15</td>\n",
       "      <td>40312.7</td>\n",
       "      <td>5615.71</td>\n",
       "      <td>9600.52</td>\n",
       "      <td>1875.68</td>\n",
       "      <td>1221.69</td>\n",
       "      <td>1761.6</td>\n",
       "      <td>949.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_114</th>\n",
       "      <td>1898.09</td>\n",
       "      <td>275.44</td>\n",
       "      <td>3129.57</td>\n",
       "      <td>7930.24</td>\n",
       "      <td>7174.47</td>\n",
       "      <td>242.863</td>\n",
       "      <td>9143.71</td>\n",
       "      <td>4906.68</td>\n",
       "      <td>1115.17</td>\n",
       "      <td>793.025</td>\n",
       "      <td>...</td>\n",
       "      <td>60898.1</td>\n",
       "      <td>184.582</td>\n",
       "      <td>14359.1</td>\n",
       "      <td>19392.1</td>\n",
       "      <td>8318.18</td>\n",
       "      <td>4035.2</td>\n",
       "      <td>2857.59</td>\n",
       "      <td>1505.53</td>\n",
       "      <td>2549.88</td>\n",
       "      <td>782.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_115</th>\n",
       "      <td>2182.05</td>\n",
       "      <td>302.67</td>\n",
       "      <td>1743.78</td>\n",
       "      <td>6705.51</td>\n",
       "      <td>7611.75</td>\n",
       "      <td>378.17</td>\n",
       "      <td>9257.68</td>\n",
       "      <td>4938.18</td>\n",
       "      <td>626.99</td>\n",
       "      <td>544.548</td>\n",
       "      <td>...</td>\n",
       "      <td>140811</td>\n",
       "      <td>330.384</td>\n",
       "      <td>14044.9</td>\n",
       "      <td>42807.4</td>\n",
       "      <td>7755.32</td>\n",
       "      <td>11219.5</td>\n",
       "      <td>2814.59</td>\n",
       "      <td>1560.46</td>\n",
       "      <td>1485.7</td>\n",
       "      <td>617.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_116</th>\n",
       "      <td>2029.71</td>\n",
       "      <td>95.8118</td>\n",
       "      <td>3966.61</td>\n",
       "      <td>5927.58</td>\n",
       "      <td>6606.8</td>\n",
       "      <td>348.189</td>\n",
       "      <td>8926.85</td>\n",
       "      <td>4102.3</td>\n",
       "      <td>778.95</td>\n",
       "      <td>601.233</td>\n",
       "      <td>...</td>\n",
       "      <td>171774</td>\n",
       "      <td>460.636</td>\n",
       "      <td>12523.8</td>\n",
       "      <td>54816.3</td>\n",
       "      <td>7925.49</td>\n",
       "      <td>12095.4</td>\n",
       "      <td>2351.61</td>\n",
       "      <td>2106.07</td>\n",
       "      <td>2687.53</td>\n",
       "      <td>981.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_117</th>\n",
       "      <td>4696.14</td>\n",
       "      <td>132.32</td>\n",
       "      <td>2511.9</td>\n",
       "      <td>7213.86</td>\n",
       "      <td>8186.46</td>\n",
       "      <td>484.247</td>\n",
       "      <td>20090.3</td>\n",
       "      <td>4494.1</td>\n",
       "      <td>557.213</td>\n",
       "      <td>908.025</td>\n",
       "      <td>...</td>\n",
       "      <td>114834</td>\n",
       "      <td>242.182</td>\n",
       "      <td>9726.09</td>\n",
       "      <td>36047.9</td>\n",
       "      <td>6264.38</td>\n",
       "      <td>8537.36</td>\n",
       "      <td>1928.08</td>\n",
       "      <td>1681.5</td>\n",
       "      <td>2003.83</td>\n",
       "      <td>672.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_118</th>\n",
       "      <td>2708.95</td>\n",
       "      <td>133.553</td>\n",
       "      <td>1231.3</td>\n",
       "      <td>6493.9</td>\n",
       "      <td>7220.77</td>\n",
       "      <td>199.444</td>\n",
       "      <td>13614.4</td>\n",
       "      <td>5191.94</td>\n",
       "      <td>1207.18</td>\n",
       "      <td>425.066</td>\n",
       "      <td>...</td>\n",
       "      <td>48562.8</td>\n",
       "      <td>341.211</td>\n",
       "      <td>10943.4</td>\n",
       "      <td>15423.9</td>\n",
       "      <td>7154.09</td>\n",
       "      <td>4306.02</td>\n",
       "      <td>2927.8</td>\n",
       "      <td>1091.92</td>\n",
       "      <td>2273.37</td>\n",
       "      <td>1139.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_11</th>\n",
       "      <td>3074.78</td>\n",
       "      <td>8.91342</td>\n",
       "      <td>6321.22</td>\n",
       "      <td>9048.24</td>\n",
       "      <td>9908.96</td>\n",
       "      <td>402.865</td>\n",
       "      <td>13325.8</td>\n",
       "      <td>5289.1</td>\n",
       "      <td>596.815</td>\n",
       "      <td>824.692</td>\n",
       "      <td>...</td>\n",
       "      <td>156272</td>\n",
       "      <td>1823.55</td>\n",
       "      <td>10832</td>\n",
       "      <td>52744.1</td>\n",
       "      <td>6807.71</td>\n",
       "      <td>12158.1</td>\n",
       "      <td>2053.01</td>\n",
       "      <td>1810.76</td>\n",
       "      <td>2424.66</td>\n",
       "      <td>860.607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_129</th>\n",
       "      <td>2405.93</td>\n",
       "      <td>1379.19</td>\n",
       "      <td>3413.82</td>\n",
       "      <td>9676.45</td>\n",
       "      <td>9488.83</td>\n",
       "      <td>664.142</td>\n",
       "      <td>11327.9</td>\n",
       "      <td>6521.06</td>\n",
       "      <td>960.039</td>\n",
       "      <td>1322.39</td>\n",
       "      <td>...</td>\n",
       "      <td>243150</td>\n",
       "      <td>934.043</td>\n",
       "      <td>4500.35</td>\n",
       "      <td>77536.7</td>\n",
       "      <td>2879.96</td>\n",
       "      <td>20878.3</td>\n",
       "      <td>710.941</td>\n",
       "      <td>1025.82</td>\n",
       "      <td>1049.04</td>\n",
       "      <td>464.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_12</th>\n",
       "      <td>1811.1</td>\n",
       "      <td>14.1081</td>\n",
       "      <td>5597.47</td>\n",
       "      <td>3923.93</td>\n",
       "      <td>7794.79</td>\n",
       "      <td>298.832</td>\n",
       "      <td>8534.05</td>\n",
       "      <td>5635.7</td>\n",
       "      <td>602.802</td>\n",
       "      <td>1374.78</td>\n",
       "      <td>...</td>\n",
       "      <td>50243.6</td>\n",
       "      <td>349.428</td>\n",
       "      <td>9150.22</td>\n",
       "      <td>15786.9</td>\n",
       "      <td>4658.59</td>\n",
       "      <td>3924.63</td>\n",
       "      <td>1905.82</td>\n",
       "      <td>1574.93</td>\n",
       "      <td>2113.7</td>\n",
       "      <td>753.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_130</th>\n",
       "      <td>3469.05</td>\n",
       "      <td>1137.49</td>\n",
       "      <td>6408.47</td>\n",
       "      <td>8747.64</td>\n",
       "      <td>7000.03</td>\n",
       "      <td>527.793</td>\n",
       "      <td>14170.1</td>\n",
       "      <td>6447.47</td>\n",
       "      <td>610.11</td>\n",
       "      <td>1201.2</td>\n",
       "      <td>...</td>\n",
       "      <td>128573</td>\n",
       "      <td>1823.68</td>\n",
       "      <td>4026.89</td>\n",
       "      <td>39243.5</td>\n",
       "      <td>2656.47</td>\n",
       "      <td>10757</td>\n",
       "      <td>596.611</td>\n",
       "      <td>727.169</td>\n",
       "      <td>1050.98</td>\n",
       "      <td>562.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_131</th>\n",
       "      <td>3289.47</td>\n",
       "      <td>122.444</td>\n",
       "      <td>4481.78</td>\n",
       "      <td>9115.63</td>\n",
       "      <td>7344.45</td>\n",
       "      <td>661.651</td>\n",
       "      <td>13936.4</td>\n",
       "      <td>4996.66</td>\n",
       "      <td>921.163</td>\n",
       "      <td>843.57</td>\n",
       "      <td>...</td>\n",
       "      <td>119036</td>\n",
       "      <td>552.139</td>\n",
       "      <td>4197.86</td>\n",
       "      <td>37128.8</td>\n",
       "      <td>2644.82</td>\n",
       "      <td>9285.53</td>\n",
       "      <td>738.681</td>\n",
       "      <td>788.029</td>\n",
       "      <td>895.66</td>\n",
       "      <td>410.558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_132</th>\n",
       "      <td>3067.61</td>\n",
       "      <td>214.814</td>\n",
       "      <td>6383.25</td>\n",
       "      <td>9678.73</td>\n",
       "      <td>7760.85</td>\n",
       "      <td>803.628</td>\n",
       "      <td>14282.4</td>\n",
       "      <td>5404.6</td>\n",
       "      <td>617.109</td>\n",
       "      <td>1381.94</td>\n",
       "      <td>...</td>\n",
       "      <td>107162</td>\n",
       "      <td>263.035</td>\n",
       "      <td>3960.09</td>\n",
       "      <td>33371.5</td>\n",
       "      <td>2235.4</td>\n",
       "      <td>7981.56</td>\n",
       "      <td>774.592</td>\n",
       "      <td>956.629</td>\n",
       "      <td>587.876</td>\n",
       "      <td>400.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_133</th>\n",
       "      <td>2900.6</td>\n",
       "      <td>175.075</td>\n",
       "      <td>4618.51</td>\n",
       "      <td>4355.05</td>\n",
       "      <td>8037.76</td>\n",
       "      <td>465.758</td>\n",
       "      <td>12823.1</td>\n",
       "      <td>5232.53</td>\n",
       "      <td>497.595</td>\n",
       "      <td>913.738</td>\n",
       "      <td>...</td>\n",
       "      <td>86166.3</td>\n",
       "      <td>568.655</td>\n",
       "      <td>3942.04</td>\n",
       "      <td>26795.1</td>\n",
       "      <td>2523.34</td>\n",
       "      <td>7223.63</td>\n",
       "      <td>511.758</td>\n",
       "      <td>851.452</td>\n",
       "      <td>742.501</td>\n",
       "      <td>287.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_134</th>\n",
       "      <td>2907.26</td>\n",
       "      <td>153.721</td>\n",
       "      <td>6654.36</td>\n",
       "      <td>18385</td>\n",
       "      <td>7801.67</td>\n",
       "      <td>773.927</td>\n",
       "      <td>11515.6</td>\n",
       "      <td>5335.28</td>\n",
       "      <td>773.344</td>\n",
       "      <td>1174.54</td>\n",
       "      <td>...</td>\n",
       "      <td>123160</td>\n",
       "      <td>461.179</td>\n",
       "      <td>3962.99</td>\n",
       "      <td>39104.5</td>\n",
       "      <td>2534.69</td>\n",
       "      <td>8754.56</td>\n",
       "      <td>468.496</td>\n",
       "      <td>968.78</td>\n",
       "      <td>698.933</td>\n",
       "      <td>365.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_67</th>\n",
       "      <td>3825.42</td>\n",
       "      <td>54.4622</td>\n",
       "      <td>7191.82</td>\n",
       "      <td>5355.77</td>\n",
       "      <td>5652.24</td>\n",
       "      <td>353.022</td>\n",
       "      <td>16995.9</td>\n",
       "      <td>4916.71</td>\n",
       "      <td>983.947</td>\n",
       "      <td>1119.69</td>\n",
       "      <td>...</td>\n",
       "      <td>42586.9</td>\n",
       "      <td>1168.7</td>\n",
       "      <td>1971.7</td>\n",
       "      <td>14116.3</td>\n",
       "      <td>1030.63</td>\n",
       "      <td>2565.21</td>\n",
       "      <td>359.118</td>\n",
       "      <td>251.366</td>\n",
       "      <td>312.098</td>\n",
       "      <td>161.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_68</th>\n",
       "      <td>2036.01</td>\n",
       "      <td>24.9666</td>\n",
       "      <td>3786.65</td>\n",
       "      <td>8608.78</td>\n",
       "      <td>6325.47</td>\n",
       "      <td>345.81</td>\n",
       "      <td>9718.7</td>\n",
       "      <td>4916.58</td>\n",
       "      <td>689.637</td>\n",
       "      <td>891.801</td>\n",
       "      <td>...</td>\n",
       "      <td>73773.5</td>\n",
       "      <td>788.88</td>\n",
       "      <td>2071.73</td>\n",
       "      <td>22937.9</td>\n",
       "      <td>1173.49</td>\n",
       "      <td>6034.15</td>\n",
       "      <td>327.052</td>\n",
       "      <td>464.706</td>\n",
       "      <td>303.122</td>\n",
       "      <td>52.1478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_69</th>\n",
       "      <td>3182.61</td>\n",
       "      <td>92.5538</td>\n",
       "      <td>5875.94</td>\n",
       "      <td>8456.74</td>\n",
       "      <td>6338.72</td>\n",
       "      <td>246.007</td>\n",
       "      <td>12744.5</td>\n",
       "      <td>3889.03</td>\n",
       "      <td>696.577</td>\n",
       "      <td>617.32</td>\n",
       "      <td>...</td>\n",
       "      <td>85955.9</td>\n",
       "      <td>805.909</td>\n",
       "      <td>2253.19</td>\n",
       "      <td>27083.2</td>\n",
       "      <td>868.478</td>\n",
       "      <td>6042.38</td>\n",
       "      <td>329.191</td>\n",
       "      <td>298.822</td>\n",
       "      <td>225.109</td>\n",
       "      <td>72.1657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_70</th>\n",
       "      <td>1308.21</td>\n",
       "      <td>47.859</td>\n",
       "      <td>3930.24</td>\n",
       "      <td>8502.85</td>\n",
       "      <td>6778.38</td>\n",
       "      <td>160.355</td>\n",
       "      <td>7271.95</td>\n",
       "      <td>7265.98</td>\n",
       "      <td>509.736</td>\n",
       "      <td>1399.81</td>\n",
       "      <td>...</td>\n",
       "      <td>21276.4</td>\n",
       "      <td>111.462</td>\n",
       "      <td>998.52</td>\n",
       "      <td>6677.61</td>\n",
       "      <td>803.434</td>\n",
       "      <td>1397.59</td>\n",
       "      <td>209.21</td>\n",
       "      <td>228.984</td>\n",
       "      <td>322.28</td>\n",
       "      <td>101.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_71</th>\n",
       "      <td>2317.68</td>\n",
       "      <td>86.6641</td>\n",
       "      <td>3841.08</td>\n",
       "      <td>9011.58</td>\n",
       "      <td>6347.07</td>\n",
       "      <td>472.853</td>\n",
       "      <td>10851.3</td>\n",
       "      <td>4532.84</td>\n",
       "      <td>1172.76</td>\n",
       "      <td>1371.92</td>\n",
       "      <td>...</td>\n",
       "      <td>109046</td>\n",
       "      <td>882.862</td>\n",
       "      <td>1905.56</td>\n",
       "      <td>35487.8</td>\n",
       "      <td>1229.79</td>\n",
       "      <td>8675.45</td>\n",
       "      <td>319.66</td>\n",
       "      <td>314.247</td>\n",
       "      <td>458.493</td>\n",
       "      <td>148.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_72</th>\n",
       "      <td>3278.12</td>\n",
       "      <td>260.492</td>\n",
       "      <td>4819.62</td>\n",
       "      <td>8860.17</td>\n",
       "      <td>6619.44</td>\n",
       "      <td>518.703</td>\n",
       "      <td>13198.1</td>\n",
       "      <td>5223.33</td>\n",
       "      <td>1075.87</td>\n",
       "      <td>1346.27</td>\n",
       "      <td>...</td>\n",
       "      <td>61045.1</td>\n",
       "      <td>991.77</td>\n",
       "      <td>1803.23</td>\n",
       "      <td>21011.9</td>\n",
       "      <td>1311.94</td>\n",
       "      <td>4474.39</td>\n",
       "      <td>342.444</td>\n",
       "      <td>233.415</td>\n",
       "      <td>405.382</td>\n",
       "      <td>163.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_73</th>\n",
       "      <td>3012.79</td>\n",
       "      <td>67.5964</td>\n",
       "      <td>4867.05</td>\n",
       "      <td>8295.81</td>\n",
       "      <td>6159.95</td>\n",
       "      <td>256.268</td>\n",
       "      <td>13243.6</td>\n",
       "      <td>7696.05</td>\n",
       "      <td>746.88</td>\n",
       "      <td>1158.92</td>\n",
       "      <td>...</td>\n",
       "      <td>49074.7</td>\n",
       "      <td>431.067</td>\n",
       "      <td>1967.69</td>\n",
       "      <td>15111.3</td>\n",
       "      <td>746.208</td>\n",
       "      <td>1848.56</td>\n",
       "      <td>231.741</td>\n",
       "      <td>267.607</td>\n",
       "      <td>354.975</td>\n",
       "      <td>62.0136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_74</th>\n",
       "      <td>4464.41</td>\n",
       "      <td>250.929</td>\n",
       "      <td>3471.82</td>\n",
       "      <td>3687.27</td>\n",
       "      <td>6685.51</td>\n",
       "      <td>459.163</td>\n",
       "      <td>17008.2</td>\n",
       "      <td>3851.88</td>\n",
       "      <td>1203.79</td>\n",
       "      <td>840.319</td>\n",
       "      <td>...</td>\n",
       "      <td>25074.3</td>\n",
       "      <td>2428.21</td>\n",
       "      <td>917.032</td>\n",
       "      <td>7205.48</td>\n",
       "      <td>687.764</td>\n",
       "      <td>1666.7</td>\n",
       "      <td>248.481</td>\n",
       "      <td>263.697</td>\n",
       "      <td>412.789</td>\n",
       "      <td>141.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_76</th>\n",
       "      <td>3383.34</td>\n",
       "      <td>413.843</td>\n",
       "      <td>4322.48</td>\n",
       "      <td>3322.19</td>\n",
       "      <td>5335.26</td>\n",
       "      <td>437.078</td>\n",
       "      <td>13707</td>\n",
       "      <td>3778.34</td>\n",
       "      <td>595.611</td>\n",
       "      <td>676.603</td>\n",
       "      <td>...</td>\n",
       "      <td>45560.6</td>\n",
       "      <td>288.124</td>\n",
       "      <td>1281.7</td>\n",
       "      <td>14369.3</td>\n",
       "      <td>749.219</td>\n",
       "      <td>2757.12</td>\n",
       "      <td>221.447</td>\n",
       "      <td>336.139</td>\n",
       "      <td>9.91248</td>\n",
       "      <td>75.8089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_77</th>\n",
       "      <td>1987.85</td>\n",
       "      <td>128.422</td>\n",
       "      <td>3213.83</td>\n",
       "      <td>8032.26</td>\n",
       "      <td>6975.67</td>\n",
       "      <td>333.028</td>\n",
       "      <td>9799.54</td>\n",
       "      <td>4927.06</td>\n",
       "      <td>956.94</td>\n",
       "      <td>1022.27</td>\n",
       "      <td>...</td>\n",
       "      <td>88513.2</td>\n",
       "      <td>150.899</td>\n",
       "      <td>1853.76</td>\n",
       "      <td>26473.5</td>\n",
       "      <td>1194.29</td>\n",
       "      <td>6161.67</td>\n",
       "      <td>418.462</td>\n",
       "      <td>296.067</td>\n",
       "      <td>290.33</td>\n",
       "      <td>135.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_78</th>\n",
       "      <td>2589.47</td>\n",
       "      <td>210.728</td>\n",
       "      <td>4130.74</td>\n",
       "      <td>7540.78</td>\n",
       "      <td>11619</td>\n",
       "      <td>560.11</td>\n",
       "      <td>11991.6</td>\n",
       "      <td>3355.99</td>\n",
       "      <td>969.147</td>\n",
       "      <td>696.589</td>\n",
       "      <td>...</td>\n",
       "      <td>51701.1</td>\n",
       "      <td>175.161</td>\n",
       "      <td>1054.96</td>\n",
       "      <td>16748.4</td>\n",
       "      <td>582.806</td>\n",
       "      <td>3058.85</td>\n",
       "      <td>232.58</td>\n",
       "      <td>267.267</td>\n",
       "      <td>293.649</td>\n",
       "      <td>131.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_79</th>\n",
       "      <td>2416.14</td>\n",
       "      <td>155.106</td>\n",
       "      <td>3366.65</td>\n",
       "      <td>7865.67</td>\n",
       "      <td>10591.3</td>\n",
       "      <td>318.491</td>\n",
       "      <td>12697.9</td>\n",
       "      <td>3910.14</td>\n",
       "      <td>802.561</td>\n",
       "      <td>706.877</td>\n",
       "      <td>...</td>\n",
       "      <td>56625.4</td>\n",
       "      <td>94.8521</td>\n",
       "      <td>850.812</td>\n",
       "      <td>16491.6</td>\n",
       "      <td>309.71</td>\n",
       "      <td>2898.08</td>\n",
       "      <td>249.83</td>\n",
       "      <td>316.516</td>\n",
       "      <td>207.311</td>\n",
       "      <td>70.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_80</th>\n",
       "      <td>2115.55</td>\n",
       "      <td>65.4289</td>\n",
       "      <td>2863.58</td>\n",
       "      <td>4865.34</td>\n",
       "      <td>8857.72</td>\n",
       "      <td>231.491</td>\n",
       "      <td>10495.7</td>\n",
       "      <td>4169.62</td>\n",
       "      <td>649.874</td>\n",
       "      <td>717.034</td>\n",
       "      <td>...</td>\n",
       "      <td>45767.2</td>\n",
       "      <td>300.071</td>\n",
       "      <td>1146.34</td>\n",
       "      <td>14252.4</td>\n",
       "      <td>555.856</td>\n",
       "      <td>2822.94</td>\n",
       "      <td>228.544</td>\n",
       "      <td>385.451</td>\n",
       "      <td>321.397</td>\n",
       "      <td>80.5437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_81</th>\n",
       "      <td>2719.57</td>\n",
       "      <td>194.7</td>\n",
       "      <td>4092.68</td>\n",
       "      <td>7097.99</td>\n",
       "      <td>6158.04</td>\n",
       "      <td>484.304</td>\n",
       "      <td>10651.9</td>\n",
       "      <td>5480.14</td>\n",
       "      <td>658.224</td>\n",
       "      <td>1220.78</td>\n",
       "      <td>...</td>\n",
       "      <td>41804.1</td>\n",
       "      <td>153.625</td>\n",
       "      <td>922.506</td>\n",
       "      <td>11997.6</td>\n",
       "      <td>602.413</td>\n",
       "      <td>2306.35</td>\n",
       "      <td>240.402</td>\n",
       "      <td>245.786</td>\n",
       "      <td>156.712</td>\n",
       "      <td>75.1529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_82</th>\n",
       "      <td>1971.27</td>\n",
       "      <td>183.489</td>\n",
       "      <td>3497.57</td>\n",
       "      <td>7680.33</td>\n",
       "      <td>7483.61</td>\n",
       "      <td>315.851</td>\n",
       "      <td>10382.8</td>\n",
       "      <td>5214.24</td>\n",
       "      <td>840.03</td>\n",
       "      <td>829.889</td>\n",
       "      <td>...</td>\n",
       "      <td>52928.3</td>\n",
       "      <td>352.417</td>\n",
       "      <td>741.862</td>\n",
       "      <td>17066</td>\n",
       "      <td>470.059</td>\n",
       "      <td>3718.5</td>\n",
       "      <td>245.099</td>\n",
       "      <td>211.495</td>\n",
       "      <td>367.882</td>\n",
       "      <td>271.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_83</th>\n",
       "      <td>2127.18</td>\n",
       "      <td>171.096</td>\n",
       "      <td>3728.93</td>\n",
       "      <td>6786.28</td>\n",
       "      <td>5775.55</td>\n",
       "      <td>262.955</td>\n",
       "      <td>10774.5</td>\n",
       "      <td>4644.66</td>\n",
       "      <td>775.908</td>\n",
       "      <td>1331.52</td>\n",
       "      <td>...</td>\n",
       "      <td>53748</td>\n",
       "      <td>134.243</td>\n",
       "      <td>1421.6</td>\n",
       "      <td>16519.9</td>\n",
       "      <td>629.323</td>\n",
       "      <td>4848.86</td>\n",
       "      <td>147.687</td>\n",
       "      <td>164.13</td>\n",
       "      <td>501.977</td>\n",
       "      <td>239.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_84</th>\n",
       "      <td>2778.39</td>\n",
       "      <td>70.1358</td>\n",
       "      <td>2801.49</td>\n",
       "      <td>7541.39</td>\n",
       "      <td>7483.85</td>\n",
       "      <td>354.231</td>\n",
       "      <td>13090</td>\n",
       "      <td>4775.79</td>\n",
       "      <td>835.021</td>\n",
       "      <td>846.227</td>\n",
       "      <td>...</td>\n",
       "      <td>52817.7</td>\n",
       "      <td>151.047</td>\n",
       "      <td>632.627</td>\n",
       "      <td>17152.8</td>\n",
       "      <td>236.814</td>\n",
       "      <td>4016.71</td>\n",
       "      <td>136.528</td>\n",
       "      <td>151.568</td>\n",
       "      <td>229.545</td>\n",
       "      <td>184.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_85</th>\n",
       "      <td>2787.18</td>\n",
       "      <td>805.902</td>\n",
       "      <td>3032.74</td>\n",
       "      <td>4532.21</td>\n",
       "      <td>6343.29</td>\n",
       "      <td>310.414</td>\n",
       "      <td>11403.1</td>\n",
       "      <td>5003.86</td>\n",
       "      <td>810.424</td>\n",
       "      <td>1209.67</td>\n",
       "      <td>...</td>\n",
       "      <td>53492.3</td>\n",
       "      <td>314.08</td>\n",
       "      <td>823.272</td>\n",
       "      <td>16891</td>\n",
       "      <td>344.211</td>\n",
       "      <td>3811.52</td>\n",
       "      <td>205.12</td>\n",
       "      <td>203.096</td>\n",
       "      <td>344.653</td>\n",
       "      <td>224.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_87</th>\n",
       "      <td>2500.09</td>\n",
       "      <td>75.4022</td>\n",
       "      <td>2334.27</td>\n",
       "      <td>6769.51</td>\n",
       "      <td>5285.59</td>\n",
       "      <td>185.86</td>\n",
       "      <td>12388.6</td>\n",
       "      <td>8103.48</td>\n",
       "      <td>813.76</td>\n",
       "      <td>1162.5</td>\n",
       "      <td>...</td>\n",
       "      <td>43348.4</td>\n",
       "      <td>122.935</td>\n",
       "      <td>636.421</td>\n",
       "      <td>14456.2</td>\n",
       "      <td>329.272</td>\n",
       "      <td>2288.87</td>\n",
       "      <td>126.354</td>\n",
       "      <td>259.906</td>\n",
       "      <td>265.839</td>\n",
       "      <td>96.0507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_88</th>\n",
       "      <td>2573.71</td>\n",
       "      <td>215.801</td>\n",
       "      <td>2602.17</td>\n",
       "      <td>7470.65</td>\n",
       "      <td>7185.44</td>\n",
       "      <td>240.991</td>\n",
       "      <td>10676.6</td>\n",
       "      <td>3127.64</td>\n",
       "      <td>599.814</td>\n",
       "      <td>647.405</td>\n",
       "      <td>...</td>\n",
       "      <td>38619.2</td>\n",
       "      <td>914.848</td>\n",
       "      <td>907.702</td>\n",
       "      <td>11296.7</td>\n",
       "      <td>386.961</td>\n",
       "      <td>2393.2</td>\n",
       "      <td>204.162</td>\n",
       "      <td>199.388</td>\n",
       "      <td>324.48</td>\n",
       "      <td>171.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_89</th>\n",
       "      <td>2117.58</td>\n",
       "      <td>86.493</td>\n",
       "      <td>2718.91</td>\n",
       "      <td>7336.01</td>\n",
       "      <td>6808.53</td>\n",
       "      <td>427.314</td>\n",
       "      <td>11067.6</td>\n",
       "      <td>5550.29</td>\n",
       "      <td>680.482</td>\n",
       "      <td>748.623</td>\n",
       "      <td>...</td>\n",
       "      <td>56531.8</td>\n",
       "      <td>478.651</td>\n",
       "      <td>560.067</td>\n",
       "      <td>17429.5</td>\n",
       "      <td>259.62</td>\n",
       "      <td>3810.83</td>\n",
       "      <td>127.995</td>\n",
       "      <td>163.644</td>\n",
       "      <td>220.636</td>\n",
       "      <td>93.3728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_90</th>\n",
       "      <td>1956.91</td>\n",
       "      <td>86.9824</td>\n",
       "      <td>1563.94</td>\n",
       "      <td>7195.44</td>\n",
       "      <td>5737.31</td>\n",
       "      <td>316.325</td>\n",
       "      <td>10009.8</td>\n",
       "      <td>4605.5</td>\n",
       "      <td>455.597</td>\n",
       "      <td>1412.3</td>\n",
       "      <td>...</td>\n",
       "      <td>53327.5</td>\n",
       "      <td>108.457</td>\n",
       "      <td>520.154</td>\n",
       "      <td>16910.1</td>\n",
       "      <td>259.955</td>\n",
       "      <td>3493.01</td>\n",
       "      <td>35.4448</td>\n",
       "      <td>91.6681</td>\n",
       "      <td>160.078</td>\n",
       "      <td>123.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_91</th>\n",
       "      <td>2326.96</td>\n",
       "      <td>49.2269</td>\n",
       "      <td>3426.89</td>\n",
       "      <td>6682.68</td>\n",
       "      <td>6007.64</td>\n",
       "      <td>453.58</td>\n",
       "      <td>10674.8</td>\n",
       "      <td>2876.16</td>\n",
       "      <td>408.128</td>\n",
       "      <td>1210.64</td>\n",
       "      <td>...</td>\n",
       "      <td>26556.9</td>\n",
       "      <td>90.4107</td>\n",
       "      <td>658.044</td>\n",
       "      <td>6886.5</td>\n",
       "      <td>347.062</td>\n",
       "      <td>1404.95</td>\n",
       "      <td>131.933</td>\n",
       "      <td>115.187</td>\n",
       "      <td>297.185</td>\n",
       "      <td>137.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_92</th>\n",
       "      <td>1329.61</td>\n",
       "      <td>722.733</td>\n",
       "      <td>1499.96</td>\n",
       "      <td>7682.48</td>\n",
       "      <td>5615.78</td>\n",
       "      <td>197.848</td>\n",
       "      <td>9915.28</td>\n",
       "      <td>4329.26</td>\n",
       "      <td>695.296</td>\n",
       "      <td>583.739</td>\n",
       "      <td>...</td>\n",
       "      <td>39236.7</td>\n",
       "      <td>203.187</td>\n",
       "      <td>483.683</td>\n",
       "      <td>11167.8</td>\n",
       "      <td>250.203</td>\n",
       "      <td>2121.84</td>\n",
       "      <td>99.5772</td>\n",
       "      <td>78.1666</td>\n",
       "      <td>343.101</td>\n",
       "      <td>122.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_93</th>\n",
       "      <td>2071.44</td>\n",
       "      <td>164.161</td>\n",
       "      <td>1646.63</td>\n",
       "      <td>6253.67</td>\n",
       "      <td>11311.5</td>\n",
       "      <td>279.136</td>\n",
       "      <td>8477.06</td>\n",
       "      <td>4925.97</td>\n",
       "      <td>390.618</td>\n",
       "      <td>597.627</td>\n",
       "      <td>...</td>\n",
       "      <td>39035.2</td>\n",
       "      <td>70.6129</td>\n",
       "      <td>396.382</td>\n",
       "      <td>11555.2</td>\n",
       "      <td>245.292</td>\n",
       "      <td>2020.08</td>\n",
       "      <td>29.5373</td>\n",
       "      <td>351.442</td>\n",
       "      <td>79.6669</td>\n",
       "      <td>84.2954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_94</th>\n",
       "      <td>2605.05</td>\n",
       "      <td>203.135</td>\n",
       "      <td>1602.42</td>\n",
       "      <td>7176.16</td>\n",
       "      <td>5942.71</td>\n",
       "      <td>340.721</td>\n",
       "      <td>11753</td>\n",
       "      <td>4095.21</td>\n",
       "      <td>624.688</td>\n",
       "      <td>872.543</td>\n",
       "      <td>...</td>\n",
       "      <td>1974.02</td>\n",
       "      <td>173.1</td>\n",
       "      <td>335.993</td>\n",
       "      <td>511.999</td>\n",
       "      <td>183.919</td>\n",
       "      <td>158.847</td>\n",
       "      <td>93.4877</td>\n",
       "      <td>151.353</td>\n",
       "      <td>185.731</td>\n",
       "      <td>50.0337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_95</th>\n",
       "      <td>4297.3</td>\n",
       "      <td>36.0322</td>\n",
       "      <td>1832.89</td>\n",
       "      <td>6840.88</td>\n",
       "      <td>5210.2</td>\n",
       "      <td>237.778</td>\n",
       "      <td>17760.8</td>\n",
       "      <td>3594.7</td>\n",
       "      <td>714.518</td>\n",
       "      <td>779.276</td>\n",
       "      <td>...</td>\n",
       "      <td>22648</td>\n",
       "      <td>94.6371</td>\n",
       "      <td>337.782</td>\n",
       "      <td>6822.84</td>\n",
       "      <td>184.895</td>\n",
       "      <td>1147.42</td>\n",
       "      <td>91.8939</td>\n",
       "      <td>249.626</td>\n",
       "      <td>265.857</td>\n",
       "      <td>82.8023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_96</th>\n",
       "      <td>1724.85</td>\n",
       "      <td>177.65</td>\n",
       "      <td>2208.15</td>\n",
       "      <td>7009.32</td>\n",
       "      <td>6148.62</td>\n",
       "      <td>313.312</td>\n",
       "      <td>10382.9</td>\n",
       "      <td>4368.89</td>\n",
       "      <td>558.546</td>\n",
       "      <td>358.22</td>\n",
       "      <td>...</td>\n",
       "      <td>19176.3</td>\n",
       "      <td>111.872</td>\n",
       "      <td>287.846</td>\n",
       "      <td>5463.07</td>\n",
       "      <td>216.7</td>\n",
       "      <td>1126.03</td>\n",
       "      <td>75.8125</td>\n",
       "      <td>256.787</td>\n",
       "      <td>182.23</td>\n",
       "      <td>99.3942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_98</th>\n",
       "      <td>2556.04</td>\n",
       "      <td>60.8528</td>\n",
       "      <td>1775.98</td>\n",
       "      <td>7040.51</td>\n",
       "      <td>6240.4</td>\n",
       "      <td>197.898</td>\n",
       "      <td>9651.4</td>\n",
       "      <td>7691.35</td>\n",
       "      <td>460.584</td>\n",
       "      <td>1210.25</td>\n",
       "      <td>...</td>\n",
       "      <td>16600.6</td>\n",
       "      <td>94.3479</td>\n",
       "      <td>229.904</td>\n",
       "      <td>5245.15</td>\n",
       "      <td>108.335</td>\n",
       "      <td>969.107</td>\n",
       "      <td>64.3045</td>\n",
       "      <td>117.961</td>\n",
       "      <td>272.119</td>\n",
       "      <td>68.3559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_99</th>\n",
       "      <td>2863.34</td>\n",
       "      <td>120.6</td>\n",
       "      <td>2302.66</td>\n",
       "      <td>7368.24</td>\n",
       "      <td>4609.03</td>\n",
       "      <td>226.982</td>\n",
       "      <td>9882.64</td>\n",
       "      <td>4448.15</td>\n",
       "      <td>532.719</td>\n",
       "      <td>742.372</td>\n",
       "      <td>...</td>\n",
       "      <td>23810.4</td>\n",
       "      <td>206.352</td>\n",
       "      <td>360.028</td>\n",
       "      <td>7517.38</td>\n",
       "      <td>189.645</td>\n",
       "      <td>1050.1</td>\n",
       "      <td>75.4843</td>\n",
       "      <td>62.8886</td>\n",
       "      <td>283.698</td>\n",
       "      <td>71.1747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows  10946 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0        1        2        3        4        5        6  \\\n",
       "new_index                                                                     \n",
       "20120829_07   4482.31  407.027  3671.02  6326.44  6176.96  533.566  18457.1   \n",
       "20120829_08   2507.02  51.2232  3250.53  6517.23  4384.86  517.621  10634.7   \n",
       "20120829_09   3298.28  4.20738  7994.55  9881.68  5931.93   483.42  14689.4   \n",
       "20120829_100  1754.61  262.214  1704.33  7109.08   3797.1  439.296  8886.16   \n",
       "20120829_101  1495.63   111.67  1964.83  6670.93  5255.66  285.331  8409.28   \n",
       "20120829_102  3020.06  157.998  1634.87  7136.84  5181.62  408.465  12003.4   \n",
       "20120829_103  2481.63  63.1608  1228.99  7284.39  5255.64  383.222  11254.2   \n",
       "20120829_104  2558.77  105.553  1993.79  7162.73  6179.08  339.455  10711.1   \n",
       "20120829_105  2993.82  183.156  1004.28  7331.51  5880.73  423.792  12874.4   \n",
       "20120829_106  1404.82  228.641  1810.98  5909.65  6487.57  348.968  7678.22   \n",
       "20120829_107  4008.43   106.47  1715.38  7326.67  7120.98  275.147  15688.4   \n",
       "20120829_109  2733.94  39.4078  3718.75  6361.42  7057.72  288.068  12659.8   \n",
       "20120829_10   2105.18  52.9066  2583.44  5775.38  7555.59  525.883   9785.9   \n",
       "20120829_110  2385.86  128.018  2420.62  6856.07  7775.63  327.347  10373.1   \n",
       "20120829_111  1837.58   103.58  1050.07  6882.22  7434.01  304.898  8530.51   \n",
       "20120829_112  2114.06  124.581  3790.93  7360.61  7794.22  160.761  8408.48   \n",
       "20120829_113  2848.74  109.893  1855.93  6971.62  7087.33  306.075  11028.2   \n",
       "20120829_114  1898.09   275.44  3129.57  7930.24  7174.47  242.863  9143.71   \n",
       "20120829_115  2182.05   302.67  1743.78  6705.51  7611.75   378.17  9257.68   \n",
       "20120829_116  2029.71  95.8118  3966.61  5927.58   6606.8  348.189  8926.85   \n",
       "20120829_117  4696.14   132.32   2511.9  7213.86  8186.46  484.247  20090.3   \n",
       "20120829_118  2708.95  133.553   1231.3   6493.9  7220.77  199.444  13614.4   \n",
       "20120829_11   3074.78  8.91342  6321.22  9048.24  9908.96  402.865  13325.8   \n",
       "20120829_129  2405.93  1379.19  3413.82  9676.45  9488.83  664.142  11327.9   \n",
       "20120829_12    1811.1  14.1081  5597.47  3923.93  7794.79  298.832  8534.05   \n",
       "20120829_130  3469.05  1137.49  6408.47  8747.64  7000.03  527.793  14170.1   \n",
       "20120829_131  3289.47  122.444  4481.78  9115.63  7344.45  661.651  13936.4   \n",
       "20120829_132  3067.61  214.814  6383.25  9678.73  7760.85  803.628  14282.4   \n",
       "20120829_133   2900.6  175.075  4618.51  4355.05  8037.76  465.758  12823.1   \n",
       "20120829_134  2907.26  153.721  6654.36    18385  7801.67  773.927  11515.6   \n",
       "...               ...      ...      ...      ...      ...      ...      ...   \n",
       "20120829_67   3825.42  54.4622  7191.82  5355.77  5652.24  353.022  16995.9   \n",
       "20120829_68   2036.01  24.9666  3786.65  8608.78  6325.47   345.81   9718.7   \n",
       "20120829_69   3182.61  92.5538  5875.94  8456.74  6338.72  246.007  12744.5   \n",
       "20120829_70   1308.21   47.859  3930.24  8502.85  6778.38  160.355  7271.95   \n",
       "20120829_71   2317.68  86.6641  3841.08  9011.58  6347.07  472.853  10851.3   \n",
       "20120829_72   3278.12  260.492  4819.62  8860.17  6619.44  518.703  13198.1   \n",
       "20120829_73   3012.79  67.5964  4867.05  8295.81  6159.95  256.268  13243.6   \n",
       "20120829_74   4464.41  250.929  3471.82  3687.27  6685.51  459.163  17008.2   \n",
       "20120829_76   3383.34  413.843  4322.48  3322.19  5335.26  437.078    13707   \n",
       "20120829_77   1987.85  128.422  3213.83  8032.26  6975.67  333.028  9799.54   \n",
       "20120829_78   2589.47  210.728  4130.74  7540.78    11619   560.11  11991.6   \n",
       "20120829_79   2416.14  155.106  3366.65  7865.67  10591.3  318.491  12697.9   \n",
       "20120829_80   2115.55  65.4289  2863.58  4865.34  8857.72  231.491  10495.7   \n",
       "20120829_81   2719.57    194.7  4092.68  7097.99  6158.04  484.304  10651.9   \n",
       "20120829_82   1971.27  183.489  3497.57  7680.33  7483.61  315.851  10382.8   \n",
       "20120829_83   2127.18  171.096  3728.93  6786.28  5775.55  262.955  10774.5   \n",
       "20120829_84   2778.39  70.1358  2801.49  7541.39  7483.85  354.231    13090   \n",
       "20120829_85   2787.18  805.902  3032.74  4532.21  6343.29  310.414  11403.1   \n",
       "20120829_87   2500.09  75.4022  2334.27  6769.51  5285.59   185.86  12388.6   \n",
       "20120829_88   2573.71  215.801  2602.17  7470.65  7185.44  240.991  10676.6   \n",
       "20120829_89   2117.58   86.493  2718.91  7336.01  6808.53  427.314  11067.6   \n",
       "20120829_90   1956.91  86.9824  1563.94  7195.44  5737.31  316.325  10009.8   \n",
       "20120829_91   2326.96  49.2269  3426.89  6682.68  6007.64   453.58  10674.8   \n",
       "20120829_92   1329.61  722.733  1499.96  7682.48  5615.78  197.848  9915.28   \n",
       "20120829_93   2071.44  164.161  1646.63  6253.67  11311.5  279.136  8477.06   \n",
       "20120829_94   2605.05  203.135  1602.42  7176.16  5942.71  340.721    11753   \n",
       "20120829_95    4297.3  36.0322  1832.89  6840.88   5210.2  237.778  17760.8   \n",
       "20120829_96   1724.85   177.65  2208.15  7009.32  6148.62  313.312  10382.9   \n",
       "20120829_98   2556.04  60.8528  1775.98  7040.51   6240.4  197.898   9651.4   \n",
       "20120829_99   2863.34    120.6  2302.66  7368.24  4609.03  226.982  9882.64   \n",
       "\n",
       "                    7        8        9   ...       10936    10937    10938  \\\n",
       "new_index                                 ...                                 \n",
       "20120829_07   4475.88  1412.48  727.531   ...       79918  5125.63  11959.2   \n",
       "20120829_08   6011.26  850.188  1016.01   ...      123186   1565.6  11029.4   \n",
       "20120829_09   4546.74  874.314  942.373   ...     75956.7  2721.17  10441.5   \n",
       "20120829_100  5029.88  456.016  1324.18   ...     20406.6   489.11  274.326   \n",
       "20120829_101  4028.25  342.784  1015.89   ...     16385.9  69.7487  380.941   \n",
       "20120829_102  5873.79  367.427  979.468   ...     21281.1  132.173  387.814   \n",
       "20120829_103  5130.25  407.389  1640.23   ...     4637.41  42.7096  269.473   \n",
       "20120829_104  5374.43  663.869  894.002   ...     7253.53  112.544  287.321   \n",
       "20120829_105  4714.81  845.356  797.323   ...     197.192  47.4063  430.275   \n",
       "20120829_106  4388.55  540.393  648.147   ...     13952.8  307.061  150.343   \n",
       "20120829_107   3823.1  800.317  1030.42   ...     3606.98  96.7879  260.307   \n",
       "20120829_109  5234.99  515.029   815.48   ...     56805.8  1289.25  9703.85   \n",
       "20120829_10   4769.35  687.835  1010.49   ...      133203  2598.01  10328.1   \n",
       "20120829_110  8863.18  1038.35  728.182   ...      115396   392.43  8701.29   \n",
       "20120829_111  5793.77  458.336  898.996   ...     49795.6  436.361  9189.91   \n",
       "20120829_112  3951.42   855.31  856.613   ...     45326.6  336.166  9425.21   \n",
       "20120829_113  4014.06  703.277  1054.39   ...      127018  302.325  8426.15   \n",
       "20120829_114  4906.68  1115.17  793.025   ...     60898.1  184.582  14359.1   \n",
       "20120829_115  4938.18   626.99  544.548   ...      140811  330.384  14044.9   \n",
       "20120829_116   4102.3   778.95  601.233   ...      171774  460.636  12523.8   \n",
       "20120829_117   4494.1  557.213  908.025   ...      114834  242.182  9726.09   \n",
       "20120829_118  5191.94  1207.18  425.066   ...     48562.8  341.211  10943.4   \n",
       "20120829_11    5289.1  596.815  824.692   ...      156272  1823.55    10832   \n",
       "20120829_129  6521.06  960.039  1322.39   ...      243150  934.043  4500.35   \n",
       "20120829_12    5635.7  602.802  1374.78   ...     50243.6  349.428  9150.22   \n",
       "20120829_130  6447.47   610.11   1201.2   ...      128573  1823.68  4026.89   \n",
       "20120829_131  4996.66  921.163   843.57   ...      119036  552.139  4197.86   \n",
       "20120829_132   5404.6  617.109  1381.94   ...      107162  263.035  3960.09   \n",
       "20120829_133  5232.53  497.595  913.738   ...     86166.3  568.655  3942.04   \n",
       "20120829_134  5335.28  773.344  1174.54   ...      123160  461.179  3962.99   \n",
       "...               ...      ...      ...   ...         ...      ...      ...   \n",
       "20120829_67   4916.71  983.947  1119.69   ...     42586.9   1168.7   1971.7   \n",
       "20120829_68   4916.58  689.637  891.801   ...     73773.5   788.88  2071.73   \n",
       "20120829_69   3889.03  696.577   617.32   ...     85955.9  805.909  2253.19   \n",
       "20120829_70   7265.98  509.736  1399.81   ...     21276.4  111.462   998.52   \n",
       "20120829_71   4532.84  1172.76  1371.92   ...      109046  882.862  1905.56   \n",
       "20120829_72   5223.33  1075.87  1346.27   ...     61045.1   991.77  1803.23   \n",
       "20120829_73   7696.05   746.88  1158.92   ...     49074.7  431.067  1967.69   \n",
       "20120829_74   3851.88  1203.79  840.319   ...     25074.3  2428.21  917.032   \n",
       "20120829_76   3778.34  595.611  676.603   ...     45560.6  288.124   1281.7   \n",
       "20120829_77   4927.06   956.94  1022.27   ...     88513.2  150.899  1853.76   \n",
       "20120829_78   3355.99  969.147  696.589   ...     51701.1  175.161  1054.96   \n",
       "20120829_79   3910.14  802.561  706.877   ...     56625.4  94.8521  850.812   \n",
       "20120829_80   4169.62  649.874  717.034   ...     45767.2  300.071  1146.34   \n",
       "20120829_81   5480.14  658.224  1220.78   ...     41804.1  153.625  922.506   \n",
       "20120829_82   5214.24   840.03  829.889   ...     52928.3  352.417  741.862   \n",
       "20120829_83   4644.66  775.908  1331.52   ...       53748  134.243   1421.6   \n",
       "20120829_84   4775.79  835.021  846.227   ...     52817.7  151.047  632.627   \n",
       "20120829_85   5003.86  810.424  1209.67   ...     53492.3   314.08  823.272   \n",
       "20120829_87   8103.48   813.76   1162.5   ...     43348.4  122.935  636.421   \n",
       "20120829_88   3127.64  599.814  647.405   ...     38619.2  914.848  907.702   \n",
       "20120829_89   5550.29  680.482  748.623   ...     56531.8  478.651  560.067   \n",
       "20120829_90    4605.5  455.597   1412.3   ...     53327.5  108.457  520.154   \n",
       "20120829_91   2876.16  408.128  1210.64   ...     26556.9  90.4107  658.044   \n",
       "20120829_92   4329.26  695.296  583.739   ...     39236.7  203.187  483.683   \n",
       "20120829_93   4925.97  390.618  597.627   ...     39035.2  70.6129  396.382   \n",
       "20120829_94   4095.21  624.688  872.543   ...     1974.02    173.1  335.993   \n",
       "20120829_95    3594.7  714.518  779.276   ...       22648  94.6371  337.782   \n",
       "20120829_96   4368.89  558.546   358.22   ...     19176.3  111.872  287.846   \n",
       "20120829_98   7691.35  460.584  1210.25   ...     16600.6  94.3479  229.904   \n",
       "20120829_99   4448.15  532.719  742.372   ...     23810.4  206.352  360.028   \n",
       "\n",
       "                10939    10940    10941    10942    10943    10944    10945  \n",
       "new_index                                                                    \n",
       "20120829_07     25885  7409.45  6441.98  2778.57   2722.8  1438.29   425.79  \n",
       "20120829_08   41771.9  7158.11  8263.18  2517.06  2331.97  2453.68   958.29  \n",
       "20120829_09   25155.9  6911.77  6635.63  2369.77  1620.75  2590.32  1443.06  \n",
       "20120829_100  6152.39  126.473  1370.22  55.4646  95.7112    146.4  48.0095  \n",
       "20120829_101  4010.65  117.559  901.018   69.905  58.6354  246.885  102.901  \n",
       "20120829_102  5939.97  172.314  1177.66  41.3523  133.906   78.639  54.9892  \n",
       "20120829_103  880.128  178.026  185.109  34.4602  73.4292  121.923  17.7994  \n",
       "20120829_104  2015.75  153.179  414.203  95.5041  47.2978  73.6355  75.7553  \n",
       "20120829_105  59.1959  105.233  13.4843  36.1623  76.7565  105.527  18.0521  \n",
       "20120829_106  4667.14  29.3562  834.821  24.3023  7.10606  93.4605  53.6453  \n",
       "20120829_107  586.708  150.627  128.129  88.3621  13.9516  33.7758  25.7216  \n",
       "20120829_109  17704.5  6558.96  3651.28   1816.3  1798.78  2964.82  1752.58  \n",
       "20120829_10   44603.4  7007.75  12706.2  2149.25  2625.79  1227.68  323.442  \n",
       "20120829_110  34324.7  5778.81  8762.74  2050.35  1576.79  1918.35  855.209  \n",
       "20120829_111  14670.7  6347.59  2695.73  2114.55  1492.88  1862.48  1060.01  \n",
       "20120829_112    15156  5867.11  3372.02  1871.85  937.171  2792.38  1185.49  \n",
       "20120829_113  40312.7  5615.71  9600.52  1875.68  1221.69   1761.6  949.462  \n",
       "20120829_114  19392.1  8318.18   4035.2  2857.59  1505.53  2549.88  782.967  \n",
       "20120829_115  42807.4  7755.32  11219.5  2814.59  1560.46   1485.7  617.653  \n",
       "20120829_116  54816.3  7925.49  12095.4  2351.61  2106.07  2687.53  981.494  \n",
       "20120829_117  36047.9  6264.38  8537.36  1928.08   1681.5  2003.83  672.176  \n",
       "20120829_118  15423.9  7154.09  4306.02   2927.8  1091.92  2273.37  1139.21  \n",
       "20120829_11   52744.1  6807.71  12158.1  2053.01  1810.76  2424.66  860.607  \n",
       "20120829_129  77536.7  2879.96  20878.3  710.941  1025.82  1049.04  464.055  \n",
       "20120829_12   15786.9  4658.59  3924.63  1905.82  1574.93   2113.7  753.697  \n",
       "20120829_130  39243.5  2656.47    10757  596.611  727.169  1050.98  562.605  \n",
       "20120829_131  37128.8  2644.82  9285.53  738.681  788.029   895.66  410.558  \n",
       "20120829_132  33371.5   2235.4  7981.56  774.592  956.629  587.876  400.312  \n",
       "20120829_133  26795.1  2523.34  7223.63  511.758  851.452  742.501  287.056  \n",
       "20120829_134  39104.5  2534.69  8754.56  468.496   968.78  698.933  365.612  \n",
       "...               ...      ...      ...      ...      ...      ...      ...  \n",
       "20120829_67   14116.3  1030.63  2565.21  359.118  251.366  312.098  161.553  \n",
       "20120829_68   22937.9  1173.49  6034.15  327.052  464.706  303.122  52.1478  \n",
       "20120829_69   27083.2  868.478  6042.38  329.191  298.822  225.109  72.1657  \n",
       "20120829_70   6677.61  803.434  1397.59   209.21  228.984   322.28  101.425  \n",
       "20120829_71   35487.8  1229.79  8675.45   319.66  314.247  458.493   148.29  \n",
       "20120829_72   21011.9  1311.94  4474.39  342.444  233.415  405.382  163.224  \n",
       "20120829_73   15111.3  746.208  1848.56  231.741  267.607  354.975  62.0136  \n",
       "20120829_74   7205.48  687.764   1666.7  248.481  263.697  412.789  141.122  \n",
       "20120829_76   14369.3  749.219  2757.12  221.447  336.139  9.91248  75.8089  \n",
       "20120829_77   26473.5  1194.29  6161.67  418.462  296.067   290.33  135.074  \n",
       "20120829_78   16748.4  582.806  3058.85   232.58  267.267  293.649  131.317  \n",
       "20120829_79   16491.6   309.71  2898.08   249.83  316.516  207.311    70.47  \n",
       "20120829_80   14252.4  555.856  2822.94  228.544  385.451  321.397  80.5437  \n",
       "20120829_81   11997.6  602.413  2306.35  240.402  245.786  156.712  75.1529  \n",
       "20120829_82     17066  470.059   3718.5  245.099  211.495  367.882   271.48  \n",
       "20120829_83   16519.9  629.323  4848.86  147.687   164.13  501.977  239.156  \n",
       "20120829_84   17152.8  236.814  4016.71  136.528  151.568  229.545  184.544  \n",
       "20120829_85     16891  344.211  3811.52   205.12  203.096  344.653  224.126  \n",
       "20120829_87   14456.2  329.272  2288.87  126.354  259.906  265.839  96.0507  \n",
       "20120829_88   11296.7  386.961   2393.2  204.162  199.388   324.48  171.518  \n",
       "20120829_89   17429.5   259.62  3810.83  127.995  163.644  220.636  93.3728  \n",
       "20120829_90   16910.1  259.955  3493.01  35.4448  91.6681  160.078  123.675  \n",
       "20120829_91    6886.5  347.062  1404.95  131.933  115.187  297.185   137.58  \n",
       "20120829_92   11167.8  250.203  2121.84  99.5772  78.1666  343.101  122.266  \n",
       "20120829_93   11555.2  245.292  2020.08  29.5373  351.442  79.6669  84.2954  \n",
       "20120829_94   511.999  183.919  158.847  93.4877  151.353  185.731  50.0337  \n",
       "20120829_95   6822.84  184.895  1147.42  91.8939  249.626  265.857  82.8023  \n",
       "20120829_96   5463.07    216.7  1126.03  75.8125  256.787   182.23  99.3942  \n",
       "20120829_98   5245.15  108.335  969.107  64.3045  117.961  272.119  68.3559  \n",
       "20120829_99   7517.38  189.645   1050.1  75.4843  62.8886  283.698  71.1747  \n",
       "\n",
       "[254 rows x 10946 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.to_csv(\"RANDFOREST_S266_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(np.log10(X.fillna(1).replace(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126248940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x=X_pca[:,0],y = X_pca[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_df = pd.DataFrame(X_pca, columns=['x','y'])\n",
    "X_pca_df['hue'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAFgCAYAAABOloX3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12e372780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot(x='x', y='y', hue = 'hue', data = X_pca_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.40346743,  0.20560745])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
