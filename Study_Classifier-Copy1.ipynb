{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_decomposition import PLSCanonical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('study_19_processed.csv', index_col=0, dtype={'Disease': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_data = data.T[['npeaks','pcgroup','drt']].T.drop('Disease', axis=1)\n",
    "data_d = data.T.drop(labels=['npeaks','pcgroup', 'drt'], axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X,y) = (data_d.drop('Disease', axis=1), data_d['Disease'])\n",
    "dummies=pd.get_dummies(y)\n",
    "y = dummies.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_scaler = StandardScaler()\n",
    "feature_data_scaled = feature_scaler.fit_transform(feature_data.T[['npeaks','drt']])\n",
    "feature_data.T[['npeaks', 'drt']] = feature_data_scaled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_data, npeaks=0, drt=0, group=False, log_scale=False):\n",
    "        self.npeaks = npeaks\n",
    "        self.drt = drt\n",
    "        self.group = group\n",
    "        self.feature_data = feature_data\n",
    "        self.log_scale = log_scale\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        if self.log_scale:\n",
    "            data = data.fillna(1).replace(0,1).apply(np.log10)\n",
    "        else:\n",
    "            data = data.fillna(0)\n",
    "        data = data.astype(float)\n",
    "        data = pd.concat([data,feature_data], axis=0)\n",
    "        data = data.T\n",
    "        index_to_drop=[]\n",
    "        for index,row in data.iterrows():\n",
    "            npeaks_data = row['npeaks']\n",
    "            drt_data = row['drt']\n",
    "            if npeaks_data<self.npeaks or drt_data<self.drt:\n",
    "                index_to_drop.append(index)\n",
    "        data = data.drop(index_to_drop).drop(['npeaks','drt'], axis=1)\n",
    "        if self.group:\n",
    "            data = data.astype(float).groupby('pcgroup').mean().T.values\n",
    "        else:\n",
    "            data = data.astype(float).drop('pcgroup', axis=1).T.values\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_selector = FeatureSelector(feature_data=feature_data, npeaks = 0.5, drt = 0.5, group=True, log_scale=True)\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=2)\n",
    "clf = RandomForestClassifier()\n",
    "estimators = [('select_features',feature_selector),('scale',scaler), ('reduce_dim',pca), ('clf',clf)]\n",
    "pipe = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npeaks = [0,0.5]\n",
    "drts = [0, 0.5]\n",
    "interizer = np.vectorize(int)\n",
    "Cs = interizer(np.logspace(1,4,4))\n",
    "param_grid = dict(select_features__npeaks = npeaks,\n",
    "                  select_features__drt = drts,\n",
    "                  select_features__group = [True, False], \n",
    "                  reduce_dim = [None, PCA(None), PCA(50)],\n",
    "                  clf__n_estimators = Cs,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7777777777777778, total=  23.4s\n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.75, total=  23.1s\n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.8571428571428571, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.6666666666666666, total=  23.2s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  23.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.2857142857142857, total=  22.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  22.8s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.625, total=  22.8s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.7142857142857143, total=  23.1s\n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.6666666666666666, total=  23.0s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  23.0s\n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  22.7s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.7777777777777778, total=  23.3s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  23.0s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  23.2s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.625, total=  24.2s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.875, total=  23.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  23.5s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  23.4s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.75, total=  23.8s\n",
      "[CV] clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.8571428571428571, total=  23.0s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.7777777777777778, total=  22.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.625, total=  22.8s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=1.0, total=  23.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  3.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7777777777777778, total=  23.3s\n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.75, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  23.5s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=1.0, total=  23.0s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.625, total=  23.5s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.8571428571428571, total=  23.1s\n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.7777777777777778, total=  22.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.625, total=  23.0s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.42857142857142855, total=  23.8s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  23.4s\n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5, total=  23.2s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.8571428571428571, total=  23.3s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.4444444444444444, total=  23.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.5714285714285714, total=  23.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  6.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  23.2s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.75, total=  23.6s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  23.1s\n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  22.9s\n",
      "\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 [CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5, total=  23.0s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  23.5s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.8888888888888888, total=  23.4s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.75, total=  23.3s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  23.4s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  23.8s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.375, total=  23.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  8.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7142857142857143, total=  23.2s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  23.2s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.375, total=  23.3s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  22.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.3333333333333333, total=  22.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.875, total=  22.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=1.0, total=  22.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.625, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  23.3s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  23.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  9.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.375, total=  22.9s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  23.2s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  23.3s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.625, total=  23.1s\n",
      "[CV] clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.42857142857142855, total=  23.0s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.7777777777777778, total=  22.9s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.625, total=  23.2s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  22.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.5555555555555556, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.5, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  23.8s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.6666666666666666, total=  23.3s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.5, total=  23.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 11.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  24.2s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.7142857142857143, total=  24.8s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  25.3s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.625, total=  25.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.8571428571428571, total=  25.0s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  24.3s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5, total=  24.5s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.8571428571428571, total=  24.8s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.5555555555555556, total=  23.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.375, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  23.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 13.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.7777777777777778, total=  24.0s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.625, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=1.0, total=  23.9s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.6666666666666666, total=  24.2s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  24.1s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=1.0, total=  23.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  23.5s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.375, total=  23.9s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  23.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  23.5s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7142857142857143, total=  24.0s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  23.8s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.75, total=  23.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.7142857142857143, total=  23.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 15.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.6666666666666666, total=  24.1s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  23.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.375, total=  24.2s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.6666666666666666, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  23.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.7142857142857143, total=  24.1s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.625, total=  23.5s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  23.5s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  24.0s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.375, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  23.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 17.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  23.9s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.75, total=  23.9s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.5, total=  23.8s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7142857142857143, total=  23.8s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.875, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  23.5s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  23.5s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.7142857142857143, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5555555555555556, total=  23.5s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.625, total=  23.6s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.6666666666666666, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  23.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 20.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  23.7s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  23.3s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5, total=  23.4s\n",
      "[CV] clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  23.6s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  23.6s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  23.4s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=100, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  23.7s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  26.4s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.5, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.6666666666666666, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.5, total=  26.5s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.7142857142857143, total=  26.7s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.6666666666666666, total=  26.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 23.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5, total=  26.0s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.8571428571428571, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.8571428571428571, total=  25.8s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.6666666666666666, total=  26.0s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.5, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  25.9s\n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.7777777777777778, total=  25.8s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5, total=  25.9s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.8571428571428571, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.6666666666666666, total=  25.9s\n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5, total=  25.8s\n",
      "\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 [CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.8571428571428571, total=  26.0s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  26.3s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.625, total=  26.0s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  26.0s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  26.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 26.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7142857142857143, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  26.0s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.75, total=  26.3s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  26.4s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  26.0s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.875, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  26.5s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.6666666666666666, total=  26.7s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  26.1s\n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  25.9s\n",
      "\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 [CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  25.8s\n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  25.7s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  26.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 29.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  26.4s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.625, total=  26.1s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  26.3s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  26.5s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7142857142857143, total=  26.3s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.75, total=  26.5s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  26.4s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  26.4s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  26.4s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  26.3s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5, total=  26.0s\n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  26.0s\n",
      "\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 [CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.5555555555555556, total=  26.2s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  26.3s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  25.9s\n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  25.9s\n",
      "\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 [CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5, total=  26.0s\n",
      "[CV] clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  26.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 32.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  26.4s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.625, total=  26.4s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=1000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  26.7s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  50.6s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.5, total=  50.0s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  50.0s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.5555555555555556, total=  50.3s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.5, total=  50.5s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  50.5s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5, total=  51.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.8571428571428571, total=  51.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.6666666666666666, total=  50.4s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5, total=  50.6s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.8571428571428571, total=  51.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.7777777777777778, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5, total=  49.9s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.8571428571428571, total=  50.3s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.5555555555555556, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.5, total=  50.6s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  50.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 38.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.7777777777777778, total=  51.0s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5, total=  51.5s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.8571428571428571, total=  50.9s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.7777777777777778, total=  50.3s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5, total=  50.6s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=None, select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.8571428571428571, total=  50.9s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.625, total=  50.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  50.0s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7142857142857143, total=  49.6s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  49.8s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.75, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  50.3s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  49.7s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  50.4s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  50.6s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  50.6s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5, total=  50.4s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  51.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.5555555555555556, total=  50.7s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  50.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 44.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  50.0s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5, total=  50.4s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  50.0s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  50.5s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  50.4s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  50.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.625, total=  50.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0, score=0.7142857142857143, total=  50.5s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7777777777777778, total=  50.6s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=True, select_features__npeaks=0.5, score=0.7142857142857143, total=  50.0s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.6666666666666666, total=  50.5s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.75, total=  50.8s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  50.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  50.0s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  50.4s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  50.5s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.6666666666666666, total=  49.9s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5, total=  49.8s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0, score=0.5714285714285714, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.5555555555555556, total=  50.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 50.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.625, total=  50.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=True, select_features__npeaks=0.5, score=0.8571428571428571, total=  50.1s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5555555555555556, total=  50.2s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5, total=  50.7s\n",
      "[CV] clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5 \n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0, score=0.5714285714285714, total=  49.8s\n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5555555555555556, total=  49.9s\n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.75, total=  49.9s\n",
      "[CV]  clf__n_estimators=10000, reduce_dim=PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), select_features__drt=0.5, select_features__group=False, select_features__npeaks=0.5, score=0.5714285714285714, total=  48.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 288 out of 288 | elapsed: 52.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('select_features', FeatureSelector(drt=0.5,\n",
       "        feature_data=                  0         1          2         3          4         5  \\\n",
       "new_index\n",
       "npeaks     0.230431 -0.424874  -0.670614 -0.342961    0.72191 -0.179135\n",
       "pcgroup          77      6780       6604      6297       6320 ...     ...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'select_features__npeaks': [0, 0.5], 'select_features__drt': [0, 0.5], 'select_features__group': [True, False], 'reduce_dim': [None, PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False), PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)], 'clf__n_estimators': array([   10,   100,  1000, 10000])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = GridSearchCV(pipe,param_grid=param_grid, verbose=10, n_jobs=-1)\n",
    "estimator.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_clf__n_estimators</th>\n",
       "      <th>param_reduce_dim</th>\n",
       "      <th>param_select_features__drt</th>\n",
       "      <th>param_select_features__group</th>\n",
       "      <th>param_select_features__npeaks</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.015584</td>\n",
       "      <td>11.162480</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': None, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087276</td>\n",
       "      <td>0.049783</td>\n",
       "      <td>0.043606</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.789093</td>\n",
       "      <td>11.234387</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': None, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.134057</td>\n",
       "      <td>0.028626</td>\n",
       "      <td>0.165172</td>\n",
       "      <td>0.027730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.625713</td>\n",
       "      <td>11.267243</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': None, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109181</td>\n",
       "      <td>0.021354</td>\n",
       "      <td>0.035215</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.556832</td>\n",
       "      <td>11.324277</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': None, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078320</td>\n",
       "      <td>0.047779</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.009953</td>\n",
       "      <td>11.575240</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': None, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064642</td>\n",
       "      <td>0.527772</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.029463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.037585</td>\n",
       "      <td>11.300622</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': None, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.175473</td>\n",
       "      <td>0.089510</td>\n",
       "      <td>0.043606</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.938110</td>\n",
       "      <td>11.445169</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': None, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.219868</td>\n",
       "      <td>0.109824</td>\n",
       "      <td>0.077152</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.539071</td>\n",
       "      <td>11.423855</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': None, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133477</td>\n",
       "      <td>0.085070</td>\n",
       "      <td>0.148293</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.829038</td>\n",
       "      <td>11.329101</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.081157</td>\n",
       "      <td>0.038272</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.756657</td>\n",
       "      <td>11.431839</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141122</td>\n",
       "      <td>0.105265</td>\n",
       "      <td>0.148293</td>\n",
       "      <td>0.029463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.750638</td>\n",
       "      <td>11.476978</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094603</td>\n",
       "      <td>0.134760</td>\n",
       "      <td>0.125660</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.630605</td>\n",
       "      <td>11.566732</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.217590</td>\n",
       "      <td>0.178141</td>\n",
       "      <td>0.141445</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.980314</td>\n",
       "      <td>11.335568</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>0.062492</td>\n",
       "      <td>0.140859</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.909832</td>\n",
       "      <td>11.482664</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200616</td>\n",
       "      <td>0.129146</td>\n",
       "      <td>0.078216</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.743212</td>\n",
       "      <td>11.557830</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.132825</td>\n",
       "      <td>0.148255</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11.599101</td>\n",
       "      <td>11.541738</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.106887</td>\n",
       "      <td>0.127753</td>\n",
       "      <td>0.030156</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12.034706</td>\n",
       "      <td>11.341305</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017882</td>\n",
       "      <td>0.042499</td>\n",
       "      <td>0.128586</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11.860545</td>\n",
       "      <td>11.508476</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.128828</td>\n",
       "      <td>0.190157</td>\n",
       "      <td>0.178638</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11.708711</td>\n",
       "      <td>11.427607</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>0.056522</td>\n",
       "      <td>0.124004</td>\n",
       "      <td>0.027730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11.557100</td>\n",
       "      <td>11.357389</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008845</td>\n",
       "      <td>0.017359</td>\n",
       "      <td>0.294628</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11.879098</td>\n",
       "      <td>11.288771</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025690</td>\n",
       "      <td>0.036985</td>\n",
       "      <td>0.035215</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11.768646</td>\n",
       "      <td>11.338297</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082208</td>\n",
       "      <td>0.080595</td>\n",
       "      <td>0.208730</td>\n",
       "      <td>0.031427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.661699</td>\n",
       "      <td>11.449664</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031284</td>\n",
       "      <td>0.117252</td>\n",
       "      <td>0.078216</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11.548043</td>\n",
       "      <td>11.378550</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10, 'reduce_dim': PCA(co...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100168</td>\n",
       "      <td>0.102938</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12.157496</td>\n",
       "      <td>11.364437</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 100, 'reduce_dim': None,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070851</td>\n",
       "      <td>0.096083</td>\n",
       "      <td>0.087211</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12.020375</td>\n",
       "      <td>11.511051</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 100, 'reduce_dim': None,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032037</td>\n",
       "      <td>0.132262</td>\n",
       "      <td>0.140859</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12.140991</td>\n",
       "      <td>12.061190</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 100, 'reduce_dim': None,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.159925</td>\n",
       "      <td>0.356417</td>\n",
       "      <td>0.090468</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12.488261</td>\n",
       "      <td>12.840627</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 100, 'reduce_dim': None,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333226</td>\n",
       "      <td>0.565644</td>\n",
       "      <td>0.125660</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12.815194</td>\n",
       "      <td>11.718088</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 100, 'reduce_dim': None,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287496</td>\n",
       "      <td>0.098096</td>\n",
       "      <td>0.140859</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12.249979</td>\n",
       "      <td>11.395466</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 100, 'reduce_dim': None,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083095</td>\n",
       "      <td>0.111392</td>\n",
       "      <td>0.191373</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>14.437385</td>\n",
       "      <td>11.926356</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 1000, 'reduce_dim': PCA(...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041316</td>\n",
       "      <td>0.064580</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>14.450727</td>\n",
       "      <td>11.886438</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 1000, 'reduce_dim': PCA(...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062652</td>\n",
       "      <td>0.027709</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>14.431783</td>\n",
       "      <td>11.688955</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 1000, 'reduce_dim': PCA(...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136258</td>\n",
       "      <td>0.013070</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>14.332872</td>\n",
       "      <td>11.784331</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 1000, 'reduce_dim': PCA(...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109556</td>\n",
       "      <td>0.030904</td>\n",
       "      <td>0.125660</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>14.270215</td>\n",
       "      <td>11.869963</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 1000, 'reduce_dim': PCA(...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067613</td>\n",
       "      <td>0.239084</td>\n",
       "      <td>0.030156</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>14.435935</td>\n",
       "      <td>12.083596</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 1000, 'reduce_dim': PCA(...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327511</td>\n",
       "      <td>0.222304</td>\n",
       "      <td>0.030156</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>37.292763</td>\n",
       "      <td>12.911550</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': Non...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166666</td>\n",
       "      <td>0.102557</td>\n",
       "      <td>0.090468</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>37.382960</td>\n",
       "      <td>12.948625</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': Non...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.104873</td>\n",
       "      <td>0.077451</td>\n",
       "      <td>0.150781</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>37.924633</td>\n",
       "      <td>13.005772</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': Non...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.325262</td>\n",
       "      <td>0.072553</td>\n",
       "      <td>0.150781</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>37.703556</td>\n",
       "      <td>13.027902</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': Non...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266801</td>\n",
       "      <td>0.053260</td>\n",
       "      <td>0.140859</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>37.194507</td>\n",
       "      <td>12.941773</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': Non...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.103778</td>\n",
       "      <td>0.048374</td>\n",
       "      <td>0.150781</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>37.480362</td>\n",
       "      <td>13.018299</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': Non...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.150344</td>\n",
       "      <td>0.033673</td>\n",
       "      <td>0.150781</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>38.124145</td>\n",
       "      <td>12.998091</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': Non...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333424</td>\n",
       "      <td>0.069146</td>\n",
       "      <td>0.150781</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>37.669380</td>\n",
       "      <td>12.960642</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': Non...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.289195</td>\n",
       "      <td>0.048761</td>\n",
       "      <td>0.150781</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>37.120566</td>\n",
       "      <td>13.047693</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024208</td>\n",
       "      <td>0.023275</td>\n",
       "      <td>0.035215</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>37.014882</td>\n",
       "      <td>12.924578</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.257633</td>\n",
       "      <td>0.046976</td>\n",
       "      <td>0.064293</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>37.152267</td>\n",
       "      <td>12.968365</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.244137</td>\n",
       "      <td>0.045288</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>37.279613</td>\n",
       "      <td>12.953753</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.373861</td>\n",
       "      <td>0.086288</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>37.540961</td>\n",
       "      <td>13.158258</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.096718</td>\n",
       "      <td>0.216211</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>37.171929</td>\n",
       "      <td>13.091165</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.147883</td>\n",
       "      <td>0.259564</td>\n",
       "      <td>0.125660</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>37.301266</td>\n",
       "      <td>12.967365</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215386</td>\n",
       "      <td>0.103754</td>\n",
       "      <td>0.030156</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>37.241355</td>\n",
       "      <td>13.041510</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.331850</td>\n",
       "      <td>0.114206</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>37.264453</td>\n",
       "      <td>12.952479</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.132643</td>\n",
       "      <td>0.036627</td>\n",
       "      <td>0.035215</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>37.335506</td>\n",
       "      <td>12.907768</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.192863</td>\n",
       "      <td>0.068855</td>\n",
       "      <td>0.064293</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>37.305571</td>\n",
       "      <td>13.164652</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110026</td>\n",
       "      <td>0.202105</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>37.318638</td>\n",
       "      <td>12.988787</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194842</td>\n",
       "      <td>0.041658</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>37.090186</td>\n",
       "      <td>12.887812</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.132386</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>37.317060</td>\n",
       "      <td>12.893817</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046425</td>\n",
       "      <td>0.138505</td>\n",
       "      <td>0.125660</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>37.300926</td>\n",
       "      <td>12.918597</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.255276</td>\n",
       "      <td>0.112514</td>\n",
       "      <td>0.030156</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>37.176423</td>\n",
       "      <td>12.269980</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>PCA(copy=True, iterated_power='auto', n_compon...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'clf__n_estimators': 10000, 'reduce_dim': PCA...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.227534</td>\n",
       "      <td>0.840018</td>\n",
       "      <td>0.088622</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       12.015584        11.162480         0.791667          1.000000   \n",
       "1       11.789093        11.234387         0.541667          0.980392   \n",
       "2       11.625713        11.267243         0.666667          1.000000   \n",
       "3       11.556832        11.324277         0.666667          1.000000   \n",
       "4       12.009953        11.575240         0.666667          0.979167   \n",
       "5       12.037585        11.300622         0.833333          1.000000   \n",
       "6       11.938110        11.445169         0.750000          1.000000   \n",
       "7       11.539071        11.423855         0.791667          1.000000   \n",
       "8       11.829038        11.329101         0.708333          1.000000   \n",
       "9       11.756657        11.431839         0.791667          0.979167   \n",
       "10      11.750638        11.476978         0.666667          1.000000   \n",
       "11      11.630605        11.566732         0.625000          1.000000   \n",
       "12      11.980314        11.335568         0.666667          1.000000   \n",
       "13      11.909832        11.482664         0.541667          1.000000   \n",
       "14      11.743212        11.557830         0.625000          1.000000   \n",
       "15      11.599101        11.541738         0.541667          1.000000   \n",
       "16      12.034706        11.341305         0.750000          1.000000   \n",
       "17      11.860545        11.508476         0.625000          1.000000   \n",
       "18      11.708711        11.427607         0.541667          0.980392   \n",
       "19      11.557100        11.357389         0.708333          1.000000   \n",
       "20      11.879098        11.288771         0.666667          1.000000   \n",
       "21      11.768646        11.338297         0.666667          0.977778   \n",
       "22      11.661699        11.449664         0.541667          1.000000   \n",
       "23      11.548043        11.378550         0.666667          1.000000   \n",
       "24      12.157496        11.364437         0.583333          1.000000   \n",
       "25      12.020375        11.511051         0.666667          1.000000   \n",
       "26      12.140991        12.061190         0.625000          1.000000   \n",
       "27      12.488261        12.840627         0.666667          1.000000   \n",
       "28      12.815194        11.718088         0.666667          1.000000   \n",
       "29      12.249979        11.395466         0.583333          1.000000   \n",
       "..            ...              ...              ...               ...   \n",
       "66      14.437385        11.926356         0.666667          1.000000   \n",
       "67      14.450727        11.886438         0.625000          1.000000   \n",
       "68      14.431783        11.688955         0.583333          1.000000   \n",
       "69      14.332872        11.784331         0.666667          1.000000   \n",
       "70      14.270215        11.869963         0.541667          1.000000   \n",
       "71      14.435935        12.083596         0.583333          1.000000   \n",
       "72      37.292763        12.911550         0.625000          1.000000   \n",
       "73      37.382960        12.948625         0.625000          1.000000   \n",
       "74      37.924633        13.005772         0.625000          1.000000   \n",
       "75      37.703556        13.027902         0.666667          1.000000   \n",
       "76      37.194507        12.941773         0.708333          1.000000   \n",
       "77      37.480362        13.018299         0.625000          1.000000   \n",
       "78      38.124145        12.998091         0.708333          1.000000   \n",
       "79      37.669380        12.960642         0.708333          1.000000   \n",
       "80      37.120566        13.047693         0.666667          1.000000   \n",
       "81      37.014882        12.924578         0.708333          1.000000   \n",
       "82      37.152267        12.968365         0.666667          1.000000   \n",
       "83      37.279613        12.953753         0.625000          1.000000   \n",
       "84      37.540961        13.158258         0.583333          1.000000   \n",
       "85      37.171929        13.091165         0.666667          1.000000   \n",
       "86      37.301266        12.967365         0.541667          1.000000   \n",
       "87      37.241355        13.041510         0.625000          1.000000   \n",
       "88      37.264453        12.952479         0.666667          1.000000   \n",
       "89      37.335506        12.907768         0.708333          1.000000   \n",
       "90      37.305571        13.164652         0.666667          1.000000   \n",
       "91      37.318638        12.988787         0.625000          1.000000   \n",
       "92      37.090186        12.887812         0.583333          1.000000   \n",
       "93      37.317060        12.893817         0.666667          1.000000   \n",
       "94      37.300926        12.918597         0.541667          1.000000   \n",
       "95      37.176423        12.269980         0.625000          1.000000   \n",
       "\n",
       "   param_clf__n_estimators                                   param_reduce_dim  \\\n",
       "0                       10                                               None   \n",
       "1                       10                                               None   \n",
       "2                       10                                               None   \n",
       "3                       10                                               None   \n",
       "4                       10                                               None   \n",
       "5                       10                                               None   \n",
       "6                       10                                               None   \n",
       "7                       10                                               None   \n",
       "8                       10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "9                       10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "10                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "11                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "12                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "13                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "14                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "15                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "16                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "17                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "18                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "19                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "20                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "21                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "22                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "23                      10  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "24                     100                                               None   \n",
       "25                     100                                               None   \n",
       "26                     100                                               None   \n",
       "27                     100                                               None   \n",
       "28                     100                                               None   \n",
       "29                     100                                               None   \n",
       "..                     ...                                                ...   \n",
       "66                    1000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "67                    1000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "68                    1000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "69                    1000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "70                    1000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "71                    1000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "72                   10000                                               None   \n",
       "73                   10000                                               None   \n",
       "74                   10000                                               None   \n",
       "75                   10000                                               None   \n",
       "76                   10000                                               None   \n",
       "77                   10000                                               None   \n",
       "78                   10000                                               None   \n",
       "79                   10000                                               None   \n",
       "80                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "81                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "82                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "83                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "84                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "85                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "86                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "87                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "88                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "89                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "90                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "91                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "92                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "93                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "94                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "95                   10000  PCA(copy=True, iterated_power='auto', n_compon...   \n",
       "\n",
       "   param_select_features__drt param_select_features__group  \\\n",
       "0                           0                         True   \n",
       "1                           0                         True   \n",
       "2                           0                        False   \n",
       "3                           0                        False   \n",
       "4                         0.5                         True   \n",
       "5                         0.5                         True   \n",
       "6                         0.5                        False   \n",
       "7                         0.5                        False   \n",
       "8                           0                         True   \n",
       "9                           0                         True   \n",
       "10                          0                        False   \n",
       "11                          0                        False   \n",
       "12                        0.5                         True   \n",
       "13                        0.5                         True   \n",
       "14                        0.5                        False   \n",
       "15                        0.5                        False   \n",
       "16                          0                         True   \n",
       "17                          0                         True   \n",
       "18                          0                        False   \n",
       "19                          0                        False   \n",
       "20                        0.5                         True   \n",
       "21                        0.5                         True   \n",
       "22                        0.5                        False   \n",
       "23                        0.5                        False   \n",
       "24                          0                         True   \n",
       "25                          0                         True   \n",
       "26                          0                        False   \n",
       "27                          0                        False   \n",
       "28                        0.5                         True   \n",
       "29                        0.5                         True   \n",
       "..                        ...                          ...   \n",
       "66                          0                        False   \n",
       "67                          0                        False   \n",
       "68                        0.5                         True   \n",
       "69                        0.5                         True   \n",
       "70                        0.5                        False   \n",
       "71                        0.5                        False   \n",
       "72                          0                         True   \n",
       "73                          0                         True   \n",
       "74                          0                        False   \n",
       "75                          0                        False   \n",
       "76                        0.5                         True   \n",
       "77                        0.5                         True   \n",
       "78                        0.5                        False   \n",
       "79                        0.5                        False   \n",
       "80                          0                         True   \n",
       "81                          0                         True   \n",
       "82                          0                        False   \n",
       "83                          0                        False   \n",
       "84                        0.5                         True   \n",
       "85                        0.5                         True   \n",
       "86                        0.5                        False   \n",
       "87                        0.5                        False   \n",
       "88                          0                         True   \n",
       "89                          0                         True   \n",
       "90                          0                        False   \n",
       "91                          0                        False   \n",
       "92                        0.5                         True   \n",
       "93                        0.5                         True   \n",
       "94                        0.5                        False   \n",
       "95                        0.5                        False   \n",
       "\n",
       "   param_select_features__npeaks  \\\n",
       "0                              0   \n",
       "1                            0.5   \n",
       "2                              0   \n",
       "3                            0.5   \n",
       "4                              0   \n",
       "5                            0.5   \n",
       "6                              0   \n",
       "7                            0.5   \n",
       "8                              0   \n",
       "9                            0.5   \n",
       "10                             0   \n",
       "11                           0.5   \n",
       "12                             0   \n",
       "13                           0.5   \n",
       "14                             0   \n",
       "15                           0.5   \n",
       "16                             0   \n",
       "17                           0.5   \n",
       "18                             0   \n",
       "19                           0.5   \n",
       "20                             0   \n",
       "21                           0.5   \n",
       "22                             0   \n",
       "23                           0.5   \n",
       "24                             0   \n",
       "25                           0.5   \n",
       "26                             0   \n",
       "27                           0.5   \n",
       "28                             0   \n",
       "29                           0.5   \n",
       "..                           ...   \n",
       "66                             0   \n",
       "67                           0.5   \n",
       "68                             0   \n",
       "69                           0.5   \n",
       "70                             0   \n",
       "71                           0.5   \n",
       "72                             0   \n",
       "73                           0.5   \n",
       "74                             0   \n",
       "75                           0.5   \n",
       "76                             0   \n",
       "77                           0.5   \n",
       "78                             0   \n",
       "79                           0.5   \n",
       "80                             0   \n",
       "81                           0.5   \n",
       "82                             0   \n",
       "83                           0.5   \n",
       "84                             0   \n",
       "85                           0.5   \n",
       "86                             0   \n",
       "87                           0.5   \n",
       "88                             0   \n",
       "89                           0.5   \n",
       "90                             0   \n",
       "91                           0.5   \n",
       "92                             0   \n",
       "93                           0.5   \n",
       "94                             0   \n",
       "95                           0.5   \n",
       "\n",
       "                                               params       ...         \\\n",
       "0   {'clf__n_estimators': 10, 'reduce_dim': None, ...       ...          \n",
       "1   {'clf__n_estimators': 10, 'reduce_dim': None, ...       ...          \n",
       "2   {'clf__n_estimators': 10, 'reduce_dim': None, ...       ...          \n",
       "3   {'clf__n_estimators': 10, 'reduce_dim': None, ...       ...          \n",
       "4   {'clf__n_estimators': 10, 'reduce_dim': None, ...       ...          \n",
       "5   {'clf__n_estimators': 10, 'reduce_dim': None, ...       ...          \n",
       "6   {'clf__n_estimators': 10, 'reduce_dim': None, ...       ...          \n",
       "7   {'clf__n_estimators': 10, 'reduce_dim': None, ...       ...          \n",
       "8   {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "9   {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "10  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "11  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "12  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "13  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "14  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "15  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "16  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "17  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "18  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "19  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "20  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "21  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "22  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "23  {'clf__n_estimators': 10, 'reduce_dim': PCA(co...       ...          \n",
       "24  {'clf__n_estimators': 100, 'reduce_dim': None,...       ...          \n",
       "25  {'clf__n_estimators': 100, 'reduce_dim': None,...       ...          \n",
       "26  {'clf__n_estimators': 100, 'reduce_dim': None,...       ...          \n",
       "27  {'clf__n_estimators': 100, 'reduce_dim': None,...       ...          \n",
       "28  {'clf__n_estimators': 100, 'reduce_dim': None,...       ...          \n",
       "29  {'clf__n_estimators': 100, 'reduce_dim': None,...       ...          \n",
       "..                                                ...       ...          \n",
       "66  {'clf__n_estimators': 1000, 'reduce_dim': PCA(...       ...          \n",
       "67  {'clf__n_estimators': 1000, 'reduce_dim': PCA(...       ...          \n",
       "68  {'clf__n_estimators': 1000, 'reduce_dim': PCA(...       ...          \n",
       "69  {'clf__n_estimators': 1000, 'reduce_dim': PCA(...       ...          \n",
       "70  {'clf__n_estimators': 1000, 'reduce_dim': PCA(...       ...          \n",
       "71  {'clf__n_estimators': 1000, 'reduce_dim': PCA(...       ...          \n",
       "72  {'clf__n_estimators': 10000, 'reduce_dim': Non...       ...          \n",
       "73  {'clf__n_estimators': 10000, 'reduce_dim': Non...       ...          \n",
       "74  {'clf__n_estimators': 10000, 'reduce_dim': Non...       ...          \n",
       "75  {'clf__n_estimators': 10000, 'reduce_dim': Non...       ...          \n",
       "76  {'clf__n_estimators': 10000, 'reduce_dim': Non...       ...          \n",
       "77  {'clf__n_estimators': 10000, 'reduce_dim': Non...       ...          \n",
       "78  {'clf__n_estimators': 10000, 'reduce_dim': Non...       ...          \n",
       "79  {'clf__n_estimators': 10000, 'reduce_dim': Non...       ...          \n",
       "80  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "81  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "82  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "83  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "84  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "85  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "86  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "87  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "88  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "89  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "90  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "91  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "92  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "93  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "94  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "95  {'clf__n_estimators': 10000, 'reduce_dim': PCA...       ...          \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0            0.777778            1.000000              0.750   \n",
       "1            0.666667            1.000000              0.625   \n",
       "2            0.666667            1.000000              0.625   \n",
       "3            0.666667            1.000000              0.750   \n",
       "4            0.777778            1.000000              0.625   \n",
       "5            0.777778            1.000000              0.875   \n",
       "6            0.666667            1.000000              0.750   \n",
       "7            0.777778            1.000000              0.625   \n",
       "8            0.777778            1.000000              0.750   \n",
       "9            0.777778            1.000000              0.625   \n",
       "10           0.555556            1.000000              0.625   \n",
       "11           0.777778            1.000000              0.625   \n",
       "12           0.666667            1.000000              0.500   \n",
       "13           0.444444            1.000000              0.625   \n",
       "14           0.555556            1.000000              0.750   \n",
       "15           0.555556            1.000000              0.500   \n",
       "16           0.888889            1.000000              0.750   \n",
       "17           0.777778            1.000000              0.375   \n",
       "18           0.666667            1.000000              0.375   \n",
       "19           0.333333            1.000000              0.875   \n",
       "20           0.666667            1.000000              0.625   \n",
       "21           0.777778            0.933333              0.375   \n",
       "22           0.555556            1.000000              0.625   \n",
       "23           0.777778            1.000000              0.625   \n",
       "24           0.555556            1.000000              0.500   \n",
       "25           0.666667            1.000000              0.500   \n",
       "26           0.666667            1.000000              0.500   \n",
       "27           0.555556            1.000000              0.625   \n",
       "28           0.666667            1.000000              0.500   \n",
       "29           0.555556            1.000000              0.375   \n",
       "..                ...                 ...                ...   \n",
       "66           0.666667            1.000000              0.750   \n",
       "67           0.555556            1.000000              0.750   \n",
       "68           0.666667            1.000000              0.500   \n",
       "69           0.555556            1.000000              0.625   \n",
       "70           0.555556            1.000000              0.500   \n",
       "71           0.555556            1.000000              0.625   \n",
       "72           0.666667            1.000000              0.500   \n",
       "73           0.555556            1.000000              0.500   \n",
       "74           0.555556            1.000000              0.500   \n",
       "75           0.666667            1.000000              0.500   \n",
       "76           0.777778            1.000000              0.500   \n",
       "77           0.555556            1.000000              0.500   \n",
       "78           0.777778            1.000000              0.500   \n",
       "79           0.777778            1.000000              0.500   \n",
       "80           0.666667            1.000000              0.625   \n",
       "81           0.777778            1.000000              0.625   \n",
       "82           0.666667            1.000000              0.750   \n",
       "83           0.555556            1.000000              0.750   \n",
       "84           0.666667            1.000000              0.500   \n",
       "85           0.555556            1.000000              0.625   \n",
       "86           0.555556            1.000000              0.500   \n",
       "87           0.555556            1.000000              0.750   \n",
       "88           0.666667            1.000000              0.625   \n",
       "89           0.777778            1.000000              0.625   \n",
       "90           0.666667            1.000000              0.750   \n",
       "91           0.555556            1.000000              0.750   \n",
       "92           0.666667            1.000000              0.500   \n",
       "93           0.555556            1.000000              0.625   \n",
       "94           0.555556            1.000000              0.500   \n",
       "95           0.555556            1.000000              0.750   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0               1.0000           0.857143            1.000000      0.087276   \n",
       "1               1.0000           0.285714            0.941176      0.134057   \n",
       "2               1.0000           0.714286            1.000000      0.109181   \n",
       "3               1.0000           0.571429            1.000000      0.078320   \n",
       "4               0.9375           0.571429            1.000000      0.064642   \n",
       "5               1.0000           0.857143            1.000000      0.175473   \n",
       "6               1.0000           0.857143            1.000000      0.219868   \n",
       "7               1.0000           1.000000            1.000000      0.133477   \n",
       "8               1.0000           0.571429            1.000000      0.081157   \n",
       "9               0.9375           1.000000            1.000000      0.141122   \n",
       "10              1.0000           0.857143            1.000000      0.094603   \n",
       "11              1.0000           0.428571            1.000000      0.217590   \n",
       "12              1.0000           0.857143            1.000000      0.013532   \n",
       "13              1.0000           0.571429            1.000000      0.200616   \n",
       "14              1.0000           0.571429            1.000000      0.132825   \n",
       "15              1.0000           0.571429            1.000000      0.106887   \n",
       "16              1.0000           0.571429            1.000000      0.017882   \n",
       "17              1.0000           0.714286            1.000000      0.128828   \n",
       "18              1.0000           0.571429            0.941176      0.104094   \n",
       "19              1.0000           1.000000            1.000000      0.008845   \n",
       "20              1.0000           0.714286            1.000000      0.025690   \n",
       "21              1.0000           0.857143            1.000000      0.082208   \n",
       "22              1.0000           0.428571            1.000000      0.031284   \n",
       "23              1.0000           0.571429            1.000000      0.100168   \n",
       "24              1.0000           0.714286            1.000000      0.070851   \n",
       "25              1.0000           0.857143            1.000000      0.032037   \n",
       "26              1.0000           0.714286            1.000000      0.159925   \n",
       "27              1.0000           0.857143            1.000000      0.333226   \n",
       "28              1.0000           0.857143            1.000000      0.287496   \n",
       "29              1.0000           0.857143            1.000000      0.083095   \n",
       "..                 ...                ...                 ...           ...   \n",
       "66              1.0000           0.571429            1.000000      0.041316   \n",
       "67              1.0000           0.571429            1.000000      0.062652   \n",
       "68              1.0000           0.571429            1.000000      0.136258   \n",
       "69              1.0000           0.857143            1.000000      0.109556   \n",
       "70              1.0000           0.571429            1.000000      0.067613   \n",
       "71              1.0000           0.571429            1.000000      0.327511   \n",
       "72              1.0000           0.714286            1.000000      0.166666   \n",
       "73              1.0000           0.857143            1.000000      0.104873   \n",
       "74              1.0000           0.857143            1.000000      0.325262   \n",
       "75              1.0000           0.857143            1.000000      0.266801   \n",
       "76              1.0000           0.857143            1.000000      0.103778   \n",
       "77              1.0000           0.857143            1.000000      0.150344   \n",
       "78              1.0000           0.857143            1.000000      0.333424   \n",
       "79              1.0000           0.857143            1.000000      0.289195   \n",
       "80              1.0000           0.714286            1.000000      0.024208   \n",
       "81              1.0000           0.714286            1.000000      0.257633   \n",
       "82              1.0000           0.571429            1.000000      0.244137   \n",
       "83              1.0000           0.571429            1.000000      0.373861   \n",
       "84              1.0000           0.571429            1.000000      0.096718   \n",
       "85              1.0000           0.857143            1.000000      0.147883   \n",
       "86              1.0000           0.571429            1.000000      0.215386   \n",
       "87              1.0000           0.571429            1.000000      0.331850   \n",
       "88              1.0000           0.714286            1.000000      0.132643   \n",
       "89              1.0000           0.714286            1.000000      0.192863   \n",
       "90              1.0000           0.571429            1.000000      0.110026   \n",
       "91              1.0000           0.571429            1.000000      0.194842   \n",
       "92              1.0000           0.571429            1.000000      0.132386   \n",
       "93              1.0000           0.857143            1.000000      0.046425   \n",
       "94              1.0000           0.571429            1.000000      0.255276   \n",
       "95              1.0000           0.571429            1.000000      0.227534   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "0         0.049783        0.043606         0.000000  \n",
       "1         0.028626        0.165172         0.027730  \n",
       "2         0.021354        0.035215         0.000000  \n",
       "3         0.047779        0.070430         0.000000  \n",
       "4         0.527772        0.088622         0.029463  \n",
       "5         0.089510        0.043606         0.000000  \n",
       "6         0.109824        0.077152         0.000000  \n",
       "7         0.085070        0.148293         0.000000  \n",
       "8         0.038272        0.088622         0.000000  \n",
       "9         0.105265        0.148293         0.029463  \n",
       "10        0.134760        0.125660         0.000000  \n",
       "11        0.178141        0.141445         0.000000  \n",
       "12        0.062492        0.140859         0.000000  \n",
       "13        0.129146        0.078216         0.000000  \n",
       "14        0.148255        0.088622         0.000000  \n",
       "15        0.127753        0.030156         0.000000  \n",
       "16        0.042499        0.128586         0.000000  \n",
       "17        0.190157        0.178638         0.000000  \n",
       "18        0.056522        0.124004         0.027730  \n",
       "19        0.017359        0.294628         0.000000  \n",
       "20        0.036985        0.035215         0.000000  \n",
       "21        0.080595        0.208730         0.031427  \n",
       "22        0.117252        0.078216         0.000000  \n",
       "23        0.102938        0.088622         0.000000  \n",
       "24        0.096083        0.087211         0.000000  \n",
       "25        0.132262        0.140859         0.000000  \n",
       "26        0.356417        0.090468         0.000000  \n",
       "27        0.565644        0.125660         0.000000  \n",
       "28        0.098096        0.140859         0.000000  \n",
       "29        0.111392        0.191373         0.000000  \n",
       "..             ...             ...              ...  \n",
       "66        0.064580        0.070430         0.000000  \n",
       "67        0.027709        0.088622         0.000000  \n",
       "68        0.013070        0.070430         0.000000  \n",
       "69        0.030904        0.125660         0.000000  \n",
       "70        0.239084        0.030156         0.000000  \n",
       "71        0.222304        0.030156         0.000000  \n",
       "72        0.102557        0.090468         0.000000  \n",
       "73        0.077451        0.150781         0.000000  \n",
       "74        0.072553        0.150781         0.000000  \n",
       "75        0.053260        0.140859         0.000000  \n",
       "76        0.048374        0.150781         0.000000  \n",
       "77        0.033673        0.150781         0.000000  \n",
       "78        0.069146        0.150781         0.000000  \n",
       "79        0.048761        0.150781         0.000000  \n",
       "80        0.023275        0.035215         0.000000  \n",
       "81        0.046976        0.064293         0.000000  \n",
       "82        0.045288        0.070430         0.000000  \n",
       "83        0.086288        0.088622         0.000000  \n",
       "84        0.216211        0.070430         0.000000  \n",
       "85        0.259564        0.125660         0.000000  \n",
       "86        0.103754        0.030156         0.000000  \n",
       "87        0.114206        0.088622         0.000000  \n",
       "88        0.036627        0.035215         0.000000  \n",
       "89        0.068855        0.064293         0.000000  \n",
       "90        0.202105        0.070430         0.000000  \n",
       "91        0.041658        0.088622         0.000000  \n",
       "92        0.032945        0.070430         0.000000  \n",
       "93        0.138505        0.125660         0.000000  \n",
       "94        0.112514        0.030156         0.000000  \n",
       "95        0.840018        0.088622         0.000000  \n",
       "\n",
       "[96 rows x 21 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(estimator.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 2]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\na/bBGxGdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b902a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(results['mean_test_score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__n_estimators': 10,\n",
       " 'reduce_dim': None,\n",
       " 'select_features__drt': 0.5,\n",
       " 'select_features__group': True,\n",
       " 'select_features__npeaks': 0.5}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83333333333333337"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>10936</th>\n",
       "      <th>10937</th>\n",
       "      <th>10938</th>\n",
       "      <th>10939</th>\n",
       "      <th>10940</th>\n",
       "      <th>10941</th>\n",
       "      <th>10942</th>\n",
       "      <th>10943</th>\n",
       "      <th>10944</th>\n",
       "      <th>10945</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20120829_07</th>\n",
       "      <td>4482.31</td>\n",
       "      <td>407.027</td>\n",
       "      <td>3671.02</td>\n",
       "      <td>6326.44</td>\n",
       "      <td>6176.96</td>\n",
       "      <td>533.566</td>\n",
       "      <td>18457.1</td>\n",
       "      <td>4475.88</td>\n",
       "      <td>1412.48</td>\n",
       "      <td>727.531</td>\n",
       "      <td>...</td>\n",
       "      <td>79918</td>\n",
       "      <td>5125.63</td>\n",
       "      <td>11959.2</td>\n",
       "      <td>25885</td>\n",
       "      <td>7409.45</td>\n",
       "      <td>6441.98</td>\n",
       "      <td>2778.57</td>\n",
       "      <td>2722.8</td>\n",
       "      <td>1438.29</td>\n",
       "      <td>425.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_08</th>\n",
       "      <td>2507.02</td>\n",
       "      <td>51.2232</td>\n",
       "      <td>3250.53</td>\n",
       "      <td>6517.23</td>\n",
       "      <td>4384.86</td>\n",
       "      <td>517.621</td>\n",
       "      <td>10634.7</td>\n",
       "      <td>6011.26</td>\n",
       "      <td>850.188</td>\n",
       "      <td>1016.01</td>\n",
       "      <td>...</td>\n",
       "      <td>123186</td>\n",
       "      <td>1565.6</td>\n",
       "      <td>11029.4</td>\n",
       "      <td>41771.9</td>\n",
       "      <td>7158.11</td>\n",
       "      <td>8263.18</td>\n",
       "      <td>2517.06</td>\n",
       "      <td>2331.97</td>\n",
       "      <td>2453.68</td>\n",
       "      <td>958.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_09</th>\n",
       "      <td>3298.28</td>\n",
       "      <td>4.20738</td>\n",
       "      <td>7994.55</td>\n",
       "      <td>9881.68</td>\n",
       "      <td>5931.93</td>\n",
       "      <td>483.42</td>\n",
       "      <td>14689.4</td>\n",
       "      <td>4546.74</td>\n",
       "      <td>874.314</td>\n",
       "      <td>942.373</td>\n",
       "      <td>...</td>\n",
       "      <td>75956.7</td>\n",
       "      <td>2721.17</td>\n",
       "      <td>10441.5</td>\n",
       "      <td>25155.9</td>\n",
       "      <td>6911.77</td>\n",
       "      <td>6635.63</td>\n",
       "      <td>2369.77</td>\n",
       "      <td>1620.75</td>\n",
       "      <td>2590.32</td>\n",
       "      <td>1443.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_100</th>\n",
       "      <td>1754.61</td>\n",
       "      <td>262.214</td>\n",
       "      <td>1704.33</td>\n",
       "      <td>7109.08</td>\n",
       "      <td>3797.1</td>\n",
       "      <td>439.296</td>\n",
       "      <td>8886.16</td>\n",
       "      <td>5029.88</td>\n",
       "      <td>456.016</td>\n",
       "      <td>1324.18</td>\n",
       "      <td>...</td>\n",
       "      <td>20406.6</td>\n",
       "      <td>489.11</td>\n",
       "      <td>274.326</td>\n",
       "      <td>6152.39</td>\n",
       "      <td>126.473</td>\n",
       "      <td>1370.22</td>\n",
       "      <td>55.4646</td>\n",
       "      <td>95.7112</td>\n",
       "      <td>146.4</td>\n",
       "      <td>48.0095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_101</th>\n",
       "      <td>1495.63</td>\n",
       "      <td>111.67</td>\n",
       "      <td>1964.83</td>\n",
       "      <td>6670.93</td>\n",
       "      <td>5255.66</td>\n",
       "      <td>285.331</td>\n",
       "      <td>8409.28</td>\n",
       "      <td>4028.25</td>\n",
       "      <td>342.784</td>\n",
       "      <td>1015.89</td>\n",
       "      <td>...</td>\n",
       "      <td>16385.9</td>\n",
       "      <td>69.7487</td>\n",
       "      <td>380.941</td>\n",
       "      <td>4010.65</td>\n",
       "      <td>117.559</td>\n",
       "      <td>901.018</td>\n",
       "      <td>69.905</td>\n",
       "      <td>58.6354</td>\n",
       "      <td>246.885</td>\n",
       "      <td>102.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_102</th>\n",
       "      <td>3020.06</td>\n",
       "      <td>157.998</td>\n",
       "      <td>1634.87</td>\n",
       "      <td>7136.84</td>\n",
       "      <td>5181.62</td>\n",
       "      <td>408.465</td>\n",
       "      <td>12003.4</td>\n",
       "      <td>5873.79</td>\n",
       "      <td>367.427</td>\n",
       "      <td>979.468</td>\n",
       "      <td>...</td>\n",
       "      <td>21281.1</td>\n",
       "      <td>132.173</td>\n",
       "      <td>387.814</td>\n",
       "      <td>5939.97</td>\n",
       "      <td>172.314</td>\n",
       "      <td>1177.66</td>\n",
       "      <td>41.3523</td>\n",
       "      <td>133.906</td>\n",
       "      <td>78.639</td>\n",
       "      <td>54.9892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_103</th>\n",
       "      <td>2481.63</td>\n",
       "      <td>63.1608</td>\n",
       "      <td>1228.99</td>\n",
       "      <td>7284.39</td>\n",
       "      <td>5255.64</td>\n",
       "      <td>383.222</td>\n",
       "      <td>11254.2</td>\n",
       "      <td>5130.25</td>\n",
       "      <td>407.389</td>\n",
       "      <td>1640.23</td>\n",
       "      <td>...</td>\n",
       "      <td>4637.41</td>\n",
       "      <td>42.7096</td>\n",
       "      <td>269.473</td>\n",
       "      <td>880.128</td>\n",
       "      <td>178.026</td>\n",
       "      <td>185.109</td>\n",
       "      <td>34.4602</td>\n",
       "      <td>73.4292</td>\n",
       "      <td>121.923</td>\n",
       "      <td>17.7994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_104</th>\n",
       "      <td>2558.77</td>\n",
       "      <td>105.553</td>\n",
       "      <td>1993.79</td>\n",
       "      <td>7162.73</td>\n",
       "      <td>6179.08</td>\n",
       "      <td>339.455</td>\n",
       "      <td>10711.1</td>\n",
       "      <td>5374.43</td>\n",
       "      <td>663.869</td>\n",
       "      <td>894.002</td>\n",
       "      <td>...</td>\n",
       "      <td>7253.53</td>\n",
       "      <td>112.544</td>\n",
       "      <td>287.321</td>\n",
       "      <td>2015.75</td>\n",
       "      <td>153.179</td>\n",
       "      <td>414.203</td>\n",
       "      <td>95.5041</td>\n",
       "      <td>47.2978</td>\n",
       "      <td>73.6355</td>\n",
       "      <td>75.7553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_105</th>\n",
       "      <td>2993.82</td>\n",
       "      <td>183.156</td>\n",
       "      <td>1004.28</td>\n",
       "      <td>7331.51</td>\n",
       "      <td>5880.73</td>\n",
       "      <td>423.792</td>\n",
       "      <td>12874.4</td>\n",
       "      <td>4714.81</td>\n",
       "      <td>845.356</td>\n",
       "      <td>797.323</td>\n",
       "      <td>...</td>\n",
       "      <td>197.192</td>\n",
       "      <td>47.4063</td>\n",
       "      <td>430.275</td>\n",
       "      <td>59.1959</td>\n",
       "      <td>105.233</td>\n",
       "      <td>13.4843</td>\n",
       "      <td>36.1623</td>\n",
       "      <td>76.7565</td>\n",
       "      <td>105.527</td>\n",
       "      <td>18.0521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_106</th>\n",
       "      <td>1404.82</td>\n",
       "      <td>228.641</td>\n",
       "      <td>1810.98</td>\n",
       "      <td>5909.65</td>\n",
       "      <td>6487.57</td>\n",
       "      <td>348.968</td>\n",
       "      <td>7678.22</td>\n",
       "      <td>4388.55</td>\n",
       "      <td>540.393</td>\n",
       "      <td>648.147</td>\n",
       "      <td>...</td>\n",
       "      <td>13952.8</td>\n",
       "      <td>307.061</td>\n",
       "      <td>150.343</td>\n",
       "      <td>4667.14</td>\n",
       "      <td>29.3562</td>\n",
       "      <td>834.821</td>\n",
       "      <td>24.3023</td>\n",
       "      <td>7.10606</td>\n",
       "      <td>93.4605</td>\n",
       "      <td>53.6453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_107</th>\n",
       "      <td>4008.43</td>\n",
       "      <td>106.47</td>\n",
       "      <td>1715.38</td>\n",
       "      <td>7326.67</td>\n",
       "      <td>7120.98</td>\n",
       "      <td>275.147</td>\n",
       "      <td>15688.4</td>\n",
       "      <td>3823.1</td>\n",
       "      <td>800.317</td>\n",
       "      <td>1030.42</td>\n",
       "      <td>...</td>\n",
       "      <td>3606.98</td>\n",
       "      <td>96.7879</td>\n",
       "      <td>260.307</td>\n",
       "      <td>586.708</td>\n",
       "      <td>150.627</td>\n",
       "      <td>128.129</td>\n",
       "      <td>88.3621</td>\n",
       "      <td>13.9516</td>\n",
       "      <td>33.7758</td>\n",
       "      <td>25.7216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_109</th>\n",
       "      <td>2733.94</td>\n",
       "      <td>39.4078</td>\n",
       "      <td>3718.75</td>\n",
       "      <td>6361.42</td>\n",
       "      <td>7057.72</td>\n",
       "      <td>288.068</td>\n",
       "      <td>12659.8</td>\n",
       "      <td>5234.99</td>\n",
       "      <td>515.029</td>\n",
       "      <td>815.48</td>\n",
       "      <td>...</td>\n",
       "      <td>56805.8</td>\n",
       "      <td>1289.25</td>\n",
       "      <td>9703.85</td>\n",
       "      <td>17704.5</td>\n",
       "      <td>6558.96</td>\n",
       "      <td>3651.28</td>\n",
       "      <td>1816.3</td>\n",
       "      <td>1798.78</td>\n",
       "      <td>2964.82</td>\n",
       "      <td>1752.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_10</th>\n",
       "      <td>2105.18</td>\n",
       "      <td>52.9066</td>\n",
       "      <td>2583.44</td>\n",
       "      <td>5775.38</td>\n",
       "      <td>7555.59</td>\n",
       "      <td>525.883</td>\n",
       "      <td>9785.9</td>\n",
       "      <td>4769.35</td>\n",
       "      <td>687.835</td>\n",
       "      <td>1010.49</td>\n",
       "      <td>...</td>\n",
       "      <td>133203</td>\n",
       "      <td>2598.01</td>\n",
       "      <td>10328.1</td>\n",
       "      <td>44603.4</td>\n",
       "      <td>7007.75</td>\n",
       "      <td>12706.2</td>\n",
       "      <td>2149.25</td>\n",
       "      <td>2625.79</td>\n",
       "      <td>1227.68</td>\n",
       "      <td>323.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_110</th>\n",
       "      <td>2385.86</td>\n",
       "      <td>128.018</td>\n",
       "      <td>2420.62</td>\n",
       "      <td>6856.07</td>\n",
       "      <td>7775.63</td>\n",
       "      <td>327.347</td>\n",
       "      <td>10373.1</td>\n",
       "      <td>8863.18</td>\n",
       "      <td>1038.35</td>\n",
       "      <td>728.182</td>\n",
       "      <td>...</td>\n",
       "      <td>115396</td>\n",
       "      <td>392.43</td>\n",
       "      <td>8701.29</td>\n",
       "      <td>34324.7</td>\n",
       "      <td>5778.81</td>\n",
       "      <td>8762.74</td>\n",
       "      <td>2050.35</td>\n",
       "      <td>1576.79</td>\n",
       "      <td>1918.35</td>\n",
       "      <td>855.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_111</th>\n",
       "      <td>1837.58</td>\n",
       "      <td>103.58</td>\n",
       "      <td>1050.07</td>\n",
       "      <td>6882.22</td>\n",
       "      <td>7434.01</td>\n",
       "      <td>304.898</td>\n",
       "      <td>8530.51</td>\n",
       "      <td>5793.77</td>\n",
       "      <td>458.336</td>\n",
       "      <td>898.996</td>\n",
       "      <td>...</td>\n",
       "      <td>49795.6</td>\n",
       "      <td>436.361</td>\n",
       "      <td>9189.91</td>\n",
       "      <td>14670.7</td>\n",
       "      <td>6347.59</td>\n",
       "      <td>2695.73</td>\n",
       "      <td>2114.55</td>\n",
       "      <td>1492.88</td>\n",
       "      <td>1862.48</td>\n",
       "      <td>1060.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_112</th>\n",
       "      <td>2114.06</td>\n",
       "      <td>124.581</td>\n",
       "      <td>3790.93</td>\n",
       "      <td>7360.61</td>\n",
       "      <td>7794.22</td>\n",
       "      <td>160.761</td>\n",
       "      <td>8408.48</td>\n",
       "      <td>3951.42</td>\n",
       "      <td>855.31</td>\n",
       "      <td>856.613</td>\n",
       "      <td>...</td>\n",
       "      <td>45326.6</td>\n",
       "      <td>336.166</td>\n",
       "      <td>9425.21</td>\n",
       "      <td>15156</td>\n",
       "      <td>5867.11</td>\n",
       "      <td>3372.02</td>\n",
       "      <td>1871.85</td>\n",
       "      <td>937.171</td>\n",
       "      <td>2792.38</td>\n",
       "      <td>1185.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_113</th>\n",
       "      <td>2848.74</td>\n",
       "      <td>109.893</td>\n",
       "      <td>1855.93</td>\n",
       "      <td>6971.62</td>\n",
       "      <td>7087.33</td>\n",
       "      <td>306.075</td>\n",
       "      <td>11028.2</td>\n",
       "      <td>4014.06</td>\n",
       "      <td>703.277</td>\n",
       "      <td>1054.39</td>\n",
       "      <td>...</td>\n",
       "      <td>127018</td>\n",
       "      <td>302.325</td>\n",
       "      <td>8426.15</td>\n",
       "      <td>40312.7</td>\n",
       "      <td>5615.71</td>\n",
       "      <td>9600.52</td>\n",
       "      <td>1875.68</td>\n",
       "      <td>1221.69</td>\n",
       "      <td>1761.6</td>\n",
       "      <td>949.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_114</th>\n",
       "      <td>1898.09</td>\n",
       "      <td>275.44</td>\n",
       "      <td>3129.57</td>\n",
       "      <td>7930.24</td>\n",
       "      <td>7174.47</td>\n",
       "      <td>242.863</td>\n",
       "      <td>9143.71</td>\n",
       "      <td>4906.68</td>\n",
       "      <td>1115.17</td>\n",
       "      <td>793.025</td>\n",
       "      <td>...</td>\n",
       "      <td>60898.1</td>\n",
       "      <td>184.582</td>\n",
       "      <td>14359.1</td>\n",
       "      <td>19392.1</td>\n",
       "      <td>8318.18</td>\n",
       "      <td>4035.2</td>\n",
       "      <td>2857.59</td>\n",
       "      <td>1505.53</td>\n",
       "      <td>2549.88</td>\n",
       "      <td>782.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_115</th>\n",
       "      <td>2182.05</td>\n",
       "      <td>302.67</td>\n",
       "      <td>1743.78</td>\n",
       "      <td>6705.51</td>\n",
       "      <td>7611.75</td>\n",
       "      <td>378.17</td>\n",
       "      <td>9257.68</td>\n",
       "      <td>4938.18</td>\n",
       "      <td>626.99</td>\n",
       "      <td>544.548</td>\n",
       "      <td>...</td>\n",
       "      <td>140811</td>\n",
       "      <td>330.384</td>\n",
       "      <td>14044.9</td>\n",
       "      <td>42807.4</td>\n",
       "      <td>7755.32</td>\n",
       "      <td>11219.5</td>\n",
       "      <td>2814.59</td>\n",
       "      <td>1560.46</td>\n",
       "      <td>1485.7</td>\n",
       "      <td>617.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_116</th>\n",
       "      <td>2029.71</td>\n",
       "      <td>95.8118</td>\n",
       "      <td>3966.61</td>\n",
       "      <td>5927.58</td>\n",
       "      <td>6606.8</td>\n",
       "      <td>348.189</td>\n",
       "      <td>8926.85</td>\n",
       "      <td>4102.3</td>\n",
       "      <td>778.95</td>\n",
       "      <td>601.233</td>\n",
       "      <td>...</td>\n",
       "      <td>171774</td>\n",
       "      <td>460.636</td>\n",
       "      <td>12523.8</td>\n",
       "      <td>54816.3</td>\n",
       "      <td>7925.49</td>\n",
       "      <td>12095.4</td>\n",
       "      <td>2351.61</td>\n",
       "      <td>2106.07</td>\n",
       "      <td>2687.53</td>\n",
       "      <td>981.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_117</th>\n",
       "      <td>4696.14</td>\n",
       "      <td>132.32</td>\n",
       "      <td>2511.9</td>\n",
       "      <td>7213.86</td>\n",
       "      <td>8186.46</td>\n",
       "      <td>484.247</td>\n",
       "      <td>20090.3</td>\n",
       "      <td>4494.1</td>\n",
       "      <td>557.213</td>\n",
       "      <td>908.025</td>\n",
       "      <td>...</td>\n",
       "      <td>114834</td>\n",
       "      <td>242.182</td>\n",
       "      <td>9726.09</td>\n",
       "      <td>36047.9</td>\n",
       "      <td>6264.38</td>\n",
       "      <td>8537.36</td>\n",
       "      <td>1928.08</td>\n",
       "      <td>1681.5</td>\n",
       "      <td>2003.83</td>\n",
       "      <td>672.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_118</th>\n",
       "      <td>2708.95</td>\n",
       "      <td>133.553</td>\n",
       "      <td>1231.3</td>\n",
       "      <td>6493.9</td>\n",
       "      <td>7220.77</td>\n",
       "      <td>199.444</td>\n",
       "      <td>13614.4</td>\n",
       "      <td>5191.94</td>\n",
       "      <td>1207.18</td>\n",
       "      <td>425.066</td>\n",
       "      <td>...</td>\n",
       "      <td>48562.8</td>\n",
       "      <td>341.211</td>\n",
       "      <td>10943.4</td>\n",
       "      <td>15423.9</td>\n",
       "      <td>7154.09</td>\n",
       "      <td>4306.02</td>\n",
       "      <td>2927.8</td>\n",
       "      <td>1091.92</td>\n",
       "      <td>2273.37</td>\n",
       "      <td>1139.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_11</th>\n",
       "      <td>3074.78</td>\n",
       "      <td>8.91342</td>\n",
       "      <td>6321.22</td>\n",
       "      <td>9048.24</td>\n",
       "      <td>9908.96</td>\n",
       "      <td>402.865</td>\n",
       "      <td>13325.8</td>\n",
       "      <td>5289.1</td>\n",
       "      <td>596.815</td>\n",
       "      <td>824.692</td>\n",
       "      <td>...</td>\n",
       "      <td>156272</td>\n",
       "      <td>1823.55</td>\n",
       "      <td>10832</td>\n",
       "      <td>52744.1</td>\n",
       "      <td>6807.71</td>\n",
       "      <td>12158.1</td>\n",
       "      <td>2053.01</td>\n",
       "      <td>1810.76</td>\n",
       "      <td>2424.66</td>\n",
       "      <td>860.607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_129</th>\n",
       "      <td>2405.93</td>\n",
       "      <td>1379.19</td>\n",
       "      <td>3413.82</td>\n",
       "      <td>9676.45</td>\n",
       "      <td>9488.83</td>\n",
       "      <td>664.142</td>\n",
       "      <td>11327.9</td>\n",
       "      <td>6521.06</td>\n",
       "      <td>960.039</td>\n",
       "      <td>1322.39</td>\n",
       "      <td>...</td>\n",
       "      <td>243150</td>\n",
       "      <td>934.043</td>\n",
       "      <td>4500.35</td>\n",
       "      <td>77536.7</td>\n",
       "      <td>2879.96</td>\n",
       "      <td>20878.3</td>\n",
       "      <td>710.941</td>\n",
       "      <td>1025.82</td>\n",
       "      <td>1049.04</td>\n",
       "      <td>464.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_12</th>\n",
       "      <td>1811.1</td>\n",
       "      <td>14.1081</td>\n",
       "      <td>5597.47</td>\n",
       "      <td>3923.93</td>\n",
       "      <td>7794.79</td>\n",
       "      <td>298.832</td>\n",
       "      <td>8534.05</td>\n",
       "      <td>5635.7</td>\n",
       "      <td>602.802</td>\n",
       "      <td>1374.78</td>\n",
       "      <td>...</td>\n",
       "      <td>50243.6</td>\n",
       "      <td>349.428</td>\n",
       "      <td>9150.22</td>\n",
       "      <td>15786.9</td>\n",
       "      <td>4658.59</td>\n",
       "      <td>3924.63</td>\n",
       "      <td>1905.82</td>\n",
       "      <td>1574.93</td>\n",
       "      <td>2113.7</td>\n",
       "      <td>753.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_130</th>\n",
       "      <td>3469.05</td>\n",
       "      <td>1137.49</td>\n",
       "      <td>6408.47</td>\n",
       "      <td>8747.64</td>\n",
       "      <td>7000.03</td>\n",
       "      <td>527.793</td>\n",
       "      <td>14170.1</td>\n",
       "      <td>6447.47</td>\n",
       "      <td>610.11</td>\n",
       "      <td>1201.2</td>\n",
       "      <td>...</td>\n",
       "      <td>128573</td>\n",
       "      <td>1823.68</td>\n",
       "      <td>4026.89</td>\n",
       "      <td>39243.5</td>\n",
       "      <td>2656.47</td>\n",
       "      <td>10757</td>\n",
       "      <td>596.611</td>\n",
       "      <td>727.169</td>\n",
       "      <td>1050.98</td>\n",
       "      <td>562.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_131</th>\n",
       "      <td>3289.47</td>\n",
       "      <td>122.444</td>\n",
       "      <td>4481.78</td>\n",
       "      <td>9115.63</td>\n",
       "      <td>7344.45</td>\n",
       "      <td>661.651</td>\n",
       "      <td>13936.4</td>\n",
       "      <td>4996.66</td>\n",
       "      <td>921.163</td>\n",
       "      <td>843.57</td>\n",
       "      <td>...</td>\n",
       "      <td>119036</td>\n",
       "      <td>552.139</td>\n",
       "      <td>4197.86</td>\n",
       "      <td>37128.8</td>\n",
       "      <td>2644.82</td>\n",
       "      <td>9285.53</td>\n",
       "      <td>738.681</td>\n",
       "      <td>788.029</td>\n",
       "      <td>895.66</td>\n",
       "      <td>410.558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_132</th>\n",
       "      <td>3067.61</td>\n",
       "      <td>214.814</td>\n",
       "      <td>6383.25</td>\n",
       "      <td>9678.73</td>\n",
       "      <td>7760.85</td>\n",
       "      <td>803.628</td>\n",
       "      <td>14282.4</td>\n",
       "      <td>5404.6</td>\n",
       "      <td>617.109</td>\n",
       "      <td>1381.94</td>\n",
       "      <td>...</td>\n",
       "      <td>107162</td>\n",
       "      <td>263.035</td>\n",
       "      <td>3960.09</td>\n",
       "      <td>33371.5</td>\n",
       "      <td>2235.4</td>\n",
       "      <td>7981.56</td>\n",
       "      <td>774.592</td>\n",
       "      <td>956.629</td>\n",
       "      <td>587.876</td>\n",
       "      <td>400.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_133</th>\n",
       "      <td>2900.6</td>\n",
       "      <td>175.075</td>\n",
       "      <td>4618.51</td>\n",
       "      <td>4355.05</td>\n",
       "      <td>8037.76</td>\n",
       "      <td>465.758</td>\n",
       "      <td>12823.1</td>\n",
       "      <td>5232.53</td>\n",
       "      <td>497.595</td>\n",
       "      <td>913.738</td>\n",
       "      <td>...</td>\n",
       "      <td>86166.3</td>\n",
       "      <td>568.655</td>\n",
       "      <td>3942.04</td>\n",
       "      <td>26795.1</td>\n",
       "      <td>2523.34</td>\n",
       "      <td>7223.63</td>\n",
       "      <td>511.758</td>\n",
       "      <td>851.452</td>\n",
       "      <td>742.501</td>\n",
       "      <td>287.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_134</th>\n",
       "      <td>2907.26</td>\n",
       "      <td>153.721</td>\n",
       "      <td>6654.36</td>\n",
       "      <td>18385</td>\n",
       "      <td>7801.67</td>\n",
       "      <td>773.927</td>\n",
       "      <td>11515.6</td>\n",
       "      <td>5335.28</td>\n",
       "      <td>773.344</td>\n",
       "      <td>1174.54</td>\n",
       "      <td>...</td>\n",
       "      <td>123160</td>\n",
       "      <td>461.179</td>\n",
       "      <td>3962.99</td>\n",
       "      <td>39104.5</td>\n",
       "      <td>2534.69</td>\n",
       "      <td>8754.56</td>\n",
       "      <td>468.496</td>\n",
       "      <td>968.78</td>\n",
       "      <td>698.933</td>\n",
       "      <td>365.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_67</th>\n",
       "      <td>3825.42</td>\n",
       "      <td>54.4622</td>\n",
       "      <td>7191.82</td>\n",
       "      <td>5355.77</td>\n",
       "      <td>5652.24</td>\n",
       "      <td>353.022</td>\n",
       "      <td>16995.9</td>\n",
       "      <td>4916.71</td>\n",
       "      <td>983.947</td>\n",
       "      <td>1119.69</td>\n",
       "      <td>...</td>\n",
       "      <td>42586.9</td>\n",
       "      <td>1168.7</td>\n",
       "      <td>1971.7</td>\n",
       "      <td>14116.3</td>\n",
       "      <td>1030.63</td>\n",
       "      <td>2565.21</td>\n",
       "      <td>359.118</td>\n",
       "      <td>251.366</td>\n",
       "      <td>312.098</td>\n",
       "      <td>161.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_68</th>\n",
       "      <td>2036.01</td>\n",
       "      <td>24.9666</td>\n",
       "      <td>3786.65</td>\n",
       "      <td>8608.78</td>\n",
       "      <td>6325.47</td>\n",
       "      <td>345.81</td>\n",
       "      <td>9718.7</td>\n",
       "      <td>4916.58</td>\n",
       "      <td>689.637</td>\n",
       "      <td>891.801</td>\n",
       "      <td>...</td>\n",
       "      <td>73773.5</td>\n",
       "      <td>788.88</td>\n",
       "      <td>2071.73</td>\n",
       "      <td>22937.9</td>\n",
       "      <td>1173.49</td>\n",
       "      <td>6034.15</td>\n",
       "      <td>327.052</td>\n",
       "      <td>464.706</td>\n",
       "      <td>303.122</td>\n",
       "      <td>52.1478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_69</th>\n",
       "      <td>3182.61</td>\n",
       "      <td>92.5538</td>\n",
       "      <td>5875.94</td>\n",
       "      <td>8456.74</td>\n",
       "      <td>6338.72</td>\n",
       "      <td>246.007</td>\n",
       "      <td>12744.5</td>\n",
       "      <td>3889.03</td>\n",
       "      <td>696.577</td>\n",
       "      <td>617.32</td>\n",
       "      <td>...</td>\n",
       "      <td>85955.9</td>\n",
       "      <td>805.909</td>\n",
       "      <td>2253.19</td>\n",
       "      <td>27083.2</td>\n",
       "      <td>868.478</td>\n",
       "      <td>6042.38</td>\n",
       "      <td>329.191</td>\n",
       "      <td>298.822</td>\n",
       "      <td>225.109</td>\n",
       "      <td>72.1657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_70</th>\n",
       "      <td>1308.21</td>\n",
       "      <td>47.859</td>\n",
       "      <td>3930.24</td>\n",
       "      <td>8502.85</td>\n",
       "      <td>6778.38</td>\n",
       "      <td>160.355</td>\n",
       "      <td>7271.95</td>\n",
       "      <td>7265.98</td>\n",
       "      <td>509.736</td>\n",
       "      <td>1399.81</td>\n",
       "      <td>...</td>\n",
       "      <td>21276.4</td>\n",
       "      <td>111.462</td>\n",
       "      <td>998.52</td>\n",
       "      <td>6677.61</td>\n",
       "      <td>803.434</td>\n",
       "      <td>1397.59</td>\n",
       "      <td>209.21</td>\n",
       "      <td>228.984</td>\n",
       "      <td>322.28</td>\n",
       "      <td>101.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_71</th>\n",
       "      <td>2317.68</td>\n",
       "      <td>86.6641</td>\n",
       "      <td>3841.08</td>\n",
       "      <td>9011.58</td>\n",
       "      <td>6347.07</td>\n",
       "      <td>472.853</td>\n",
       "      <td>10851.3</td>\n",
       "      <td>4532.84</td>\n",
       "      <td>1172.76</td>\n",
       "      <td>1371.92</td>\n",
       "      <td>...</td>\n",
       "      <td>109046</td>\n",
       "      <td>882.862</td>\n",
       "      <td>1905.56</td>\n",
       "      <td>35487.8</td>\n",
       "      <td>1229.79</td>\n",
       "      <td>8675.45</td>\n",
       "      <td>319.66</td>\n",
       "      <td>314.247</td>\n",
       "      <td>458.493</td>\n",
       "      <td>148.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_72</th>\n",
       "      <td>3278.12</td>\n",
       "      <td>260.492</td>\n",
       "      <td>4819.62</td>\n",
       "      <td>8860.17</td>\n",
       "      <td>6619.44</td>\n",
       "      <td>518.703</td>\n",
       "      <td>13198.1</td>\n",
       "      <td>5223.33</td>\n",
       "      <td>1075.87</td>\n",
       "      <td>1346.27</td>\n",
       "      <td>...</td>\n",
       "      <td>61045.1</td>\n",
       "      <td>991.77</td>\n",
       "      <td>1803.23</td>\n",
       "      <td>21011.9</td>\n",
       "      <td>1311.94</td>\n",
       "      <td>4474.39</td>\n",
       "      <td>342.444</td>\n",
       "      <td>233.415</td>\n",
       "      <td>405.382</td>\n",
       "      <td>163.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_73</th>\n",
       "      <td>3012.79</td>\n",
       "      <td>67.5964</td>\n",
       "      <td>4867.05</td>\n",
       "      <td>8295.81</td>\n",
       "      <td>6159.95</td>\n",
       "      <td>256.268</td>\n",
       "      <td>13243.6</td>\n",
       "      <td>7696.05</td>\n",
       "      <td>746.88</td>\n",
       "      <td>1158.92</td>\n",
       "      <td>...</td>\n",
       "      <td>49074.7</td>\n",
       "      <td>431.067</td>\n",
       "      <td>1967.69</td>\n",
       "      <td>15111.3</td>\n",
       "      <td>746.208</td>\n",
       "      <td>1848.56</td>\n",
       "      <td>231.741</td>\n",
       "      <td>267.607</td>\n",
       "      <td>354.975</td>\n",
       "      <td>62.0136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_74</th>\n",
       "      <td>4464.41</td>\n",
       "      <td>250.929</td>\n",
       "      <td>3471.82</td>\n",
       "      <td>3687.27</td>\n",
       "      <td>6685.51</td>\n",
       "      <td>459.163</td>\n",
       "      <td>17008.2</td>\n",
       "      <td>3851.88</td>\n",
       "      <td>1203.79</td>\n",
       "      <td>840.319</td>\n",
       "      <td>...</td>\n",
       "      <td>25074.3</td>\n",
       "      <td>2428.21</td>\n",
       "      <td>917.032</td>\n",
       "      <td>7205.48</td>\n",
       "      <td>687.764</td>\n",
       "      <td>1666.7</td>\n",
       "      <td>248.481</td>\n",
       "      <td>263.697</td>\n",
       "      <td>412.789</td>\n",
       "      <td>141.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_76</th>\n",
       "      <td>3383.34</td>\n",
       "      <td>413.843</td>\n",
       "      <td>4322.48</td>\n",
       "      <td>3322.19</td>\n",
       "      <td>5335.26</td>\n",
       "      <td>437.078</td>\n",
       "      <td>13707</td>\n",
       "      <td>3778.34</td>\n",
       "      <td>595.611</td>\n",
       "      <td>676.603</td>\n",
       "      <td>...</td>\n",
       "      <td>45560.6</td>\n",
       "      <td>288.124</td>\n",
       "      <td>1281.7</td>\n",
       "      <td>14369.3</td>\n",
       "      <td>749.219</td>\n",
       "      <td>2757.12</td>\n",
       "      <td>221.447</td>\n",
       "      <td>336.139</td>\n",
       "      <td>9.91248</td>\n",
       "      <td>75.8089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_77</th>\n",
       "      <td>1987.85</td>\n",
       "      <td>128.422</td>\n",
       "      <td>3213.83</td>\n",
       "      <td>8032.26</td>\n",
       "      <td>6975.67</td>\n",
       "      <td>333.028</td>\n",
       "      <td>9799.54</td>\n",
       "      <td>4927.06</td>\n",
       "      <td>956.94</td>\n",
       "      <td>1022.27</td>\n",
       "      <td>...</td>\n",
       "      <td>88513.2</td>\n",
       "      <td>150.899</td>\n",
       "      <td>1853.76</td>\n",
       "      <td>26473.5</td>\n",
       "      <td>1194.29</td>\n",
       "      <td>6161.67</td>\n",
       "      <td>418.462</td>\n",
       "      <td>296.067</td>\n",
       "      <td>290.33</td>\n",
       "      <td>135.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_78</th>\n",
       "      <td>2589.47</td>\n",
       "      <td>210.728</td>\n",
       "      <td>4130.74</td>\n",
       "      <td>7540.78</td>\n",
       "      <td>11619</td>\n",
       "      <td>560.11</td>\n",
       "      <td>11991.6</td>\n",
       "      <td>3355.99</td>\n",
       "      <td>969.147</td>\n",
       "      <td>696.589</td>\n",
       "      <td>...</td>\n",
       "      <td>51701.1</td>\n",
       "      <td>175.161</td>\n",
       "      <td>1054.96</td>\n",
       "      <td>16748.4</td>\n",
       "      <td>582.806</td>\n",
       "      <td>3058.85</td>\n",
       "      <td>232.58</td>\n",
       "      <td>267.267</td>\n",
       "      <td>293.649</td>\n",
       "      <td>131.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_79</th>\n",
       "      <td>2416.14</td>\n",
       "      <td>155.106</td>\n",
       "      <td>3366.65</td>\n",
       "      <td>7865.67</td>\n",
       "      <td>10591.3</td>\n",
       "      <td>318.491</td>\n",
       "      <td>12697.9</td>\n",
       "      <td>3910.14</td>\n",
       "      <td>802.561</td>\n",
       "      <td>706.877</td>\n",
       "      <td>...</td>\n",
       "      <td>56625.4</td>\n",
       "      <td>94.8521</td>\n",
       "      <td>850.812</td>\n",
       "      <td>16491.6</td>\n",
       "      <td>309.71</td>\n",
       "      <td>2898.08</td>\n",
       "      <td>249.83</td>\n",
       "      <td>316.516</td>\n",
       "      <td>207.311</td>\n",
       "      <td>70.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_80</th>\n",
       "      <td>2115.55</td>\n",
       "      <td>65.4289</td>\n",
       "      <td>2863.58</td>\n",
       "      <td>4865.34</td>\n",
       "      <td>8857.72</td>\n",
       "      <td>231.491</td>\n",
       "      <td>10495.7</td>\n",
       "      <td>4169.62</td>\n",
       "      <td>649.874</td>\n",
       "      <td>717.034</td>\n",
       "      <td>...</td>\n",
       "      <td>45767.2</td>\n",
       "      <td>300.071</td>\n",
       "      <td>1146.34</td>\n",
       "      <td>14252.4</td>\n",
       "      <td>555.856</td>\n",
       "      <td>2822.94</td>\n",
       "      <td>228.544</td>\n",
       "      <td>385.451</td>\n",
       "      <td>321.397</td>\n",
       "      <td>80.5437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_81</th>\n",
       "      <td>2719.57</td>\n",
       "      <td>194.7</td>\n",
       "      <td>4092.68</td>\n",
       "      <td>7097.99</td>\n",
       "      <td>6158.04</td>\n",
       "      <td>484.304</td>\n",
       "      <td>10651.9</td>\n",
       "      <td>5480.14</td>\n",
       "      <td>658.224</td>\n",
       "      <td>1220.78</td>\n",
       "      <td>...</td>\n",
       "      <td>41804.1</td>\n",
       "      <td>153.625</td>\n",
       "      <td>922.506</td>\n",
       "      <td>11997.6</td>\n",
       "      <td>602.413</td>\n",
       "      <td>2306.35</td>\n",
       "      <td>240.402</td>\n",
       "      <td>245.786</td>\n",
       "      <td>156.712</td>\n",
       "      <td>75.1529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_82</th>\n",
       "      <td>1971.27</td>\n",
       "      <td>183.489</td>\n",
       "      <td>3497.57</td>\n",
       "      <td>7680.33</td>\n",
       "      <td>7483.61</td>\n",
       "      <td>315.851</td>\n",
       "      <td>10382.8</td>\n",
       "      <td>5214.24</td>\n",
       "      <td>840.03</td>\n",
       "      <td>829.889</td>\n",
       "      <td>...</td>\n",
       "      <td>52928.3</td>\n",
       "      <td>352.417</td>\n",
       "      <td>741.862</td>\n",
       "      <td>17066</td>\n",
       "      <td>470.059</td>\n",
       "      <td>3718.5</td>\n",
       "      <td>245.099</td>\n",
       "      <td>211.495</td>\n",
       "      <td>367.882</td>\n",
       "      <td>271.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_83</th>\n",
       "      <td>2127.18</td>\n",
       "      <td>171.096</td>\n",
       "      <td>3728.93</td>\n",
       "      <td>6786.28</td>\n",
       "      <td>5775.55</td>\n",
       "      <td>262.955</td>\n",
       "      <td>10774.5</td>\n",
       "      <td>4644.66</td>\n",
       "      <td>775.908</td>\n",
       "      <td>1331.52</td>\n",
       "      <td>...</td>\n",
       "      <td>53748</td>\n",
       "      <td>134.243</td>\n",
       "      <td>1421.6</td>\n",
       "      <td>16519.9</td>\n",
       "      <td>629.323</td>\n",
       "      <td>4848.86</td>\n",
       "      <td>147.687</td>\n",
       "      <td>164.13</td>\n",
       "      <td>501.977</td>\n",
       "      <td>239.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_84</th>\n",
       "      <td>2778.39</td>\n",
       "      <td>70.1358</td>\n",
       "      <td>2801.49</td>\n",
       "      <td>7541.39</td>\n",
       "      <td>7483.85</td>\n",
       "      <td>354.231</td>\n",
       "      <td>13090</td>\n",
       "      <td>4775.79</td>\n",
       "      <td>835.021</td>\n",
       "      <td>846.227</td>\n",
       "      <td>...</td>\n",
       "      <td>52817.7</td>\n",
       "      <td>151.047</td>\n",
       "      <td>632.627</td>\n",
       "      <td>17152.8</td>\n",
       "      <td>236.814</td>\n",
       "      <td>4016.71</td>\n",
       "      <td>136.528</td>\n",
       "      <td>151.568</td>\n",
       "      <td>229.545</td>\n",
       "      <td>184.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_85</th>\n",
       "      <td>2787.18</td>\n",
       "      <td>805.902</td>\n",
       "      <td>3032.74</td>\n",
       "      <td>4532.21</td>\n",
       "      <td>6343.29</td>\n",
       "      <td>310.414</td>\n",
       "      <td>11403.1</td>\n",
       "      <td>5003.86</td>\n",
       "      <td>810.424</td>\n",
       "      <td>1209.67</td>\n",
       "      <td>...</td>\n",
       "      <td>53492.3</td>\n",
       "      <td>314.08</td>\n",
       "      <td>823.272</td>\n",
       "      <td>16891</td>\n",
       "      <td>344.211</td>\n",
       "      <td>3811.52</td>\n",
       "      <td>205.12</td>\n",
       "      <td>203.096</td>\n",
       "      <td>344.653</td>\n",
       "      <td>224.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_87</th>\n",
       "      <td>2500.09</td>\n",
       "      <td>75.4022</td>\n",
       "      <td>2334.27</td>\n",
       "      <td>6769.51</td>\n",
       "      <td>5285.59</td>\n",
       "      <td>185.86</td>\n",
       "      <td>12388.6</td>\n",
       "      <td>8103.48</td>\n",
       "      <td>813.76</td>\n",
       "      <td>1162.5</td>\n",
       "      <td>...</td>\n",
       "      <td>43348.4</td>\n",
       "      <td>122.935</td>\n",
       "      <td>636.421</td>\n",
       "      <td>14456.2</td>\n",
       "      <td>329.272</td>\n",
       "      <td>2288.87</td>\n",
       "      <td>126.354</td>\n",
       "      <td>259.906</td>\n",
       "      <td>265.839</td>\n",
       "      <td>96.0507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_88</th>\n",
       "      <td>2573.71</td>\n",
       "      <td>215.801</td>\n",
       "      <td>2602.17</td>\n",
       "      <td>7470.65</td>\n",
       "      <td>7185.44</td>\n",
       "      <td>240.991</td>\n",
       "      <td>10676.6</td>\n",
       "      <td>3127.64</td>\n",
       "      <td>599.814</td>\n",
       "      <td>647.405</td>\n",
       "      <td>...</td>\n",
       "      <td>38619.2</td>\n",
       "      <td>914.848</td>\n",
       "      <td>907.702</td>\n",
       "      <td>11296.7</td>\n",
       "      <td>386.961</td>\n",
       "      <td>2393.2</td>\n",
       "      <td>204.162</td>\n",
       "      <td>199.388</td>\n",
       "      <td>324.48</td>\n",
       "      <td>171.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_89</th>\n",
       "      <td>2117.58</td>\n",
       "      <td>86.493</td>\n",
       "      <td>2718.91</td>\n",
       "      <td>7336.01</td>\n",
       "      <td>6808.53</td>\n",
       "      <td>427.314</td>\n",
       "      <td>11067.6</td>\n",
       "      <td>5550.29</td>\n",
       "      <td>680.482</td>\n",
       "      <td>748.623</td>\n",
       "      <td>...</td>\n",
       "      <td>56531.8</td>\n",
       "      <td>478.651</td>\n",
       "      <td>560.067</td>\n",
       "      <td>17429.5</td>\n",
       "      <td>259.62</td>\n",
       "      <td>3810.83</td>\n",
       "      <td>127.995</td>\n",
       "      <td>163.644</td>\n",
       "      <td>220.636</td>\n",
       "      <td>93.3728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_90</th>\n",
       "      <td>1956.91</td>\n",
       "      <td>86.9824</td>\n",
       "      <td>1563.94</td>\n",
       "      <td>7195.44</td>\n",
       "      <td>5737.31</td>\n",
       "      <td>316.325</td>\n",
       "      <td>10009.8</td>\n",
       "      <td>4605.5</td>\n",
       "      <td>455.597</td>\n",
       "      <td>1412.3</td>\n",
       "      <td>...</td>\n",
       "      <td>53327.5</td>\n",
       "      <td>108.457</td>\n",
       "      <td>520.154</td>\n",
       "      <td>16910.1</td>\n",
       "      <td>259.955</td>\n",
       "      <td>3493.01</td>\n",
       "      <td>35.4448</td>\n",
       "      <td>91.6681</td>\n",
       "      <td>160.078</td>\n",
       "      <td>123.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_91</th>\n",
       "      <td>2326.96</td>\n",
       "      <td>49.2269</td>\n",
       "      <td>3426.89</td>\n",
       "      <td>6682.68</td>\n",
       "      <td>6007.64</td>\n",
       "      <td>453.58</td>\n",
       "      <td>10674.8</td>\n",
       "      <td>2876.16</td>\n",
       "      <td>408.128</td>\n",
       "      <td>1210.64</td>\n",
       "      <td>...</td>\n",
       "      <td>26556.9</td>\n",
       "      <td>90.4107</td>\n",
       "      <td>658.044</td>\n",
       "      <td>6886.5</td>\n",
       "      <td>347.062</td>\n",
       "      <td>1404.95</td>\n",
       "      <td>131.933</td>\n",
       "      <td>115.187</td>\n",
       "      <td>297.185</td>\n",
       "      <td>137.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_92</th>\n",
       "      <td>1329.61</td>\n",
       "      <td>722.733</td>\n",
       "      <td>1499.96</td>\n",
       "      <td>7682.48</td>\n",
       "      <td>5615.78</td>\n",
       "      <td>197.848</td>\n",
       "      <td>9915.28</td>\n",
       "      <td>4329.26</td>\n",
       "      <td>695.296</td>\n",
       "      <td>583.739</td>\n",
       "      <td>...</td>\n",
       "      <td>39236.7</td>\n",
       "      <td>203.187</td>\n",
       "      <td>483.683</td>\n",
       "      <td>11167.8</td>\n",
       "      <td>250.203</td>\n",
       "      <td>2121.84</td>\n",
       "      <td>99.5772</td>\n",
       "      <td>78.1666</td>\n",
       "      <td>343.101</td>\n",
       "      <td>122.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_93</th>\n",
       "      <td>2071.44</td>\n",
       "      <td>164.161</td>\n",
       "      <td>1646.63</td>\n",
       "      <td>6253.67</td>\n",
       "      <td>11311.5</td>\n",
       "      <td>279.136</td>\n",
       "      <td>8477.06</td>\n",
       "      <td>4925.97</td>\n",
       "      <td>390.618</td>\n",
       "      <td>597.627</td>\n",
       "      <td>...</td>\n",
       "      <td>39035.2</td>\n",
       "      <td>70.6129</td>\n",
       "      <td>396.382</td>\n",
       "      <td>11555.2</td>\n",
       "      <td>245.292</td>\n",
       "      <td>2020.08</td>\n",
       "      <td>29.5373</td>\n",
       "      <td>351.442</td>\n",
       "      <td>79.6669</td>\n",
       "      <td>84.2954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_94</th>\n",
       "      <td>2605.05</td>\n",
       "      <td>203.135</td>\n",
       "      <td>1602.42</td>\n",
       "      <td>7176.16</td>\n",
       "      <td>5942.71</td>\n",
       "      <td>340.721</td>\n",
       "      <td>11753</td>\n",
       "      <td>4095.21</td>\n",
       "      <td>624.688</td>\n",
       "      <td>872.543</td>\n",
       "      <td>...</td>\n",
       "      <td>1974.02</td>\n",
       "      <td>173.1</td>\n",
       "      <td>335.993</td>\n",
       "      <td>511.999</td>\n",
       "      <td>183.919</td>\n",
       "      <td>158.847</td>\n",
       "      <td>93.4877</td>\n",
       "      <td>151.353</td>\n",
       "      <td>185.731</td>\n",
       "      <td>50.0337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_95</th>\n",
       "      <td>4297.3</td>\n",
       "      <td>36.0322</td>\n",
       "      <td>1832.89</td>\n",
       "      <td>6840.88</td>\n",
       "      <td>5210.2</td>\n",
       "      <td>237.778</td>\n",
       "      <td>17760.8</td>\n",
       "      <td>3594.7</td>\n",
       "      <td>714.518</td>\n",
       "      <td>779.276</td>\n",
       "      <td>...</td>\n",
       "      <td>22648</td>\n",
       "      <td>94.6371</td>\n",
       "      <td>337.782</td>\n",
       "      <td>6822.84</td>\n",
       "      <td>184.895</td>\n",
       "      <td>1147.42</td>\n",
       "      <td>91.8939</td>\n",
       "      <td>249.626</td>\n",
       "      <td>265.857</td>\n",
       "      <td>82.8023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_96</th>\n",
       "      <td>1724.85</td>\n",
       "      <td>177.65</td>\n",
       "      <td>2208.15</td>\n",
       "      <td>7009.32</td>\n",
       "      <td>6148.62</td>\n",
       "      <td>313.312</td>\n",
       "      <td>10382.9</td>\n",
       "      <td>4368.89</td>\n",
       "      <td>558.546</td>\n",
       "      <td>358.22</td>\n",
       "      <td>...</td>\n",
       "      <td>19176.3</td>\n",
       "      <td>111.872</td>\n",
       "      <td>287.846</td>\n",
       "      <td>5463.07</td>\n",
       "      <td>216.7</td>\n",
       "      <td>1126.03</td>\n",
       "      <td>75.8125</td>\n",
       "      <td>256.787</td>\n",
       "      <td>182.23</td>\n",
       "      <td>99.3942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_98</th>\n",
       "      <td>2556.04</td>\n",
       "      <td>60.8528</td>\n",
       "      <td>1775.98</td>\n",
       "      <td>7040.51</td>\n",
       "      <td>6240.4</td>\n",
       "      <td>197.898</td>\n",
       "      <td>9651.4</td>\n",
       "      <td>7691.35</td>\n",
       "      <td>460.584</td>\n",
       "      <td>1210.25</td>\n",
       "      <td>...</td>\n",
       "      <td>16600.6</td>\n",
       "      <td>94.3479</td>\n",
       "      <td>229.904</td>\n",
       "      <td>5245.15</td>\n",
       "      <td>108.335</td>\n",
       "      <td>969.107</td>\n",
       "      <td>64.3045</td>\n",
       "      <td>117.961</td>\n",
       "      <td>272.119</td>\n",
       "      <td>68.3559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20120829_99</th>\n",
       "      <td>2863.34</td>\n",
       "      <td>120.6</td>\n",
       "      <td>2302.66</td>\n",
       "      <td>7368.24</td>\n",
       "      <td>4609.03</td>\n",
       "      <td>226.982</td>\n",
       "      <td>9882.64</td>\n",
       "      <td>4448.15</td>\n",
       "      <td>532.719</td>\n",
       "      <td>742.372</td>\n",
       "      <td>...</td>\n",
       "      <td>23810.4</td>\n",
       "      <td>206.352</td>\n",
       "      <td>360.028</td>\n",
       "      <td>7517.38</td>\n",
       "      <td>189.645</td>\n",
       "      <td>1050.1</td>\n",
       "      <td>75.4843</td>\n",
       "      <td>62.8886</td>\n",
       "      <td>283.698</td>\n",
       "      <td>71.1747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows  10946 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0        1        2        3        4        5        6  \\\n",
       "new_index                                                                     \n",
       "20120829_07   4482.31  407.027  3671.02  6326.44  6176.96  533.566  18457.1   \n",
       "20120829_08   2507.02  51.2232  3250.53  6517.23  4384.86  517.621  10634.7   \n",
       "20120829_09   3298.28  4.20738  7994.55  9881.68  5931.93   483.42  14689.4   \n",
       "20120829_100  1754.61  262.214  1704.33  7109.08   3797.1  439.296  8886.16   \n",
       "20120829_101  1495.63   111.67  1964.83  6670.93  5255.66  285.331  8409.28   \n",
       "20120829_102  3020.06  157.998  1634.87  7136.84  5181.62  408.465  12003.4   \n",
       "20120829_103  2481.63  63.1608  1228.99  7284.39  5255.64  383.222  11254.2   \n",
       "20120829_104  2558.77  105.553  1993.79  7162.73  6179.08  339.455  10711.1   \n",
       "20120829_105  2993.82  183.156  1004.28  7331.51  5880.73  423.792  12874.4   \n",
       "20120829_106  1404.82  228.641  1810.98  5909.65  6487.57  348.968  7678.22   \n",
       "20120829_107  4008.43   106.47  1715.38  7326.67  7120.98  275.147  15688.4   \n",
       "20120829_109  2733.94  39.4078  3718.75  6361.42  7057.72  288.068  12659.8   \n",
       "20120829_10   2105.18  52.9066  2583.44  5775.38  7555.59  525.883   9785.9   \n",
       "20120829_110  2385.86  128.018  2420.62  6856.07  7775.63  327.347  10373.1   \n",
       "20120829_111  1837.58   103.58  1050.07  6882.22  7434.01  304.898  8530.51   \n",
       "20120829_112  2114.06  124.581  3790.93  7360.61  7794.22  160.761  8408.48   \n",
       "20120829_113  2848.74  109.893  1855.93  6971.62  7087.33  306.075  11028.2   \n",
       "20120829_114  1898.09   275.44  3129.57  7930.24  7174.47  242.863  9143.71   \n",
       "20120829_115  2182.05   302.67  1743.78  6705.51  7611.75   378.17  9257.68   \n",
       "20120829_116  2029.71  95.8118  3966.61  5927.58   6606.8  348.189  8926.85   \n",
       "20120829_117  4696.14   132.32   2511.9  7213.86  8186.46  484.247  20090.3   \n",
       "20120829_118  2708.95  133.553   1231.3   6493.9  7220.77  199.444  13614.4   \n",
       "20120829_11   3074.78  8.91342  6321.22  9048.24  9908.96  402.865  13325.8   \n",
       "20120829_129  2405.93  1379.19  3413.82  9676.45  9488.83  664.142  11327.9   \n",
       "20120829_12    1811.1  14.1081  5597.47  3923.93  7794.79  298.832  8534.05   \n",
       "20120829_130  3469.05  1137.49  6408.47  8747.64  7000.03  527.793  14170.1   \n",
       "20120829_131  3289.47  122.444  4481.78  9115.63  7344.45  661.651  13936.4   \n",
       "20120829_132  3067.61  214.814  6383.25  9678.73  7760.85  803.628  14282.4   \n",
       "20120829_133   2900.6  175.075  4618.51  4355.05  8037.76  465.758  12823.1   \n",
       "20120829_134  2907.26  153.721  6654.36    18385  7801.67  773.927  11515.6   \n",
       "...               ...      ...      ...      ...      ...      ...      ...   \n",
       "20120829_67   3825.42  54.4622  7191.82  5355.77  5652.24  353.022  16995.9   \n",
       "20120829_68   2036.01  24.9666  3786.65  8608.78  6325.47   345.81   9718.7   \n",
       "20120829_69   3182.61  92.5538  5875.94  8456.74  6338.72  246.007  12744.5   \n",
       "20120829_70   1308.21   47.859  3930.24  8502.85  6778.38  160.355  7271.95   \n",
       "20120829_71   2317.68  86.6641  3841.08  9011.58  6347.07  472.853  10851.3   \n",
       "20120829_72   3278.12  260.492  4819.62  8860.17  6619.44  518.703  13198.1   \n",
       "20120829_73   3012.79  67.5964  4867.05  8295.81  6159.95  256.268  13243.6   \n",
       "20120829_74   4464.41  250.929  3471.82  3687.27  6685.51  459.163  17008.2   \n",
       "20120829_76   3383.34  413.843  4322.48  3322.19  5335.26  437.078    13707   \n",
       "20120829_77   1987.85  128.422  3213.83  8032.26  6975.67  333.028  9799.54   \n",
       "20120829_78   2589.47  210.728  4130.74  7540.78    11619   560.11  11991.6   \n",
       "20120829_79   2416.14  155.106  3366.65  7865.67  10591.3  318.491  12697.9   \n",
       "20120829_80   2115.55  65.4289  2863.58  4865.34  8857.72  231.491  10495.7   \n",
       "20120829_81   2719.57    194.7  4092.68  7097.99  6158.04  484.304  10651.9   \n",
       "20120829_82   1971.27  183.489  3497.57  7680.33  7483.61  315.851  10382.8   \n",
       "20120829_83   2127.18  171.096  3728.93  6786.28  5775.55  262.955  10774.5   \n",
       "20120829_84   2778.39  70.1358  2801.49  7541.39  7483.85  354.231    13090   \n",
       "20120829_85   2787.18  805.902  3032.74  4532.21  6343.29  310.414  11403.1   \n",
       "20120829_87   2500.09  75.4022  2334.27  6769.51  5285.59   185.86  12388.6   \n",
       "20120829_88   2573.71  215.801  2602.17  7470.65  7185.44  240.991  10676.6   \n",
       "20120829_89   2117.58   86.493  2718.91  7336.01  6808.53  427.314  11067.6   \n",
       "20120829_90   1956.91  86.9824  1563.94  7195.44  5737.31  316.325  10009.8   \n",
       "20120829_91   2326.96  49.2269  3426.89  6682.68  6007.64   453.58  10674.8   \n",
       "20120829_92   1329.61  722.733  1499.96  7682.48  5615.78  197.848  9915.28   \n",
       "20120829_93   2071.44  164.161  1646.63  6253.67  11311.5  279.136  8477.06   \n",
       "20120829_94   2605.05  203.135  1602.42  7176.16  5942.71  340.721    11753   \n",
       "20120829_95    4297.3  36.0322  1832.89  6840.88   5210.2  237.778  17760.8   \n",
       "20120829_96   1724.85   177.65  2208.15  7009.32  6148.62  313.312  10382.9   \n",
       "20120829_98   2556.04  60.8528  1775.98  7040.51   6240.4  197.898   9651.4   \n",
       "20120829_99   2863.34    120.6  2302.66  7368.24  4609.03  226.982  9882.64   \n",
       "\n",
       "                    7        8        9   ...       10936    10937    10938  \\\n",
       "new_index                                 ...                                 \n",
       "20120829_07   4475.88  1412.48  727.531   ...       79918  5125.63  11959.2   \n",
       "20120829_08   6011.26  850.188  1016.01   ...      123186   1565.6  11029.4   \n",
       "20120829_09   4546.74  874.314  942.373   ...     75956.7  2721.17  10441.5   \n",
       "20120829_100  5029.88  456.016  1324.18   ...     20406.6   489.11  274.326   \n",
       "20120829_101  4028.25  342.784  1015.89   ...     16385.9  69.7487  380.941   \n",
       "20120829_102  5873.79  367.427  979.468   ...     21281.1  132.173  387.814   \n",
       "20120829_103  5130.25  407.389  1640.23   ...     4637.41  42.7096  269.473   \n",
       "20120829_104  5374.43  663.869  894.002   ...     7253.53  112.544  287.321   \n",
       "20120829_105  4714.81  845.356  797.323   ...     197.192  47.4063  430.275   \n",
       "20120829_106  4388.55  540.393  648.147   ...     13952.8  307.061  150.343   \n",
       "20120829_107   3823.1  800.317  1030.42   ...     3606.98  96.7879  260.307   \n",
       "20120829_109  5234.99  515.029   815.48   ...     56805.8  1289.25  9703.85   \n",
       "20120829_10   4769.35  687.835  1010.49   ...      133203  2598.01  10328.1   \n",
       "20120829_110  8863.18  1038.35  728.182   ...      115396   392.43  8701.29   \n",
       "20120829_111  5793.77  458.336  898.996   ...     49795.6  436.361  9189.91   \n",
       "20120829_112  3951.42   855.31  856.613   ...     45326.6  336.166  9425.21   \n",
       "20120829_113  4014.06  703.277  1054.39   ...      127018  302.325  8426.15   \n",
       "20120829_114  4906.68  1115.17  793.025   ...     60898.1  184.582  14359.1   \n",
       "20120829_115  4938.18   626.99  544.548   ...      140811  330.384  14044.9   \n",
       "20120829_116   4102.3   778.95  601.233   ...      171774  460.636  12523.8   \n",
       "20120829_117   4494.1  557.213  908.025   ...      114834  242.182  9726.09   \n",
       "20120829_118  5191.94  1207.18  425.066   ...     48562.8  341.211  10943.4   \n",
       "20120829_11    5289.1  596.815  824.692   ...      156272  1823.55    10832   \n",
       "20120829_129  6521.06  960.039  1322.39   ...      243150  934.043  4500.35   \n",
       "20120829_12    5635.7  602.802  1374.78   ...     50243.6  349.428  9150.22   \n",
       "20120829_130  6447.47   610.11   1201.2   ...      128573  1823.68  4026.89   \n",
       "20120829_131  4996.66  921.163   843.57   ...      119036  552.139  4197.86   \n",
       "20120829_132   5404.6  617.109  1381.94   ...      107162  263.035  3960.09   \n",
       "20120829_133  5232.53  497.595  913.738   ...     86166.3  568.655  3942.04   \n",
       "20120829_134  5335.28  773.344  1174.54   ...      123160  461.179  3962.99   \n",
       "...               ...      ...      ...   ...         ...      ...      ...   \n",
       "20120829_67   4916.71  983.947  1119.69   ...     42586.9   1168.7   1971.7   \n",
       "20120829_68   4916.58  689.637  891.801   ...     73773.5   788.88  2071.73   \n",
       "20120829_69   3889.03  696.577   617.32   ...     85955.9  805.909  2253.19   \n",
       "20120829_70   7265.98  509.736  1399.81   ...     21276.4  111.462   998.52   \n",
       "20120829_71   4532.84  1172.76  1371.92   ...      109046  882.862  1905.56   \n",
       "20120829_72   5223.33  1075.87  1346.27   ...     61045.1   991.77  1803.23   \n",
       "20120829_73   7696.05   746.88  1158.92   ...     49074.7  431.067  1967.69   \n",
       "20120829_74   3851.88  1203.79  840.319   ...     25074.3  2428.21  917.032   \n",
       "20120829_76   3778.34  595.611  676.603   ...     45560.6  288.124   1281.7   \n",
       "20120829_77   4927.06   956.94  1022.27   ...     88513.2  150.899  1853.76   \n",
       "20120829_78   3355.99  969.147  696.589   ...     51701.1  175.161  1054.96   \n",
       "20120829_79   3910.14  802.561  706.877   ...     56625.4  94.8521  850.812   \n",
       "20120829_80   4169.62  649.874  717.034   ...     45767.2  300.071  1146.34   \n",
       "20120829_81   5480.14  658.224  1220.78   ...     41804.1  153.625  922.506   \n",
       "20120829_82   5214.24   840.03  829.889   ...     52928.3  352.417  741.862   \n",
       "20120829_83   4644.66  775.908  1331.52   ...       53748  134.243   1421.6   \n",
       "20120829_84   4775.79  835.021  846.227   ...     52817.7  151.047  632.627   \n",
       "20120829_85   5003.86  810.424  1209.67   ...     53492.3   314.08  823.272   \n",
       "20120829_87   8103.48   813.76   1162.5   ...     43348.4  122.935  636.421   \n",
       "20120829_88   3127.64  599.814  647.405   ...     38619.2  914.848  907.702   \n",
       "20120829_89   5550.29  680.482  748.623   ...     56531.8  478.651  560.067   \n",
       "20120829_90    4605.5  455.597   1412.3   ...     53327.5  108.457  520.154   \n",
       "20120829_91   2876.16  408.128  1210.64   ...     26556.9  90.4107  658.044   \n",
       "20120829_92   4329.26  695.296  583.739   ...     39236.7  203.187  483.683   \n",
       "20120829_93   4925.97  390.618  597.627   ...     39035.2  70.6129  396.382   \n",
       "20120829_94   4095.21  624.688  872.543   ...     1974.02    173.1  335.993   \n",
       "20120829_95    3594.7  714.518  779.276   ...       22648  94.6371  337.782   \n",
       "20120829_96   4368.89  558.546   358.22   ...     19176.3  111.872  287.846   \n",
       "20120829_98   7691.35  460.584  1210.25   ...     16600.6  94.3479  229.904   \n",
       "20120829_99   4448.15  532.719  742.372   ...     23810.4  206.352  360.028   \n",
       "\n",
       "                10939    10940    10941    10942    10943    10944    10945  \n",
       "new_index                                                                    \n",
       "20120829_07     25885  7409.45  6441.98  2778.57   2722.8  1438.29   425.79  \n",
       "20120829_08   41771.9  7158.11  8263.18  2517.06  2331.97  2453.68   958.29  \n",
       "20120829_09   25155.9  6911.77  6635.63  2369.77  1620.75  2590.32  1443.06  \n",
       "20120829_100  6152.39  126.473  1370.22  55.4646  95.7112    146.4  48.0095  \n",
       "20120829_101  4010.65  117.559  901.018   69.905  58.6354  246.885  102.901  \n",
       "20120829_102  5939.97  172.314  1177.66  41.3523  133.906   78.639  54.9892  \n",
       "20120829_103  880.128  178.026  185.109  34.4602  73.4292  121.923  17.7994  \n",
       "20120829_104  2015.75  153.179  414.203  95.5041  47.2978  73.6355  75.7553  \n",
       "20120829_105  59.1959  105.233  13.4843  36.1623  76.7565  105.527  18.0521  \n",
       "20120829_106  4667.14  29.3562  834.821  24.3023  7.10606  93.4605  53.6453  \n",
       "20120829_107  586.708  150.627  128.129  88.3621  13.9516  33.7758  25.7216  \n",
       "20120829_109  17704.5  6558.96  3651.28   1816.3  1798.78  2964.82  1752.58  \n",
       "20120829_10   44603.4  7007.75  12706.2  2149.25  2625.79  1227.68  323.442  \n",
       "20120829_110  34324.7  5778.81  8762.74  2050.35  1576.79  1918.35  855.209  \n",
       "20120829_111  14670.7  6347.59  2695.73  2114.55  1492.88  1862.48  1060.01  \n",
       "20120829_112    15156  5867.11  3372.02  1871.85  937.171  2792.38  1185.49  \n",
       "20120829_113  40312.7  5615.71  9600.52  1875.68  1221.69   1761.6  949.462  \n",
       "20120829_114  19392.1  8318.18   4035.2  2857.59  1505.53  2549.88  782.967  \n",
       "20120829_115  42807.4  7755.32  11219.5  2814.59  1560.46   1485.7  617.653  \n",
       "20120829_116  54816.3  7925.49  12095.4  2351.61  2106.07  2687.53  981.494  \n",
       "20120829_117  36047.9  6264.38  8537.36  1928.08   1681.5  2003.83  672.176  \n",
       "20120829_118  15423.9  7154.09  4306.02   2927.8  1091.92  2273.37  1139.21  \n",
       "20120829_11   52744.1  6807.71  12158.1  2053.01  1810.76  2424.66  860.607  \n",
       "20120829_129  77536.7  2879.96  20878.3  710.941  1025.82  1049.04  464.055  \n",
       "20120829_12   15786.9  4658.59  3924.63  1905.82  1574.93   2113.7  753.697  \n",
       "20120829_130  39243.5  2656.47    10757  596.611  727.169  1050.98  562.605  \n",
       "20120829_131  37128.8  2644.82  9285.53  738.681  788.029   895.66  410.558  \n",
       "20120829_132  33371.5   2235.4  7981.56  774.592  956.629  587.876  400.312  \n",
       "20120829_133  26795.1  2523.34  7223.63  511.758  851.452  742.501  287.056  \n",
       "20120829_134  39104.5  2534.69  8754.56  468.496   968.78  698.933  365.612  \n",
       "...               ...      ...      ...      ...      ...      ...      ...  \n",
       "20120829_67   14116.3  1030.63  2565.21  359.118  251.366  312.098  161.553  \n",
       "20120829_68   22937.9  1173.49  6034.15  327.052  464.706  303.122  52.1478  \n",
       "20120829_69   27083.2  868.478  6042.38  329.191  298.822  225.109  72.1657  \n",
       "20120829_70   6677.61  803.434  1397.59   209.21  228.984   322.28  101.425  \n",
       "20120829_71   35487.8  1229.79  8675.45   319.66  314.247  458.493   148.29  \n",
       "20120829_72   21011.9  1311.94  4474.39  342.444  233.415  405.382  163.224  \n",
       "20120829_73   15111.3  746.208  1848.56  231.741  267.607  354.975  62.0136  \n",
       "20120829_74   7205.48  687.764   1666.7  248.481  263.697  412.789  141.122  \n",
       "20120829_76   14369.3  749.219  2757.12  221.447  336.139  9.91248  75.8089  \n",
       "20120829_77   26473.5  1194.29  6161.67  418.462  296.067   290.33  135.074  \n",
       "20120829_78   16748.4  582.806  3058.85   232.58  267.267  293.649  131.317  \n",
       "20120829_79   16491.6   309.71  2898.08   249.83  316.516  207.311    70.47  \n",
       "20120829_80   14252.4  555.856  2822.94  228.544  385.451  321.397  80.5437  \n",
       "20120829_81   11997.6  602.413  2306.35  240.402  245.786  156.712  75.1529  \n",
       "20120829_82     17066  470.059   3718.5  245.099  211.495  367.882   271.48  \n",
       "20120829_83   16519.9  629.323  4848.86  147.687   164.13  501.977  239.156  \n",
       "20120829_84   17152.8  236.814  4016.71  136.528  151.568  229.545  184.544  \n",
       "20120829_85     16891  344.211  3811.52   205.12  203.096  344.653  224.126  \n",
       "20120829_87   14456.2  329.272  2288.87  126.354  259.906  265.839  96.0507  \n",
       "20120829_88   11296.7  386.961   2393.2  204.162  199.388   324.48  171.518  \n",
       "20120829_89   17429.5   259.62  3810.83  127.995  163.644  220.636  93.3728  \n",
       "20120829_90   16910.1  259.955  3493.01  35.4448  91.6681  160.078  123.675  \n",
       "20120829_91    6886.5  347.062  1404.95  131.933  115.187  297.185   137.58  \n",
       "20120829_92   11167.8  250.203  2121.84  99.5772  78.1666  343.101  122.266  \n",
       "20120829_93   11555.2  245.292  2020.08  29.5373  351.442  79.6669  84.2954  \n",
       "20120829_94   511.999  183.919  158.847  93.4877  151.353  185.731  50.0337  \n",
       "20120829_95   6822.84  184.895  1147.42  91.8939  249.626  265.857  82.8023  \n",
       "20120829_96   5463.07    216.7  1126.03  75.8125  256.787   182.23  99.3942  \n",
       "20120829_98   5245.15  108.335  969.107  64.3045  117.961  272.119  68.3559  \n",
       "20120829_99   7517.38  189.645   1050.1  75.4843  62.8886  283.698  71.1747  \n",
       "\n",
       "[254 rows x 10946 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = X.index.to_series().map(lambda s: s.split('_')[0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(np.log10(X.fillna(1).replace(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126248940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x=X_pca[:,0],y = X_pca[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_pca_df = pd.DataFrame(X_pca, columns=['x','y'])\n",
    "X_pca_df['hue'] = batch.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='x', y='y', hue = 'hue', data = X_pca_df, fit_reg=False)\n",
    "plt.xlabel('Component #1, explained variance = %f' %(pca.explained_variance_ratio_[0]))\n",
    "plt.ylabel('Component #2, explained variance = %f' %(pca.explained_variance_ratio_[1]))\n",
    "plt.savefig('batch_effect_s_19.png', format = 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76904318,  0.01417732])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21367</th>\n",
       "      <th>21368</th>\n",
       "      <th>21369</th>\n",
       "      <th>21370</th>\n",
       "      <th>21371</th>\n",
       "      <th>21372</th>\n",
       "      <th>21373</th>\n",
       "      <th>21374</th>\n",
       "      <th>21375</th>\n",
       "      <th>21376</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_10</th>\n",
       "      <td>80.0899</td>\n",
       "      <td>28.7067</td>\n",
       "      <td>40.5381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.2363</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.2747</td>\n",
       "      <td>527.403</td>\n",
       "      <td>1.56058</td>\n",
       "      <td>213.008</td>\n",
       "      <td>3997.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.52</td>\n",
       "      <td>242.64</td>\n",
       "      <td>1724.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_11</th>\n",
       "      <td>87.0454</td>\n",
       "      <td>39.6048</td>\n",
       "      <td>60.8281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.5215</td>\n",
       "      <td>...</td>\n",
       "      <td>12.9178</td>\n",
       "      <td>261.362</td>\n",
       "      <td>222.892</td>\n",
       "      <td>12.3805</td>\n",
       "      <td>54.8183</td>\n",
       "      <td>3747.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.2474</td>\n",
       "      <td>16.345</td>\n",
       "      <td>1593.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_12</th>\n",
       "      <td>62.6872</td>\n",
       "      <td>30.5712</td>\n",
       "      <td>57.5239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.1217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.7559</td>\n",
       "      <td>...</td>\n",
       "      <td>20.3359</td>\n",
       "      <td>19.5269</td>\n",
       "      <td>1235.24</td>\n",
       "      <td>14.5052</td>\n",
       "      <td>809.919</td>\n",
       "      <td>4008.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.2019</td>\n",
       "      <td>7.6364</td>\n",
       "      <td>1545.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_13</th>\n",
       "      <td>69.4026</td>\n",
       "      <td>52.2609</td>\n",
       "      <td>77.8203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.8509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.979</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.344</td>\n",
       "      <td>115.373</td>\n",
       "      <td>3.39932</td>\n",
       "      <td>62.8582</td>\n",
       "      <td>1977.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.3452</td>\n",
       "      <td>151.078</td>\n",
       "      <td>1566.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_14</th>\n",
       "      <td>68.7106</td>\n",
       "      <td>45.9003</td>\n",
       "      <td>33.9039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.2127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.6993</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0735</td>\n",
       "      <td>111.629</td>\n",
       "      <td>5.19909</td>\n",
       "      <td>33.0926</td>\n",
       "      <td>3173.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.7006</td>\n",
       "      <td>1825.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_15</th>\n",
       "      <td>74.7311</td>\n",
       "      <td>60.8891</td>\n",
       "      <td>48.5094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0502</td>\n",
       "      <td>...</td>\n",
       "      <td>23.3853</td>\n",
       "      <td>66.3531</td>\n",
       "      <td>22.1942</td>\n",
       "      <td>22.2415</td>\n",
       "      <td>11.6695</td>\n",
       "      <td>3826.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.5518</td>\n",
       "      <td>103.743</td>\n",
       "      <td>1576.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_16</th>\n",
       "      <td>68.7716</td>\n",
       "      <td>36.0315</td>\n",
       "      <td>60.427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.3421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.3848</td>\n",
       "      <td>...</td>\n",
       "      <td>14.2265</td>\n",
       "      <td>84.931</td>\n",
       "      <td>192.528</td>\n",
       "      <td>26.3868</td>\n",
       "      <td>62.3026</td>\n",
       "      <td>3996.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.3457</td>\n",
       "      <td>11.1602</td>\n",
       "      <td>1780.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_17</th>\n",
       "      <td>48.7485</td>\n",
       "      <td>47.5603</td>\n",
       "      <td>41.9786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.8348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.9712</td>\n",
       "      <td>...</td>\n",
       "      <td>13.8729</td>\n",
       "      <td>59.565</td>\n",
       "      <td>70.8836</td>\n",
       "      <td>21.7693</td>\n",
       "      <td>15.087</td>\n",
       "      <td>5348.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0883</td>\n",
       "      <td>128.796</td>\n",
       "      <td>834.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_18</th>\n",
       "      <td>70.8186</td>\n",
       "      <td>38.6817</td>\n",
       "      <td>35.5133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.9552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0604</td>\n",
       "      <td>...</td>\n",
       "      <td>13.7124</td>\n",
       "      <td>146.46</td>\n",
       "      <td>25.6081</td>\n",
       "      <td>18.5059</td>\n",
       "      <td>4.53157</td>\n",
       "      <td>3290.5</td>\n",
       "      <td>69.2473</td>\n",
       "      <td>47.1894</td>\n",
       "      <td>27.1255</td>\n",
       "      <td>1345.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_19</th>\n",
       "      <td>69.0987</td>\n",
       "      <td>28.5402</td>\n",
       "      <td>36.6327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.7377</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3893</td>\n",
       "      <td>8.78686</td>\n",
       "      <td>34.0187</td>\n",
       "      <td>3.78028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2637.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.124</td>\n",
       "      <td>1176.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_1</th>\n",
       "      <td>68.4803</td>\n",
       "      <td>55.0909</td>\n",
       "      <td>47.9794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.9266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.4353</td>\n",
       "      <td>...</td>\n",
       "      <td>33.5644</td>\n",
       "      <td>219.203</td>\n",
       "      <td>1015.24</td>\n",
       "      <td>22.52</td>\n",
       "      <td>385.275</td>\n",
       "      <td>2852.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.65009</td>\n",
       "      <td>1224.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_20</th>\n",
       "      <td>85.5679</td>\n",
       "      <td>26.271</td>\n",
       "      <td>48.7511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.9696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.2281</td>\n",
       "      <td>...</td>\n",
       "      <td>23.2061</td>\n",
       "      <td>16.097</td>\n",
       "      <td>12.8256</td>\n",
       "      <td>11.351</td>\n",
       "      <td>1.84587</td>\n",
       "      <td>3198.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.599</td>\n",
       "      <td>3.87507</td>\n",
       "      <td>1256.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_21</th>\n",
       "      <td>59.2164</td>\n",
       "      <td>11.3051</td>\n",
       "      <td>42.4213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.5272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.271</td>\n",
       "      <td>...</td>\n",
       "      <td>4.33954</td>\n",
       "      <td>17.9994</td>\n",
       "      <td>83.3308</td>\n",
       "      <td>6.05702</td>\n",
       "      <td>20.1533</td>\n",
       "      <td>4029.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.9854</td>\n",
       "      <td>6.34885</td>\n",
       "      <td>934.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_22</th>\n",
       "      <td>72.0269</td>\n",
       "      <td>24.5632</td>\n",
       "      <td>49.123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.7142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.7153</td>\n",
       "      <td>...</td>\n",
       "      <td>10.5798</td>\n",
       "      <td>91.3324</td>\n",
       "      <td>215.857</td>\n",
       "      <td>27.7436</td>\n",
       "      <td>38.369</td>\n",
       "      <td>3408.24</td>\n",
       "      <td>167.207</td>\n",
       "      <td>51.8855</td>\n",
       "      <td>13.7271</td>\n",
       "      <td>1424.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_23</th>\n",
       "      <td>71.2611</td>\n",
       "      <td>23.4764</td>\n",
       "      <td>25.656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.4065</td>\n",
       "      <td>...</td>\n",
       "      <td>23.4773</td>\n",
       "      <td>21.6535</td>\n",
       "      <td>2291.28</td>\n",
       "      <td>7.12017</td>\n",
       "      <td>895.511</td>\n",
       "      <td>3322.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.7214</td>\n",
       "      <td>35.6606</td>\n",
       "      <td>1671.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_24</th>\n",
       "      <td>86.5317</td>\n",
       "      <td>48.1451</td>\n",
       "      <td>34.4752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.5855</td>\n",
       "      <td>...</td>\n",
       "      <td>10.7149</td>\n",
       "      <td>91.4433</td>\n",
       "      <td>181.644</td>\n",
       "      <td>10.0229</td>\n",
       "      <td>75.9837</td>\n",
       "      <td>4782.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.869</td>\n",
       "      <td>3.78124</td>\n",
       "      <td>1372.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_25</th>\n",
       "      <td>85.3486</td>\n",
       "      <td>30.9149</td>\n",
       "      <td>40.9814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.8989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.8411</td>\n",
       "      <td>...</td>\n",
       "      <td>20.2205</td>\n",
       "      <td>208.352</td>\n",
       "      <td>1851.87</td>\n",
       "      <td>14.4358</td>\n",
       "      <td>272.847</td>\n",
       "      <td>4401.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>184.002</td>\n",
       "      <td>1690.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_2</th>\n",
       "      <td>76.3428</td>\n",
       "      <td>40.9088</td>\n",
       "      <td>71.9816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0075</td>\n",
       "      <td>...</td>\n",
       "      <td>42.4715</td>\n",
       "      <td>32.704</td>\n",
       "      <td>1116.37</td>\n",
       "      <td>7.62887</td>\n",
       "      <td>1185.81</td>\n",
       "      <td>3224.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0948</td>\n",
       "      <td>15.4429</td>\n",
       "      <td>1965.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_3</th>\n",
       "      <td>78.0717</td>\n",
       "      <td>43.0734</td>\n",
       "      <td>42.8725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.6301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0863</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0778</td>\n",
       "      <td>75.3961</td>\n",
       "      <td>489.896</td>\n",
       "      <td>2.98877</td>\n",
       "      <td>114.022</td>\n",
       "      <td>4970.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.957</td>\n",
       "      <td>1.55003</td>\n",
       "      <td>1960.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_4</th>\n",
       "      <td>60.9885</td>\n",
       "      <td>35.7748</td>\n",
       "      <td>38.9346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.5713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0094</td>\n",
       "      <td>...</td>\n",
       "      <td>19.7232</td>\n",
       "      <td>37.174</td>\n",
       "      <td>147.465</td>\n",
       "      <td>29.8664</td>\n",
       "      <td>59.9227</td>\n",
       "      <td>3322.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.6785</td>\n",
       "      <td>6.97513</td>\n",
       "      <td>1440.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_5</th>\n",
       "      <td>89.6784</td>\n",
       "      <td>55.0952</td>\n",
       "      <td>68.8806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>142.217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.1877</td>\n",
       "      <td>...</td>\n",
       "      <td>16.4474</td>\n",
       "      <td>121.826</td>\n",
       "      <td>317.865</td>\n",
       "      <td>19.8983</td>\n",
       "      <td>56.7577</td>\n",
       "      <td>4088.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.6252</td>\n",
       "      <td>1485.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_6</th>\n",
       "      <td>93.8074</td>\n",
       "      <td>52.2609</td>\n",
       "      <td>63.4691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.1565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.8569</td>\n",
       "      <td>...</td>\n",
       "      <td>7.90682</td>\n",
       "      <td>21.6703</td>\n",
       "      <td>308.842</td>\n",
       "      <td>7.40672</td>\n",
       "      <td>159.044</td>\n",
       "      <td>1948.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.2495</td>\n",
       "      <td>642.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_7</th>\n",
       "      <td>64.0357</td>\n",
       "      <td>47.4375</td>\n",
       "      <td>75.6512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.7778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.1028</td>\n",
       "      <td>...</td>\n",
       "      <td>36.9743</td>\n",
       "      <td>57.7466</td>\n",
       "      <td>295.504</td>\n",
       "      <td>18.171</td>\n",
       "      <td>141.115</td>\n",
       "      <td>5086.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.1937</td>\n",
       "      <td>11.0758</td>\n",
       "      <td>1615.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_8</th>\n",
       "      <td>46.2643</td>\n",
       "      <td>55.4754</td>\n",
       "      <td>30.3108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.6163</td>\n",
       "      <td>...</td>\n",
       "      <td>28.2244</td>\n",
       "      <td>24.4851</td>\n",
       "      <td>233.584</td>\n",
       "      <td>22.5219</td>\n",
       "      <td>78.9303</td>\n",
       "      <td>3405.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.6353</td>\n",
       "      <td>25.3589</td>\n",
       "      <td>1656.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_CRR_9</th>\n",
       "      <td>57.8165</td>\n",
       "      <td>39.9969</td>\n",
       "      <td>53.1096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.4456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.4745</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209.767</td>\n",
       "      <td>35.5561</td>\n",
       "      <td>42.9655</td>\n",
       "      <td>2.56967</td>\n",
       "      <td>3232.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.9006</td>\n",
       "      <td>1305.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_HCC_10</th>\n",
       "      <td>65.5861</td>\n",
       "      <td>44.237</td>\n",
       "      <td>69.1177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.2725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.4562</td>\n",
       "      <td>...</td>\n",
       "      <td>10.8799</td>\n",
       "      <td>58.0584</td>\n",
       "      <td>804.706</td>\n",
       "      <td>10.2284</td>\n",
       "      <td>288.125</td>\n",
       "      <td>4787.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.5617</td>\n",
       "      <td>5.57384</td>\n",
       "      <td>1976.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_HCC_11</th>\n",
       "      <td>69.6211</td>\n",
       "      <td>53.961</td>\n",
       "      <td>35.3572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.6828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.5441</td>\n",
       "      <td>...</td>\n",
       "      <td>5.83397</td>\n",
       "      <td>380.914</td>\n",
       "      <td>262.724</td>\n",
       "      <td>30.5707</td>\n",
       "      <td>67.8104</td>\n",
       "      <td>2899.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0687</td>\n",
       "      <td>147.675</td>\n",
       "      <td>1401.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_HCC_12</th>\n",
       "      <td>52.6753</td>\n",
       "      <td>32.8956</td>\n",
       "      <td>41.691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.1928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.9207</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.3828</td>\n",
       "      <td>146.238</td>\n",
       "      <td>8.59936</td>\n",
       "      <td>48.426</td>\n",
       "      <td>3362.61</td>\n",
       "      <td>12.0744</td>\n",
       "      <td>32.7188</td>\n",
       "      <td>6.30232</td>\n",
       "      <td>1048.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_HCC_13</th>\n",
       "      <td>61.8865</td>\n",
       "      <td>34.9438</td>\n",
       "      <td>53.0076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.4228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.238</td>\n",
       "      <td>...</td>\n",
       "      <td>12.9442</td>\n",
       "      <td>120.007</td>\n",
       "      <td>191.548</td>\n",
       "      <td>12.5811</td>\n",
       "      <td>30.6443</td>\n",
       "      <td>4275.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.3589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1932.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp1F_HCC_14</th>\n",
       "      <td>57.3854</td>\n",
       "      <td>82.4987</td>\n",
       "      <td>29.0472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.5612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.8889</td>\n",
       "      <td>...</td>\n",
       "      <td>5.01064</td>\n",
       "      <td>130.5</td>\n",
       "      <td>47.2612</td>\n",
       "      <td>43.2974</td>\n",
       "      <td>25.0418</td>\n",
       "      <td>3129.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.7108</td>\n",
       "      <td>128.129</td>\n",
       "      <td>1335.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_CRR_24</th>\n",
       "      <td>103.626</td>\n",
       "      <td>81.5708</td>\n",
       "      <td>42.6182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.3282</td>\n",
       "      <td>17.0365</td>\n",
       "      <td>66.8246</td>\n",
       "      <td>75.2962</td>\n",
       "      <td>120.465</td>\n",
       "      <td>109.79</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_CRR_25</th>\n",
       "      <td>100.682</td>\n",
       "      <td>38.3554</td>\n",
       "      <td>38.8004</td>\n",
       "      <td>479.513</td>\n",
       "      <td>8.78453</td>\n",
       "      <td>2.76021</td>\n",
       "      <td>147.992</td>\n",
       "      <td>26.78</td>\n",
       "      <td>185.773</td>\n",
       "      <td>29.7483</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_CRR_2</th>\n",
       "      <td>81.0997</td>\n",
       "      <td>21.4281</td>\n",
       "      <td>13.0622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.5962</td>\n",
       "      <td>29.3758</td>\n",
       "      <td>128.982</td>\n",
       "      <td>30.2597</td>\n",
       "      <td>59.6354</td>\n",
       "      <td>57.1691</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_CRR_3</th>\n",
       "      <td>57.7325</td>\n",
       "      <td>16.4276</td>\n",
       "      <td>7.70586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.9418</td>\n",
       "      <td>61.6197</td>\n",
       "      <td>74.2459</td>\n",
       "      <td>42.2822</td>\n",
       "      <td>46.878</td>\n",
       "      <td>49.2671</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_CRR_4</th>\n",
       "      <td>44.8516</td>\n",
       "      <td>22.0419</td>\n",
       "      <td>11.2347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.1851</td>\n",
       "      <td>38.5591</td>\n",
       "      <td>173.167</td>\n",
       "      <td>34.8235</td>\n",
       "      <td>242.246</td>\n",
       "      <td>45.2435</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_CRR_5</th>\n",
       "      <td>79.7581</td>\n",
       "      <td>42.7533</td>\n",
       "      <td>12.3251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.4555</td>\n",
       "      <td>33.5362</td>\n",
       "      <td>138.249</td>\n",
       "      <td>38.6493</td>\n",
       "      <td>119.925</td>\n",
       "      <td>30.7505</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_CRR_6</th>\n",
       "      <td>88.7551</td>\n",
       "      <td>24.2461</td>\n",
       "      <td>15.9648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.4623</td>\n",
       "      <td>49.4763</td>\n",
       "      <td>42.2131</td>\n",
       "      <td>22.0832</td>\n",
       "      <td>86.529</td>\n",
       "      <td>9.03745</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_CRR_7</th>\n",
       "      <td>87.1723</td>\n",
       "      <td>36.0018</td>\n",
       "      <td>17.6546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0385</td>\n",
       "      <td>44.1694</td>\n",
       "      <td>109.474</td>\n",
       "      <td>52.8633</td>\n",
       "      <td>172.649</td>\n",
       "      <td>58.6994</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_CRR_8</th>\n",
       "      <td>56.0818</td>\n",
       "      <td>24.2461</td>\n",
       "      <td>17.6546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.1991</td>\n",
       "      <td>42.3242</td>\n",
       "      <td>86.3047</td>\n",
       "      <td>46.7144</td>\n",
       "      <td>111.379</td>\n",
       "      <td>64.2334</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_CRR_9</th>\n",
       "      <td>75.2604</td>\n",
       "      <td>18.3682</td>\n",
       "      <td>23.3118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.6297</td>\n",
       "      <td>41.3769</td>\n",
       "      <td>97.1987</td>\n",
       "      <td>48.2721</td>\n",
       "      <td>36.1405</td>\n",
       "      <td>18.6911</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_10</th>\n",
       "      <td>86.5728</td>\n",
       "      <td>24.9808</td>\n",
       "      <td>20.3076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.6047</td>\n",
       "      <td>32.9203</td>\n",
       "      <td>128.244</td>\n",
       "      <td>28.878</td>\n",
       "      <td>25.9046</td>\n",
       "      <td>13.967</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_11</th>\n",
       "      <td>70.6039</td>\n",
       "      <td>8.08203</td>\n",
       "      <td>17.6546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.2684</td>\n",
       "      <td>36.1669</td>\n",
       "      <td>107.763</td>\n",
       "      <td>76.9357</td>\n",
       "      <td>13.9582</td>\n",
       "      <td>52.0934</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_12</th>\n",
       "      <td>83.3336</td>\n",
       "      <td>47.0227</td>\n",
       "      <td>36.4705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.8717</td>\n",
       "      <td>11.8904</td>\n",
       "      <td>126.72</td>\n",
       "      <td>9.17302</td>\n",
       "      <td>182.005</td>\n",
       "      <td>14.7886</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_13</th>\n",
       "      <td>67.0956</td>\n",
       "      <td>57.375</td>\n",
       "      <td>23.9896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.9451</td>\n",
       "      <td>27.0787</td>\n",
       "      <td>121.213</td>\n",
       "      <td>37.7113</td>\n",
       "      <td>11.2793</td>\n",
       "      <td>38.6762</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_14</th>\n",
       "      <td>247.496</td>\n",
       "      <td>52.4944</td>\n",
       "      <td>15.606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.2666</td>\n",
       "      <td>26.7677</td>\n",
       "      <td>151.265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.814</td>\n",
       "      <td>56.5928</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_15</th>\n",
       "      <td>77.0398</td>\n",
       "      <td>28.6545</td>\n",
       "      <td>35.4014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.4475</td>\n",
       "      <td>4.60035</td>\n",
       "      <td>105.046</td>\n",
       "      <td>38.3246</td>\n",
       "      <td>3.52479</td>\n",
       "      <td>23.0044</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_16</th>\n",
       "      <td>105.648</td>\n",
       "      <td>74.7888</td>\n",
       "      <td>17.6546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0022</td>\n",
       "      <td>12.011</td>\n",
       "      <td>105.079</td>\n",
       "      <td>94.5776</td>\n",
       "      <td>107.836</td>\n",
       "      <td>39.3189</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_17</th>\n",
       "      <td>75.8707</td>\n",
       "      <td>21.0801</td>\n",
       "      <td>15.2471</td>\n",
       "      <td>321.474</td>\n",
       "      <td>2.25888</td>\n",
       "      <td>7.75418</td>\n",
       "      <td>90.6599</td>\n",
       "      <td>33.9847</td>\n",
       "      <td>82.9983</td>\n",
       "      <td>23.0044</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_18</th>\n",
       "      <td>82.7195</td>\n",
       "      <td>35.2374</td>\n",
       "      <td>28.6818</td>\n",
       "      <td>669.95</td>\n",
       "      <td>7.90608</td>\n",
       "      <td>5.30194</td>\n",
       "      <td>116.301</td>\n",
       "      <td>55.989</td>\n",
       "      <td>134.613</td>\n",
       "      <td>19.5403</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_19</th>\n",
       "      <td>146.614</td>\n",
       "      <td>54.2998</td>\n",
       "      <td>50.9856</td>\n",
       "      <td>584.091</td>\n",
       "      <td>16.1629</td>\n",
       "      <td>6.1338</td>\n",
       "      <td>105.419</td>\n",
       "      <td>39.8271</td>\n",
       "      <td>98.9814</td>\n",
       "      <td>12.2652</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_1</th>\n",
       "      <td>88.6741</td>\n",
       "      <td>17.2273</td>\n",
       "      <td>19.9966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.4138</td>\n",
       "      <td>32.9661</td>\n",
       "      <td>128.154</td>\n",
       "      <td>30.1176</td>\n",
       "      <td>157.299</td>\n",
       "      <td>286.529</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_20</th>\n",
       "      <td>82.5803</td>\n",
       "      <td>58.2183</td>\n",
       "      <td>55.6939</td>\n",
       "      <td>537.924</td>\n",
       "      <td>14.9337</td>\n",
       "      <td>9.2007</td>\n",
       "      <td>68.3733</td>\n",
       "      <td>133.26</td>\n",
       "      <td>12.673</td>\n",
       "      <td>13.4192</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_2</th>\n",
       "      <td>104.595</td>\n",
       "      <td>9.14529</td>\n",
       "      <td>8.57925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.7065</td>\n",
       "      <td>47.786</td>\n",
       "      <td>64.5019</td>\n",
       "      <td>51.9804</td>\n",
       "      <td>25.59</td>\n",
       "      <td>35.7357</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_3</th>\n",
       "      <td>79.3626</td>\n",
       "      <td>10.916</td>\n",
       "      <td>4.0124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.1833</td>\n",
       "      <td>33.1731</td>\n",
       "      <td>59.7126</td>\n",
       "      <td>49.1795</td>\n",
       "      <td>521.211</td>\n",
       "      <td>214.392</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_4</th>\n",
       "      <td>88.0115</td>\n",
       "      <td>24.5746</td>\n",
       "      <td>18.4571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.5046</td>\n",
       "      <td>26.6404</td>\n",
       "      <td>68.2462</td>\n",
       "      <td>33.6344</td>\n",
       "      <td>238.972</td>\n",
       "      <td>18.8965</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_5</th>\n",
       "      <td>103.255</td>\n",
       "      <td>39.8249</td>\n",
       "      <td>9.62977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.7413</td>\n",
       "      <td>17.8004</td>\n",
       "      <td>103.142</td>\n",
       "      <td>98.667</td>\n",
       "      <td>359.999</td>\n",
       "      <td>148.646</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_6</th>\n",
       "      <td>64.1428</td>\n",
       "      <td>15.872</td>\n",
       "      <td>27.1971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.8106</td>\n",
       "      <td>40.9483</td>\n",
       "      <td>142.541</td>\n",
       "      <td>10.1922</td>\n",
       "      <td>77.1544</td>\n",
       "      <td>28.274</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_7</th>\n",
       "      <td>87.9605</td>\n",
       "      <td>17.6335</td>\n",
       "      <td>4.0124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.5967</td>\n",
       "      <td>4.60035</td>\n",
       "      <td>166.94</td>\n",
       "      <td>22.0002</td>\n",
       "      <td>181.135</td>\n",
       "      <td>89.8254</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_8</th>\n",
       "      <td>82.6305</td>\n",
       "      <td>35.8712</td>\n",
       "      <td>19.0115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.039</td>\n",
       "      <td>41.1965</td>\n",
       "      <td>114.523</td>\n",
       "      <td>25.4806</td>\n",
       "      <td>44.0563</td>\n",
       "      <td>52.7715</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exp2R_HCC_9</th>\n",
       "      <td>114.852</td>\n",
       "      <td>25.7156</td>\n",
       "      <td>31.2968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.3425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.5905</td>\n",
       "      <td>19.8397</td>\n",
       "      <td>132.002</td>\n",
       "      <td>22.7286</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows  21377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0        1        2        3        4        5        6  \\\n",
       "new_index                                                                     \n",
       "Exp1F_CRR_10  80.0899  28.7067  40.5381      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_11  87.0454  39.6048  60.8281      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_12  62.6872  30.5712  57.5239      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_13  69.4026  52.2609  77.8203      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_14  68.7106  45.9003  33.9039      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_15  74.7311  60.8891  48.5094      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_16  68.7716  36.0315   60.427      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_17  48.7485  47.5603  41.9786      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_18  70.8186  38.6817  35.5133      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_19  69.0987  28.5402  36.6327      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_1   68.4803  55.0909  47.9794      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_20  85.5679   26.271  48.7511      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_21  59.2164  11.3051  42.4213      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_22  72.0269  24.5632   49.123      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_23  71.2611  23.4764   25.656      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_24  86.5317  48.1451  34.4752      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_25  85.3486  30.9149  40.9814      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_2   76.3428  40.9088  71.9816      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_3   78.0717  43.0734  42.8725      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_4   60.9885  35.7748  38.9346      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_5   89.6784  55.0952  68.8806      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_6   93.8074  52.2609  63.4691      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_7   64.0357  47.4375  75.6512      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_8   46.2643  55.4754  30.3108      NaN      NaN      NaN      NaN   \n",
       "Exp1F_CRR_9   57.8165  39.9969  53.1096      NaN      NaN      NaN      NaN   \n",
       "Exp1F_HCC_10  65.5861   44.237  69.1177      NaN      NaN      NaN      NaN   \n",
       "Exp1F_HCC_11  69.6211   53.961  35.3572      NaN      NaN      NaN      NaN   \n",
       "Exp1F_HCC_12  52.6753  32.8956   41.691      NaN      NaN      NaN      NaN   \n",
       "Exp1F_HCC_13  61.8865  34.9438  53.0076      NaN      NaN      NaN      NaN   \n",
       "Exp1F_HCC_14  57.3854  82.4987  29.0472      NaN      NaN      NaN      NaN   \n",
       "...               ...      ...      ...      ...      ...      ...      ...   \n",
       "Exp2R_CRR_24  103.626  81.5708  42.6182      NaN  21.3282  17.0365  66.8246   \n",
       "Exp2R_CRR_25  100.682  38.3554  38.8004  479.513  8.78453  2.76021  147.992   \n",
       "Exp2R_CRR_2   81.0997  21.4281  13.0622      NaN  47.5962  29.3758  128.982   \n",
       "Exp2R_CRR_3   57.7325  16.4276  7.70586      NaN  51.9418  61.6197  74.2459   \n",
       "Exp2R_CRR_4   44.8516  22.0419  11.2347      NaN  35.1851  38.5591  173.167   \n",
       "Exp2R_CRR_5   79.7581  42.7533  12.3251      NaN  31.4555  33.5362  138.249   \n",
       "Exp2R_CRR_6   88.7551  24.2461  15.9648      NaN  38.4623  49.4763  42.2131   \n",
       "Exp2R_CRR_7   87.1723  36.0018  17.6546      NaN  43.0385  44.1694  109.474   \n",
       "Exp2R_CRR_8   56.0818  24.2461  17.6546      NaN  37.1991  42.3242  86.3047   \n",
       "Exp2R_CRR_9   75.2604  18.3682  23.3118      NaN  37.6297  41.3769  97.1987   \n",
       "Exp2R_HCC_10  86.5728  24.9808  20.3076      NaN  46.6047  32.9203  128.244   \n",
       "Exp2R_HCC_11  70.6039  8.08203  17.6546      NaN  23.2684  36.1669  107.763   \n",
       "Exp2R_HCC_12  83.3336  47.0227  36.4705      NaN  26.8717  11.8904   126.72   \n",
       "Exp2R_HCC_13  67.0956   57.375  23.9896      NaN  23.9451  27.0787  121.213   \n",
       "Exp2R_HCC_14  247.496  52.4944   15.606      NaN  24.2666  26.7677  151.265   \n",
       "Exp2R_HCC_15  77.0398  28.6545  35.4014      NaN  18.4475  4.60035  105.046   \n",
       "Exp2R_HCC_16  105.648  74.7888  17.6546      NaN  13.0022   12.011  105.079   \n",
       "Exp2R_HCC_17  75.8707  21.0801  15.2471  321.474  2.25888  7.75418  90.6599   \n",
       "Exp2R_HCC_18  82.7195  35.2374  28.6818   669.95  7.90608  5.30194  116.301   \n",
       "Exp2R_HCC_19  146.614  54.2998  50.9856  584.091  16.1629   6.1338  105.419   \n",
       "Exp2R_HCC_1   88.6741  17.2273  19.9966      NaN  43.4138  32.9661  128.154   \n",
       "Exp2R_HCC_20  82.5803  58.2183  55.6939  537.924  14.9337   9.2007  68.3733   \n",
       "Exp2R_HCC_2   104.595  9.14529  8.57925      NaN  44.7065   47.786  64.5019   \n",
       "Exp2R_HCC_3   79.3626   10.916   4.0124      NaN  43.1833  33.1731  59.7126   \n",
       "Exp2R_HCC_4   88.0115  24.5746  18.4571      NaN  38.5046  26.6404  68.2462   \n",
       "Exp2R_HCC_5   103.255  39.8249  9.62977      NaN  42.7413  17.8004  103.142   \n",
       "Exp2R_HCC_6   64.1428   15.872  27.1971      NaN  40.8106  40.9483  142.541   \n",
       "Exp2R_HCC_7   87.9605  17.6335   4.0124      NaN  24.5967  4.60035   166.94   \n",
       "Exp2R_HCC_8   82.6305  35.8712  19.0115      NaN   37.039  41.1965  114.523   \n",
       "Exp2R_HCC_9   114.852  25.7156  31.2968      NaN  46.3425      NaN  38.5905   \n",
       "\n",
       "                    7        8        9   ...       21367    21368    21369  \\\n",
       "new_index                                 ...                                 \n",
       "Exp1F_CRR_10  45.0885      NaN  53.2363   ...         NaN  79.2747  527.403   \n",
       "Exp1F_CRR_11   71.461      NaN  27.5215   ...     12.9178  261.362  222.892   \n",
       "Exp1F_CRR_12  41.1217      NaN  46.7559   ...     20.3359  19.5269  1235.24   \n",
       "Exp1F_CRR_13  43.8509      NaN   33.979   ...         NaN  192.344  115.373   \n",
       "Exp1F_CRR_14  43.2127      NaN  95.6993   ...         NaN  14.0735  111.629   \n",
       "Exp1F_CRR_15  81.0278      NaN  79.0502   ...     23.3853  66.3531  22.1942   \n",
       "Exp1F_CRR_16  49.3421      NaN  44.3848   ...     14.2265   84.931  192.528   \n",
       "Exp1F_CRR_17  40.8348      NaN  43.9712   ...     13.8729   59.565  70.8836   \n",
       "Exp1F_CRR_18  54.9552      NaN  63.0604   ...     13.7124   146.46  25.6081   \n",
       "Exp1F_CRR_19  51.3486      NaN  75.7377   ...     12.3893  8.78686  34.0187   \n",
       "Exp1F_CRR_1   37.9266      NaN  10.4353   ...     33.5644  219.203  1015.24   \n",
       "Exp1F_CRR_20  22.9696      NaN  32.2281   ...     23.2061   16.097  12.8256   \n",
       "Exp1F_CRR_21  41.5272      NaN  145.271   ...     4.33954  17.9994  83.3308   \n",
       "Exp1F_CRR_22  39.7142      NaN  34.7153   ...     10.5798  91.3324  215.857   \n",
       "Exp1F_CRR_23  32.0253      NaN  36.4065   ...     23.4773  21.6535  2291.28   \n",
       "Exp1F_CRR_24  58.9038      NaN  72.5855   ...     10.7149  91.4433  181.644   \n",
       "Exp1F_CRR_25  67.8989      NaN  58.8411   ...     20.2205  208.352  1851.87   \n",
       "Exp1F_CRR_2   100.426      NaN  45.0075   ...     42.4715   32.704  1116.37   \n",
       "Exp1F_CRR_3   66.6301      NaN  26.0863   ...     31.0778  75.3961  489.896   \n",
       "Exp1F_CRR_4   49.5713      NaN  39.0094   ...     19.7232   37.174  147.465   \n",
       "Exp1F_CRR_5   142.217      NaN  66.1877   ...     16.4474  121.826  317.865   \n",
       "Exp1F_CRR_6   49.1565      NaN  16.8569   ...     7.90682  21.6703  308.842   \n",
       "Exp1F_CRR_7   43.7778      NaN  14.1028   ...     36.9743  57.7466  295.504   \n",
       "Exp1F_CRR_8     34.93      NaN  41.6163   ...     28.2244  24.4851  233.584   \n",
       "Exp1F_CRR_9   32.4456      NaN  22.4745   ...         NaN  209.767  35.5561   \n",
       "Exp1F_HCC_10  20.2725      NaN  50.4562   ...     10.8799  58.0584  804.706   \n",
       "Exp1F_HCC_11  21.6828      NaN  51.5441   ...     5.83397  380.914  262.724   \n",
       "Exp1F_HCC_12  50.1928      NaN  15.9207   ...         NaN  54.3828  146.238   \n",
       "Exp1F_HCC_13  59.4228      NaN   11.238   ...     12.9442  120.007  191.548   \n",
       "Exp1F_HCC_14  61.5612      NaN  61.8889   ...     5.01064    130.5  47.2612   \n",
       "...               ...      ...      ...   ...         ...      ...      ...   \n",
       "Exp2R_CRR_24  75.2962  120.465   109.79   ...         NaN      NaN      NaN   \n",
       "Exp2R_CRR_25    26.78  185.773  29.7483   ...         NaN      NaN      NaN   \n",
       "Exp2R_CRR_2   30.2597  59.6354  57.1691   ...         NaN      NaN      NaN   \n",
       "Exp2R_CRR_3   42.2822   46.878  49.2671   ...         NaN      NaN      NaN   \n",
       "Exp2R_CRR_4   34.8235  242.246  45.2435   ...         NaN      NaN      NaN   \n",
       "Exp2R_CRR_5   38.6493  119.925  30.7505   ...         NaN      NaN      NaN   \n",
       "Exp2R_CRR_6   22.0832   86.529  9.03745   ...         NaN      NaN      NaN   \n",
       "Exp2R_CRR_7   52.8633  172.649  58.6994   ...         NaN      NaN      NaN   \n",
       "Exp2R_CRR_8   46.7144  111.379  64.2334   ...         NaN      NaN      NaN   \n",
       "Exp2R_CRR_9   48.2721  36.1405  18.6911   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_10   28.878  25.9046   13.967   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_11  76.9357  13.9582  52.0934   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_12  9.17302  182.005  14.7886   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_13  37.7113  11.2793  38.6762   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_14      NaN  150.814  56.5928   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_15  38.3246  3.52479  23.0044   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_16  94.5776  107.836  39.3189   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_17  33.9847  82.9983  23.0044   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_18   55.989  134.613  19.5403   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_19  39.8271  98.9814  12.2652   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_1   30.1176  157.299  286.529   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_20   133.26   12.673  13.4192   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_2   51.9804    25.59  35.7357   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_3   49.1795  521.211  214.392   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_4   33.6344  238.972  18.8965   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_5    98.667  359.999  148.646   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_6   10.1922  77.1544   28.274   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_7   22.0002  181.135  89.8254   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_8   25.4806  44.0563  52.7715   ...         NaN      NaN      NaN   \n",
       "Exp2R_HCC_9   19.8397  132.002  22.7286   ...         NaN      NaN      NaN   \n",
       "\n",
       "                21370    21371    21372    21373    21374    21375    21376  \n",
       "new_index                                                                    \n",
       "Exp1F_CRR_10  1.56058  213.008  3997.61      NaN    43.52   242.64  1724.41  \n",
       "Exp1F_CRR_11  12.3805  54.8183  3747.28      NaN  16.2474   16.345  1593.36  \n",
       "Exp1F_CRR_12  14.5052  809.919  4008.72      NaN  15.2019   7.6364  1545.28  \n",
       "Exp1F_CRR_13  3.39932  62.8582  1977.11      NaN  63.3452  151.078  1566.88  \n",
       "Exp1F_CRR_14  5.19909  33.0926  3173.29      NaN      NaN  28.7006  1825.64  \n",
       "Exp1F_CRR_15  22.2415  11.6695  3826.54      NaN  11.5518  103.743  1576.27  \n",
       "Exp1F_CRR_16  26.3868  62.3026  3996.89      NaN  13.3457  11.1602  1780.15  \n",
       "Exp1F_CRR_17  21.7693   15.087  5348.81      NaN  47.0883  128.796  834.762  \n",
       "Exp1F_CRR_18  18.5059  4.53157   3290.5  69.2473  47.1894  27.1255  1345.87  \n",
       "Exp1F_CRR_19  3.78028      NaN   2637.6      NaN      NaN  164.124  1176.16  \n",
       "Exp1F_CRR_1     22.52  385.275  2852.07      NaN      NaN  4.65009  1224.59  \n",
       "Exp1F_CRR_20   11.351  1.84587  3198.58      NaN   51.599  3.87507  1256.33  \n",
       "Exp1F_CRR_21  6.05702  20.1533   4029.2      NaN  48.9854  6.34885  934.958  \n",
       "Exp1F_CRR_22  27.7436   38.369  3408.24  167.207  51.8855  13.7271  1424.95  \n",
       "Exp1F_CRR_23  7.12017  895.511  3322.92      NaN  22.7214  35.6606  1671.81  \n",
       "Exp1F_CRR_24  10.0229  75.9837  4782.43      NaN   21.869  3.78124  1372.24  \n",
       "Exp1F_CRR_25  14.4358  272.847  4401.09      NaN      NaN  184.002  1690.53  \n",
       "Exp1F_CRR_2   7.62887  1185.81  3224.21      NaN  24.0948  15.4429  1965.69  \n",
       "Exp1F_CRR_3   2.98877  114.022  4970.29      NaN   35.957  1.55003  1960.89  \n",
       "Exp1F_CRR_4   29.8664  59.9227  3322.86      NaN  35.6785  6.97513  1440.78  \n",
       "Exp1F_CRR_5   19.8983  56.7577  4088.78      NaN      NaN  11.6252  1485.73  \n",
       "Exp1F_CRR_6   7.40672  159.044  1948.94      NaN      NaN  37.2495  642.643  \n",
       "Exp1F_CRR_7    18.171  141.115  5086.65      NaN  20.1937  11.0758  1615.48  \n",
       "Exp1F_CRR_8   22.5219  78.9303  3405.36      NaN  24.6353  25.3589   1656.5  \n",
       "Exp1F_CRR_9   42.9655  2.56967  3232.35      NaN      NaN  27.9006  1305.97  \n",
       "Exp1F_HCC_10  10.2284  288.125  4787.08      NaN  34.5617  5.57384  1976.19  \n",
       "Exp1F_HCC_11  30.5707  67.8104  2899.01      NaN  46.0687  147.675  1401.75  \n",
       "Exp1F_HCC_12  8.59936   48.426  3362.61  12.0744  32.7188  6.30232  1048.19  \n",
       "Exp1F_HCC_13  12.5811  30.6443  4275.39      NaN  11.3589      NaN  1932.78  \n",
       "Exp1F_HCC_14  43.2974  25.0418  3129.48      NaN  19.7108  128.129  1335.54  \n",
       "...               ...      ...      ...      ...      ...      ...      ...  \n",
       "Exp2R_CRR_24      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_CRR_25      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_CRR_2       NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_CRR_3       NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_CRR_4       NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_CRR_5       NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_CRR_6       NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_CRR_7       NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_CRR_8       NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_CRR_9       NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_10      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_11      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_12      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_13      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_14      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_15      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_16      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_17      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_18      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_19      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_1       NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_20      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_2       NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_3       NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_4       NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_5       NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_6       NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_7       NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_8       NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "Exp2R_HCC_9       NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "\n",
       "[180 rows x 21377 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
